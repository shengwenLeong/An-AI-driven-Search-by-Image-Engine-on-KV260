I0316 12:04:35.021112 55708 caffe.cpp:204] Using GPUs 3
I0316 12:04:35.239470 55708 caffe.cpp:209] GPU 3: PH402 SKU 200
I0316 12:04:35.823271 55708 solver.cpp:45] Initializing solver from parameters: 
test_iter: 200
test_interval: 1000
base_lr: 0.001
display: 100
max_iter: 50000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 25000
snapshot: 50000
snapshot_prefix: "DPU_CIFAR10_48"
solver_mode: GPU
device_id: 3
random_seed: 42
net: "dpu_googlenet_hash48.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: false
weights: "googlenet.caffemodel"
I0316 12:04:35.823549 55708 solver.cpp:102] Creating training net from net file: dpu_googlenet_hash48.prototxt
I0316 12:04:35.825217 55708 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: dpu_googlenet_hash48.prototxt
I0316 12:04:35.825237 55708 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0316 12:04:35.825451 55708 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0316 12:04:35.825522 55708 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0316 12:04:35.825532 55708 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top5
I0316 12:04:35.826231 55708 net.cpp:51] Initializing net from parameters: 
name: "miniGoogleNet for CIFAR10, model 3"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "../../data/cifar10/cifar10_train_leveldb"
    batch_size: 32
  }
}
layer {
  name: "conv1/3x3_s1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/bn1"
  type: "BatchNorm"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1/scale1"
  type: "Scale"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1/relu1"
  type: "ReLU"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
}
layer {
  name: "inception_2a/1x1"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_2a/1x1/scale1"
  type: "Scale"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_2a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
}
layer {
  name: "inception_2a/3x3"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_2a/3x3/scale1"
  type: "Scale"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_2a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
}
layer {
  name: "inception_2a/output"
  type: "Concat"
  bottom: "inception_2a/1x1"
  bottom: "inception_2a/3x3"
  top: "inception_2a/output"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_3a/1x1/scale1"
  type: "Scale"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_3a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_3a/3x3/scale1"
  type: "Scale"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_3a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1"
  bottom: "inception_3a/3x3"
  top: "inception_3a/output"
}
layer {
  name: "downsample_4/3x3_s2"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "downsample_4/3x3_s2/scale1"
  type: "Scale"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "downsample_4/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
}
layer {
  name: "downsample_4/pool_s2"
  type: "Pooling"
  bottom: "inception_3a/output"
  top: "downsample_4/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_4/output"
  type: "Concat"
  bottom: "downsample_4/3x3_s2"
  bottom: "downsample_4/pool_s2"
  top: "downsample_4/output"
}
layer {
  name: "inception_5a/1x1"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_5a/1x1/scale1"
  type: "Scale"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_5a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
}
layer {
  name: "inception_5a/3x3"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_5a/3x3/scale1"
  type: "Scale"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_5a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
}
layer {
  name: "inception_5a/output"
  type: "Concat"
  bottom: "inception_5a/1x1"
  bottom: "inception_5a/3x3"
  top: "inception_5a/output"
}
layer {
  name: "inception_6a/1x1"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_6a/1x1/scale1"
  type: "Scale"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_6a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
}
layer {
  name: "inception_6a/3x3"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_6a/3x3/scale1"
  type: "Scale"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_6a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
}
layer {
  name: "inception_6a/output"
  type: "Concat"
  bottom: "inception_6a/1x1"
  bottom: "inception_6a/3x3"
  top: "inception_6a/output"
}
layer {
  name: "inception_7a/1x1"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_7a/1x1/scale1"
  type: "Scale"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_7a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
}
layer {
  name: "inception_7a/3x3"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_7a/3x3/scale1"
  type: "Scale"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_7a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
}
layer {
  name: "inception_7a/output"
  type: "Concat"
  bottom: "inception_7a/1x1"
  bottom: "inception_7a/3x3"
  top: "inception_7a/output"
}
layer {
  name: "inception_8a/1x1"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_8a/1x1/scale1"
  type: "Scale"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_8a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
}
layer {
  name: "inception_8a/3x3"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_8a/3x3/scale1"
  type: "Scale"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_8a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
}
layer {
  name: "inception_8a/output"
  type: "Concat"
  bottom: "inception_8a/1x1"
  bottom: "inception_8a/3x3"
  top: "inception_8a/output"
}
layer {
  name: "downsample_9/3x3_s2"
  type: "Convolution"
  bottom: "inception_8a/output"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "downsample_9/3x3_s2/scale1"
  type: "Scale"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "downsample_9/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
}
layer {
  name: "downsample_9/pool_s2"
  type: "Pooling"
  bottom: "inception_8a/output"
  top: "downsample_9/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_9/output"
  type: "Concat"
  bottom: "downsample_9/3x3_s2"
  bottom: "downsample_9/pool_s2"
  top: "downsample_9/output"
}
layer {
  name: "inception_10a/1x1"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_10a/1x1/scale1"
  type: "Scale"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_10a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
}
layer {
  name: "inception_10a/3x3"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_10a/3x3/scale1"
  type: "Scale"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_10a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
}
layer {
  name: "inception_10a/output"
  type: "Concat"
  bottom: "inception_10a/1x1"
  bottom: "inception_10a/3x3"
  top: "inception_10a/output"
}
layer {
  name: "inception_11a/1x1"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_11a/1x1/scale1"
  type: "Scale"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_11a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
}
layer {
  name: "inception_11a/3x3"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_11a/3x3/scale1"
  type: "Scale"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_11a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
}
layer {
  name: "inception_11a/output"
  type: "Concat"
  bottom: "inception_11a/1x1"
  bottom: "inception_11a/3x3"
  top: "inception_11a/output"
}
layer {
  name: "avg_pool_12/8x8_s1"
  type: "Pooling"
  bottom: "inception_11a/output"
  top: "avg_pool_12/8x8_s1"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "drop_8x8_s1"
  type: "Dropout"
  bottom: "avg_pool_12/8x8_s1"
  top: "avg_pool_12/8x8_s1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "latent"
  type: "InnerProduct"
  bottom: "avg_pool_12/8x8_s1"
  top: "latent"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 48
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "latent_sigmoid"
  type: "Sigmoid"
  bottom: "latent"
  top: "latent_sigmoid"
}
layer {
  name: "loss_1"
  type: "K1_EuclideanLoss"
  bottom: "latent_sigmoid"
  bottom: "latent_sigmoid"
  top: "loss: forcing-binary"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
}
layer {
  name: "latent_sigmoid_reshape"
  type: "Reshape"
  bottom: "latent_sigmoid"
  top: "latent_sigmoid_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 1
      dim: -1
    }
  }
}
layer {
  name: "latent_sigmoid_avg"
  type: "Pooling"
  bottom: "latent_sigmoid_reshape"
  top: "latent_sigmoid_avg"
  pooling_param {
    pool: AVE
    kernel_h: 1
    kernel_w: 48
  }
}
layer {
  name: "loss_2"
  type: "K2_EuclideanLoss"
  bottom: "latent_sigmoid_avg"
  bottom: "latent_sigmoid_avg"
  top: "loss: 50%-fire-rate"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
}
layer {
  name: "fc10"
  type: "InnerProduct"
  bottom: "latent_sigmoid"
  top: "fc10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc10"
  bottom: "label"
  top: "loss"
}
I0316 12:04:35.827121 55708 layer_factory.hpp:77] Creating layer data
I0316 12:04:36.831622 55708 db_leveldb.cpp:18] Opened leveldb ../../data/cifar10/cifar10_train_leveldb
I0316 12:04:36.831749 55708 net.cpp:84] Creating Layer data
I0316 12:04:36.833902 55708 net.cpp:380] data -> data
I0316 12:04:36.833941 55708 net.cpp:380] data -> label
I0316 12:04:36.835881 55708 data_layer.cpp:45] output data size: 32,3,32,32
I0316 12:04:36.836616 55708 net.cpp:122] Setting up data
I0316 12:04:36.836633 55708 net.cpp:129] Top shape: 32 3 32 32 (98304)
I0316 12:04:36.836639 55708 net.cpp:129] Top shape: 32 (32)
I0316 12:04:36.836642 55708 net.cpp:137] Memory required for data: 393344
I0316 12:04:36.836652 55708 layer_factory.hpp:77] Creating layer conv1/3x3_s1
I0316 12:04:36.836776 55708 net.cpp:84] Creating Layer conv1/3x3_s1
I0316 12:04:36.836784 55708 net.cpp:406] conv1/3x3_s1 <- data
I0316 12:04:36.836802 55708 net.cpp:380] conv1/3x3_s1 -> conv1/3x3_s1
I0316 12:04:36.837476 55708 net.cpp:122] Setting up conv1/3x3_s1
I0316 12:04:36.837488 55708 net.cpp:129] Top shape: 32 96 32 32 (3145728)
I0316 12:04:36.837492 55708 net.cpp:137] Memory required for data: 12976256
I0316 12:04:36.837507 55708 layer_factory.hpp:77] Creating layer conv1/bn1
I0316 12:04:36.837522 55708 net.cpp:84] Creating Layer conv1/bn1
I0316 12:04:36.837530 55708 net.cpp:406] conv1/bn1 <- conv1/3x3_s1
I0316 12:04:36.837538 55708 net.cpp:367] conv1/bn1 -> conv1/3x3_s1 (in-place)
I0316 12:04:36.837743 55708 net.cpp:122] Setting up conv1/bn1
I0316 12:04:36.837750 55708 net.cpp:129] Top shape: 32 96 32 32 (3145728)
I0316 12:04:36.837754 55708 net.cpp:137] Memory required for data: 25559168
I0316 12:04:36.837765 55708 layer_factory.hpp:77] Creating layer conv1/scale1
I0316 12:04:36.837774 55708 net.cpp:84] Creating Layer conv1/scale1
I0316 12:04:36.837778 55708 net.cpp:406] conv1/scale1 <- conv1/3x3_s1
I0316 12:04:36.837785 55708 net.cpp:367] conv1/scale1 -> conv1/3x3_s1 (in-place)
I0316 12:04:36.837821 55708 layer_factory.hpp:77] Creating layer conv1/scale1
I0316 12:04:36.837934 55708 net.cpp:122] Setting up conv1/scale1
I0316 12:04:36.837940 55708 net.cpp:129] Top shape: 32 96 32 32 (3145728)
I0316 12:04:36.837945 55708 net.cpp:137] Memory required for data: 38142080
I0316 12:04:36.837952 55708 layer_factory.hpp:77] Creating layer conv1/relu1
I0316 12:04:36.837958 55708 net.cpp:84] Creating Layer conv1/relu1
I0316 12:04:36.837962 55708 net.cpp:406] conv1/relu1 <- conv1/3x3_s1
I0316 12:04:36.837970 55708 net.cpp:367] conv1/relu1 -> conv1/3x3_s1 (in-place)
I0316 12:04:36.837975 55708 net.cpp:122] Setting up conv1/relu1
I0316 12:04:36.837980 55708 net.cpp:129] Top shape: 32 96 32 32 (3145728)
I0316 12:04:36.837987 55708 net.cpp:137] Memory required for data: 50724992
I0316 12:04:36.837991 55708 layer_factory.hpp:77] Creating layer conv1/3x3_s1_conv1/relu1_0_split
I0316 12:04:36.837997 55708 net.cpp:84] Creating Layer conv1/3x3_s1_conv1/relu1_0_split
I0316 12:04:36.838001 55708 net.cpp:406] conv1/3x3_s1_conv1/relu1_0_split <- conv1/3x3_s1
I0316 12:04:36.838007 55708 net.cpp:380] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_0
I0316 12:04:36.838016 55708 net.cpp:380] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_1
I0316 12:04:36.838042 55708 net.cpp:122] Setting up conv1/3x3_s1_conv1/relu1_0_split
I0316 12:04:36.838047 55708 net.cpp:129] Top shape: 32 96 32 32 (3145728)
I0316 12:04:36.838052 55708 net.cpp:129] Top shape: 32 96 32 32 (3145728)
I0316 12:04:36.838057 55708 net.cpp:137] Memory required for data: 75890816
I0316 12:04:36.838059 55708 layer_factory.hpp:77] Creating layer inception_2a/1x1
I0316 12:04:36.838068 55708 net.cpp:84] Creating Layer inception_2a/1x1
I0316 12:04:36.838071 55708 net.cpp:406] inception_2a/1x1 <- conv1/3x3_s1_conv1/relu1_0_split_0
I0316 12:04:36.838078 55708 net.cpp:380] inception_2a/1x1 -> inception_2a/1x1
I0316 12:04:36.838299 55708 net.cpp:122] Setting up inception_2a/1x1
I0316 12:04:36.838306 55708 net.cpp:129] Top shape: 32 32 32 32 (1048576)
I0316 12:04:36.838310 55708 net.cpp:137] Memory required for data: 80085120
I0316 12:04:36.838320 55708 layer_factory.hpp:77] Creating layer inception_2a/1x1/bn1
I0316 12:04:36.838340 55708 net.cpp:84] Creating Layer inception_2a/1x1/bn1
I0316 12:04:36.838344 55708 net.cpp:406] inception_2a/1x1/bn1 <- inception_2a/1x1
I0316 12:04:36.838351 55708 net.cpp:367] inception_2a/1x1/bn1 -> inception_2a/1x1 (in-place)
I0316 12:04:36.838515 55708 net.cpp:122] Setting up inception_2a/1x1/bn1
I0316 12:04:36.838522 55708 net.cpp:129] Top shape: 32 32 32 32 (1048576)
I0316 12:04:36.838526 55708 net.cpp:137] Memory required for data: 84279424
I0316 12:04:36.838532 55708 layer_factory.hpp:77] Creating layer inception_2a/1x1/scale1
I0316 12:04:36.838541 55708 net.cpp:84] Creating Layer inception_2a/1x1/scale1
I0316 12:04:36.838546 55708 net.cpp:406] inception_2a/1x1/scale1 <- inception_2a/1x1
I0316 12:04:36.838551 55708 net.cpp:367] inception_2a/1x1/scale1 -> inception_2a/1x1 (in-place)
I0316 12:04:36.838582 55708 layer_factory.hpp:77] Creating layer inception_2a/1x1/scale1
I0316 12:04:36.838675 55708 net.cpp:122] Setting up inception_2a/1x1/scale1
I0316 12:04:36.838682 55708 net.cpp:129] Top shape: 32 32 32 32 (1048576)
I0316 12:04:36.838686 55708 net.cpp:137] Memory required for data: 88473728
I0316 12:04:36.838691 55708 layer_factory.hpp:77] Creating layer inception_2a/1x1/relu1
I0316 12:04:36.838697 55708 net.cpp:84] Creating Layer inception_2a/1x1/relu1
I0316 12:04:36.838701 55708 net.cpp:406] inception_2a/1x1/relu1 <- inception_2a/1x1
I0316 12:04:36.838708 55708 net.cpp:367] inception_2a/1x1/relu1 -> inception_2a/1x1 (in-place)
I0316 12:04:36.838713 55708 net.cpp:122] Setting up inception_2a/1x1/relu1
I0316 12:04:36.838719 55708 net.cpp:129] Top shape: 32 32 32 32 (1048576)
I0316 12:04:36.838722 55708 net.cpp:137] Memory required for data: 92668032
I0316 12:04:36.838726 55708 layer_factory.hpp:77] Creating layer inception_2a/3x3
I0316 12:04:36.838735 55708 net.cpp:84] Creating Layer inception_2a/3x3
I0316 12:04:36.838739 55708 net.cpp:406] inception_2a/3x3 <- conv1/3x3_s1_conv1/relu1_0_split_1
I0316 12:04:36.838745 55708 net.cpp:380] inception_2a/3x3 -> inception_2a/3x3
I0316 12:04:36.839138 55708 net.cpp:122] Setting up inception_2a/3x3
I0316 12:04:36.839145 55708 net.cpp:129] Top shape: 32 32 32 32 (1048576)
I0316 12:04:36.839149 55708 net.cpp:137] Memory required for data: 96862336
I0316 12:04:36.839155 55708 layer_factory.hpp:77] Creating layer inception_2a/3x3/bn1
I0316 12:04:36.839161 55708 net.cpp:84] Creating Layer inception_2a/3x3/bn1
I0316 12:04:36.839164 55708 net.cpp:406] inception_2a/3x3/bn1 <- inception_2a/3x3
I0316 12:04:36.839172 55708 net.cpp:367] inception_2a/3x3/bn1 -> inception_2a/3x3 (in-place)
I0316 12:04:36.839334 55708 net.cpp:122] Setting up inception_2a/3x3/bn1
I0316 12:04:36.839341 55708 net.cpp:129] Top shape: 32 32 32 32 (1048576)
I0316 12:04:36.839344 55708 net.cpp:137] Memory required for data: 101056640
I0316 12:04:36.839356 55708 layer_factory.hpp:77] Creating layer inception_2a/3x3/scale1
I0316 12:04:36.839361 55708 net.cpp:84] Creating Layer inception_2a/3x3/scale1
I0316 12:04:36.839365 55708 net.cpp:406] inception_2a/3x3/scale1 <- inception_2a/3x3
I0316 12:04:36.839371 55708 net.cpp:367] inception_2a/3x3/scale1 -> inception_2a/3x3 (in-place)
I0316 12:04:36.839402 55708 layer_factory.hpp:77] Creating layer inception_2a/3x3/scale1
I0316 12:04:36.839494 55708 net.cpp:122] Setting up inception_2a/3x3/scale1
I0316 12:04:36.839502 55708 net.cpp:129] Top shape: 32 32 32 32 (1048576)
I0316 12:04:36.839505 55708 net.cpp:137] Memory required for data: 105250944
I0316 12:04:36.839512 55708 layer_factory.hpp:77] Creating layer inception_2a/3x3/relu1
I0316 12:04:36.839517 55708 net.cpp:84] Creating Layer inception_2a/3x3/relu1
I0316 12:04:36.839520 55708 net.cpp:406] inception_2a/3x3/relu1 <- inception_2a/3x3
I0316 12:04:36.839525 55708 net.cpp:367] inception_2a/3x3/relu1 -> inception_2a/3x3 (in-place)
I0316 12:04:36.839531 55708 net.cpp:122] Setting up inception_2a/3x3/relu1
I0316 12:04:36.839536 55708 net.cpp:129] Top shape: 32 32 32 32 (1048576)
I0316 12:04:36.839540 55708 net.cpp:137] Memory required for data: 109445248
I0316 12:04:36.839543 55708 layer_factory.hpp:77] Creating layer inception_2a/output
I0316 12:04:36.839557 55708 net.cpp:84] Creating Layer inception_2a/output
I0316 12:04:36.839561 55708 net.cpp:406] inception_2a/output <- inception_2a/1x1
I0316 12:04:36.839565 55708 net.cpp:406] inception_2a/output <- inception_2a/3x3
I0316 12:04:36.839570 55708 net.cpp:380] inception_2a/output -> inception_2a/output
I0316 12:04:36.839586 55708 net.cpp:122] Setting up inception_2a/output
I0316 12:04:36.839592 55708 net.cpp:129] Top shape: 32 64 32 32 (2097152)
I0316 12:04:36.839596 55708 net.cpp:137] Memory required for data: 117833856
I0316 12:04:36.839598 55708 layer_factory.hpp:77] Creating layer inception_2a/output_inception_2a/output_0_split
I0316 12:04:36.839607 55708 net.cpp:84] Creating Layer inception_2a/output_inception_2a/output_0_split
I0316 12:04:36.839609 55708 net.cpp:406] inception_2a/output_inception_2a/output_0_split <- inception_2a/output
I0316 12:04:36.839617 55708 net.cpp:380] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_0
I0316 12:04:36.839624 55708 net.cpp:380] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_1
I0316 12:04:36.839653 55708 net.cpp:122] Setting up inception_2a/output_inception_2a/output_0_split
I0316 12:04:36.839658 55708 net.cpp:129] Top shape: 32 64 32 32 (2097152)
I0316 12:04:36.839663 55708 net.cpp:129] Top shape: 32 64 32 32 (2097152)
I0316 12:04:36.839668 55708 net.cpp:137] Memory required for data: 134611072
I0316 12:04:36.839673 55708 layer_factory.hpp:77] Creating layer inception_3a/1x1
I0316 12:04:36.839682 55708 net.cpp:84] Creating Layer inception_3a/1x1
I0316 12:04:36.839686 55708 net.cpp:406] inception_3a/1x1 <- inception_2a/output_inception_2a/output_0_split_0
I0316 12:04:36.839694 55708 net.cpp:380] inception_3a/1x1 -> inception_3a/1x1
I0316 12:04:36.839910 55708 net.cpp:122] Setting up inception_3a/1x1
I0316 12:04:36.839917 55708 net.cpp:129] Top shape: 32 32 32 32 (1048576)
I0316 12:04:36.839920 55708 net.cpp:137] Memory required for data: 138805376
I0316 12:04:36.839927 55708 layer_factory.hpp:77] Creating layer inception_3a/1x1/bn1
I0316 12:04:36.839934 55708 net.cpp:84] Creating Layer inception_3a/1x1/bn1
I0316 12:04:36.839937 55708 net.cpp:406] inception_3a/1x1/bn1 <- inception_3a/1x1
I0316 12:04:36.839943 55708 net.cpp:367] inception_3a/1x1/bn1 -> inception_3a/1x1 (in-place)
I0316 12:04:36.840103 55708 net.cpp:122] Setting up inception_3a/1x1/bn1
I0316 12:04:36.840113 55708 net.cpp:129] Top shape: 32 32 32 32 (1048576)
I0316 12:04:36.840116 55708 net.cpp:137] Memory required for data: 142999680
I0316 12:04:36.840123 55708 layer_factory.hpp:77] Creating layer inception_3a/1x1/scale1
I0316 12:04:36.840128 55708 net.cpp:84] Creating Layer inception_3a/1x1/scale1
I0316 12:04:36.840133 55708 net.cpp:406] inception_3a/1x1/scale1 <- inception_3a/1x1
I0316 12:04:36.840138 55708 net.cpp:367] inception_3a/1x1/scale1 -> inception_3a/1x1 (in-place)
I0316 12:04:36.840167 55708 layer_factory.hpp:77] Creating layer inception_3a/1x1/scale1
I0316 12:04:36.840256 55708 net.cpp:122] Setting up inception_3a/1x1/scale1
I0316 12:04:36.840265 55708 net.cpp:129] Top shape: 32 32 32 32 (1048576)
I0316 12:04:36.840267 55708 net.cpp:137] Memory required for data: 147193984
I0316 12:04:36.840273 55708 layer_factory.hpp:77] Creating layer inception_3a/1x1/relu1
I0316 12:04:36.840278 55708 net.cpp:84] Creating Layer inception_3a/1x1/relu1
I0316 12:04:36.840283 55708 net.cpp:406] inception_3a/1x1/relu1 <- inception_3a/1x1
I0316 12:04:36.840287 55708 net.cpp:367] inception_3a/1x1/relu1 -> inception_3a/1x1 (in-place)
I0316 12:04:36.840293 55708 net.cpp:122] Setting up inception_3a/1x1/relu1
I0316 12:04:36.840297 55708 net.cpp:129] Top shape: 32 32 32 32 (1048576)
I0316 12:04:36.840302 55708 net.cpp:137] Memory required for data: 151388288
I0316 12:04:36.840306 55708 layer_factory.hpp:77] Creating layer inception_3a/3x3
I0316 12:04:36.840313 55708 net.cpp:84] Creating Layer inception_3a/3x3
I0316 12:04:36.840317 55708 net.cpp:406] inception_3a/3x3 <- inception_2a/output_inception_2a/output_0_split_1
I0316 12:04:36.840332 55708 net.cpp:380] inception_3a/3x3 -> inception_3a/3x3
I0316 12:04:36.840757 55708 net.cpp:122] Setting up inception_3a/3x3
I0316 12:04:36.840766 55708 net.cpp:129] Top shape: 32 48 32 32 (1572864)
I0316 12:04:36.840770 55708 net.cpp:137] Memory required for data: 157679744
I0316 12:04:36.840777 55708 layer_factory.hpp:77] Creating layer inception_3a/3x3/bn1
I0316 12:04:36.840785 55708 net.cpp:84] Creating Layer inception_3a/3x3/bn1
I0316 12:04:36.840787 55708 net.cpp:406] inception_3a/3x3/bn1 <- inception_3a/3x3
I0316 12:04:36.840793 55708 net.cpp:367] inception_3a/3x3/bn1 -> inception_3a/3x3 (in-place)
I0316 12:04:36.840958 55708 net.cpp:122] Setting up inception_3a/3x3/bn1
I0316 12:04:36.840966 55708 net.cpp:129] Top shape: 32 48 32 32 (1572864)
I0316 12:04:36.840970 55708 net.cpp:137] Memory required for data: 163971200
I0316 12:04:36.840981 55708 layer_factory.hpp:77] Creating layer inception_3a/3x3/scale1
I0316 12:04:36.840988 55708 net.cpp:84] Creating Layer inception_3a/3x3/scale1
I0316 12:04:36.840992 55708 net.cpp:406] inception_3a/3x3/scale1 <- inception_3a/3x3
I0316 12:04:36.840998 55708 net.cpp:367] inception_3a/3x3/scale1 -> inception_3a/3x3 (in-place)
I0316 12:04:36.841028 55708 layer_factory.hpp:77] Creating layer inception_3a/3x3/scale1
I0316 12:04:36.841146 55708 net.cpp:122] Setting up inception_3a/3x3/scale1
I0316 12:04:36.841154 55708 net.cpp:129] Top shape: 32 48 32 32 (1572864)
I0316 12:04:36.841158 55708 net.cpp:137] Memory required for data: 170262656
I0316 12:04:36.841166 55708 layer_factory.hpp:77] Creating layer inception_3a/3x3/relu1
I0316 12:04:36.841172 55708 net.cpp:84] Creating Layer inception_3a/3x3/relu1
I0316 12:04:36.841176 55708 net.cpp:406] inception_3a/3x3/relu1 <- inception_3a/3x3
I0316 12:04:36.841183 55708 net.cpp:367] inception_3a/3x3/relu1 -> inception_3a/3x3 (in-place)
I0316 12:04:36.841188 55708 net.cpp:122] Setting up inception_3a/3x3/relu1
I0316 12:04:36.841197 55708 net.cpp:129] Top shape: 32 48 32 32 (1572864)
I0316 12:04:36.841200 55708 net.cpp:137] Memory required for data: 176554112
I0316 12:04:36.841207 55708 layer_factory.hpp:77] Creating layer inception_3a/output
I0316 12:04:36.841212 55708 net.cpp:84] Creating Layer inception_3a/output
I0316 12:04:36.841217 55708 net.cpp:406] inception_3a/output <- inception_3a/1x1
I0316 12:04:36.841224 55708 net.cpp:406] inception_3a/output <- inception_3a/3x3
I0316 12:04:36.841229 55708 net.cpp:380] inception_3a/output -> inception_3a/output
I0316 12:04:36.841280 55708 net.cpp:122] Setting up inception_3a/output
I0316 12:04:36.841290 55708 net.cpp:129] Top shape: 32 80 32 32 (2621440)
I0316 12:04:36.841293 55708 net.cpp:137] Memory required for data: 187039872
I0316 12:04:36.841297 55708 layer_factory.hpp:77] Creating layer inception_3a/output_inception_3a/output_0_split
I0316 12:04:36.841306 55708 net.cpp:84] Creating Layer inception_3a/output_inception_3a/output_0_split
I0316 12:04:36.841311 55708 net.cpp:406] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0316 12:04:36.841316 55708 net.cpp:380] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0316 12:04:36.841325 55708 net.cpp:380] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0316 12:04:36.841359 55708 net.cpp:122] Setting up inception_3a/output_inception_3a/output_0_split
I0316 12:04:36.841368 55708 net.cpp:129] Top shape: 32 80 32 32 (2621440)
I0316 12:04:36.841372 55708 net.cpp:129] Top shape: 32 80 32 32 (2621440)
I0316 12:04:36.841377 55708 net.cpp:137] Memory required for data: 208011392
I0316 12:04:36.841380 55708 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2
I0316 12:04:36.841389 55708 net.cpp:84] Creating Layer downsample_4/3x3_s2
I0316 12:04:36.841394 55708 net.cpp:406] downsample_4/3x3_s2 <- inception_3a/output_inception_3a/output_0_split_0
I0316 12:04:36.841399 55708 net.cpp:380] downsample_4/3x3_s2 -> downsample_4/3x3_s2
I0316 12:04:36.843398 55708 net.cpp:122] Setting up downsample_4/3x3_s2
I0316 12:04:36.843426 55708 net.cpp:129] Top shape: 32 80 16 16 (655360)
I0316 12:04:36.843430 55708 net.cpp:137] Memory required for data: 210632832
I0316 12:04:36.843438 55708 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/bn1
I0316 12:04:36.843446 55708 net.cpp:84] Creating Layer downsample_4/3x3_s2/bn1
I0316 12:04:36.843451 55708 net.cpp:406] downsample_4/3x3_s2/bn1 <- downsample_4/3x3_s2
I0316 12:04:36.843458 55708 net.cpp:367] downsample_4/3x3_s2/bn1 -> downsample_4/3x3_s2 (in-place)
I0316 12:04:36.843614 55708 net.cpp:122] Setting up downsample_4/3x3_s2/bn1
I0316 12:04:36.843621 55708 net.cpp:129] Top shape: 32 80 16 16 (655360)
I0316 12:04:36.843626 55708 net.cpp:137] Memory required for data: 213254272
I0316 12:04:36.843632 55708 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/scale1
I0316 12:04:36.843637 55708 net.cpp:84] Creating Layer downsample_4/3x3_s2/scale1
I0316 12:04:36.843641 55708 net.cpp:406] downsample_4/3x3_s2/scale1 <- downsample_4/3x3_s2
I0316 12:04:36.843647 55708 net.cpp:367] downsample_4/3x3_s2/scale1 -> downsample_4/3x3_s2 (in-place)
I0316 12:04:36.843680 55708 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/scale1
I0316 12:04:36.843780 55708 net.cpp:122] Setting up downsample_4/3x3_s2/scale1
I0316 12:04:36.843786 55708 net.cpp:129] Top shape: 32 80 16 16 (655360)
I0316 12:04:36.843791 55708 net.cpp:137] Memory required for data: 215875712
I0316 12:04:36.843796 55708 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/relu1
I0316 12:04:36.843801 55708 net.cpp:84] Creating Layer downsample_4/3x3_s2/relu1
I0316 12:04:36.843804 55708 net.cpp:406] downsample_4/3x3_s2/relu1 <- downsample_4/3x3_s2
I0316 12:04:36.843809 55708 net.cpp:367] downsample_4/3x3_s2/relu1 -> downsample_4/3x3_s2 (in-place)
I0316 12:04:36.843814 55708 net.cpp:122] Setting up downsample_4/3x3_s2/relu1
I0316 12:04:36.843818 55708 net.cpp:129] Top shape: 32 80 16 16 (655360)
I0316 12:04:36.843822 55708 net.cpp:137] Memory required for data: 218497152
I0316 12:04:36.843827 55708 layer_factory.hpp:77] Creating layer downsample_4/pool_s2
I0316 12:04:36.843839 55708 net.cpp:84] Creating Layer downsample_4/pool_s2
I0316 12:04:36.843844 55708 net.cpp:406] downsample_4/pool_s2 <- inception_3a/output_inception_3a/output_0_split_1
I0316 12:04:36.843849 55708 net.cpp:380] downsample_4/pool_s2 -> downsample_4/pool_s2
I0316 12:04:36.843895 55708 net.cpp:122] Setting up downsample_4/pool_s2
I0316 12:04:36.843902 55708 net.cpp:129] Top shape: 32 80 16 16 (655360)
I0316 12:04:36.843906 55708 net.cpp:137] Memory required for data: 221118592
I0316 12:04:36.843909 55708 layer_factory.hpp:77] Creating layer downsample_4/output
I0316 12:04:36.843915 55708 net.cpp:84] Creating Layer downsample_4/output
I0316 12:04:36.843919 55708 net.cpp:406] downsample_4/output <- downsample_4/3x3_s2
I0316 12:04:36.843922 55708 net.cpp:406] downsample_4/output <- downsample_4/pool_s2
I0316 12:04:36.843927 55708 net.cpp:380] downsample_4/output -> downsample_4/output
I0316 12:04:36.843945 55708 net.cpp:122] Setting up downsample_4/output
I0316 12:04:36.843950 55708 net.cpp:129] Top shape: 32 160 16 16 (1310720)
I0316 12:04:36.843955 55708 net.cpp:137] Memory required for data: 226361472
I0316 12:04:36.843957 55708 layer_factory.hpp:77] Creating layer downsample_4/output_downsample_4/output_0_split
I0316 12:04:36.843969 55708 net.cpp:84] Creating Layer downsample_4/output_downsample_4/output_0_split
I0316 12:04:36.843973 55708 net.cpp:406] downsample_4/output_downsample_4/output_0_split <- downsample_4/output
I0316 12:04:36.843978 55708 net.cpp:380] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_0
I0316 12:04:36.843984 55708 net.cpp:380] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_1
I0316 12:04:36.844010 55708 net.cpp:122] Setting up downsample_4/output_downsample_4/output_0_split
I0316 12:04:36.844017 55708 net.cpp:129] Top shape: 32 160 16 16 (1310720)
I0316 12:04:36.844022 55708 net.cpp:129] Top shape: 32 160 16 16 (1310720)
I0316 12:04:36.844033 55708 net.cpp:137] Memory required for data: 236847232
I0316 12:04:36.844036 55708 layer_factory.hpp:77] Creating layer inception_5a/1x1
I0316 12:04:36.844045 55708 net.cpp:84] Creating Layer inception_5a/1x1
I0316 12:04:36.844048 55708 net.cpp:406] inception_5a/1x1 <- downsample_4/output_downsample_4/output_0_split_0
I0316 12:04:36.844053 55708 net.cpp:380] inception_5a/1x1 -> inception_5a/1x1
I0316 12:04:36.844449 55708 net.cpp:122] Setting up inception_5a/1x1
I0316 12:04:36.844457 55708 net.cpp:129] Top shape: 32 112 16 16 (917504)
I0316 12:04:36.844460 55708 net.cpp:137] Memory required for data: 240517248
I0316 12:04:36.844466 55708 layer_factory.hpp:77] Creating layer inception_5a/1x1/bn1
I0316 12:04:36.844475 55708 net.cpp:84] Creating Layer inception_5a/1x1/bn1
I0316 12:04:36.844478 55708 net.cpp:406] inception_5a/1x1/bn1 <- inception_5a/1x1
I0316 12:04:36.844485 55708 net.cpp:367] inception_5a/1x1/bn1 -> inception_5a/1x1 (in-place)
I0316 12:04:36.844633 55708 net.cpp:122] Setting up inception_5a/1x1/bn1
I0316 12:04:36.844641 55708 net.cpp:129] Top shape: 32 112 16 16 (917504)
I0316 12:04:36.844645 55708 net.cpp:137] Memory required for data: 244187264
I0316 12:04:36.844650 55708 layer_factory.hpp:77] Creating layer inception_5a/1x1/scale1
I0316 12:04:36.844655 55708 net.cpp:84] Creating Layer inception_5a/1x1/scale1
I0316 12:04:36.844660 55708 net.cpp:406] inception_5a/1x1/scale1 <- inception_5a/1x1
I0316 12:04:36.844664 55708 net.cpp:367] inception_5a/1x1/scale1 -> inception_5a/1x1 (in-place)
I0316 12:04:36.844692 55708 layer_factory.hpp:77] Creating layer inception_5a/1x1/scale1
I0316 12:04:36.844784 55708 net.cpp:122] Setting up inception_5a/1x1/scale1
I0316 12:04:36.844792 55708 net.cpp:129] Top shape: 32 112 16 16 (917504)
I0316 12:04:36.844795 55708 net.cpp:137] Memory required for data: 247857280
I0316 12:04:36.844800 55708 layer_factory.hpp:77] Creating layer inception_5a/1x1/relu1
I0316 12:04:36.844805 55708 net.cpp:84] Creating Layer inception_5a/1x1/relu1
I0316 12:04:36.844810 55708 net.cpp:406] inception_5a/1x1/relu1 <- inception_5a/1x1
I0316 12:04:36.844813 55708 net.cpp:367] inception_5a/1x1/relu1 -> inception_5a/1x1 (in-place)
I0316 12:04:36.844818 55708 net.cpp:122] Setting up inception_5a/1x1/relu1
I0316 12:04:36.844822 55708 net.cpp:129] Top shape: 32 112 16 16 (917504)
I0316 12:04:36.844826 55708 net.cpp:137] Memory required for data: 251527296
I0316 12:04:36.844830 55708 layer_factory.hpp:77] Creating layer inception_5a/3x3
I0316 12:04:36.844835 55708 net.cpp:84] Creating Layer inception_5a/3x3
I0316 12:04:36.844839 55708 net.cpp:406] inception_5a/3x3 <- downsample_4/output_downsample_4/output_0_split_1
I0316 12:04:36.844846 55708 net.cpp:380] inception_5a/3x3 -> inception_5a/3x3
I0316 12:04:36.845520 55708 net.cpp:122] Setting up inception_5a/3x3
I0316 12:04:36.845528 55708 net.cpp:129] Top shape: 32 48 16 16 (393216)
I0316 12:04:36.845531 55708 net.cpp:137] Memory required for data: 253100160
I0316 12:04:36.845537 55708 layer_factory.hpp:77] Creating layer inception_5a/3x3/bn1
I0316 12:04:36.845543 55708 net.cpp:84] Creating Layer inception_5a/3x3/bn1
I0316 12:04:36.845546 55708 net.cpp:406] inception_5a/3x3/bn1 <- inception_5a/3x3
I0316 12:04:36.845551 55708 net.cpp:367] inception_5a/3x3/bn1 -> inception_5a/3x3 (in-place)
I0316 12:04:36.845705 55708 net.cpp:122] Setting up inception_5a/3x3/bn1
I0316 12:04:36.845710 55708 net.cpp:129] Top shape: 32 48 16 16 (393216)
I0316 12:04:36.845713 55708 net.cpp:137] Memory required for data: 254673024
I0316 12:04:36.845719 55708 layer_factory.hpp:77] Creating layer inception_5a/3x3/scale1
I0316 12:04:36.845726 55708 net.cpp:84] Creating Layer inception_5a/3x3/scale1
I0316 12:04:36.845729 55708 net.cpp:406] inception_5a/3x3/scale1 <- inception_5a/3x3
I0316 12:04:36.845734 55708 net.cpp:367] inception_5a/3x3/scale1 -> inception_5a/3x3 (in-place)
I0316 12:04:36.845762 55708 layer_factory.hpp:77] Creating layer inception_5a/3x3/scale1
I0316 12:04:36.845850 55708 net.cpp:122] Setting up inception_5a/3x3/scale1
I0316 12:04:36.845870 55708 net.cpp:129] Top shape: 32 48 16 16 (393216)
I0316 12:04:36.845872 55708 net.cpp:137] Memory required for data: 256245888
I0316 12:04:36.845877 55708 layer_factory.hpp:77] Creating layer inception_5a/3x3/relu1
I0316 12:04:36.845882 55708 net.cpp:84] Creating Layer inception_5a/3x3/relu1
I0316 12:04:36.845886 55708 net.cpp:406] inception_5a/3x3/relu1 <- inception_5a/3x3
I0316 12:04:36.845891 55708 net.cpp:367] inception_5a/3x3/relu1 -> inception_5a/3x3 (in-place)
I0316 12:04:36.845896 55708 net.cpp:122] Setting up inception_5a/3x3/relu1
I0316 12:04:36.845901 55708 net.cpp:129] Top shape: 32 48 16 16 (393216)
I0316 12:04:36.845904 55708 net.cpp:137] Memory required for data: 257818752
I0316 12:04:36.845907 55708 layer_factory.hpp:77] Creating layer inception_5a/output
I0316 12:04:36.845911 55708 net.cpp:84] Creating Layer inception_5a/output
I0316 12:04:36.845916 55708 net.cpp:406] inception_5a/output <- inception_5a/1x1
I0316 12:04:36.845919 55708 net.cpp:406] inception_5a/output <- inception_5a/3x3
I0316 12:04:36.845924 55708 net.cpp:380] inception_5a/output -> inception_5a/output
I0316 12:04:36.845938 55708 net.cpp:122] Setting up inception_5a/output
I0316 12:04:36.845944 55708 net.cpp:129] Top shape: 32 160 16 16 (1310720)
I0316 12:04:36.845947 55708 net.cpp:137] Memory required for data: 263061632
I0316 12:04:36.845950 55708 layer_factory.hpp:77] Creating layer inception_5a/output_inception_5a/output_0_split
I0316 12:04:36.845955 55708 net.cpp:84] Creating Layer inception_5a/output_inception_5a/output_0_split
I0316 12:04:36.845959 55708 net.cpp:406] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0316 12:04:36.845964 55708 net.cpp:380] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0316 12:04:36.845970 55708 net.cpp:380] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0316 12:04:36.845994 55708 net.cpp:122] Setting up inception_5a/output_inception_5a/output_0_split
I0316 12:04:36.846000 55708 net.cpp:129] Top shape: 32 160 16 16 (1310720)
I0316 12:04:36.846004 55708 net.cpp:129] Top shape: 32 160 16 16 (1310720)
I0316 12:04:36.846007 55708 net.cpp:137] Memory required for data: 273547392
I0316 12:04:36.846010 55708 layer_factory.hpp:77] Creating layer inception_6a/1x1
I0316 12:04:36.846019 55708 net.cpp:84] Creating Layer inception_6a/1x1
I0316 12:04:36.846022 55708 net.cpp:406] inception_6a/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0316 12:04:36.846027 55708 net.cpp:380] inception_6a/1x1 -> inception_6a/1x1
I0316 12:04:36.846308 55708 net.cpp:122] Setting up inception_6a/1x1
I0316 12:04:36.846316 55708 net.cpp:129] Top shape: 32 96 16 16 (786432)
I0316 12:04:36.846319 55708 net.cpp:137] Memory required for data: 276693120
I0316 12:04:36.846324 55708 layer_factory.hpp:77] Creating layer inception_6a/1x1/bn1
I0316 12:04:36.846330 55708 net.cpp:84] Creating Layer inception_6a/1x1/bn1
I0316 12:04:36.846334 55708 net.cpp:406] inception_6a/1x1/bn1 <- inception_6a/1x1
I0316 12:04:36.846339 55708 net.cpp:367] inception_6a/1x1/bn1 -> inception_6a/1x1 (in-place)
I0316 12:04:36.846525 55708 net.cpp:122] Setting up inception_6a/1x1/bn1
I0316 12:04:36.846534 55708 net.cpp:129] Top shape: 32 96 16 16 (786432)
I0316 12:04:36.846537 55708 net.cpp:137] Memory required for data: 279838848
I0316 12:04:36.846544 55708 layer_factory.hpp:77] Creating layer inception_6a/1x1/scale1
I0316 12:04:36.846549 55708 net.cpp:84] Creating Layer inception_6a/1x1/scale1
I0316 12:04:36.846552 55708 net.cpp:406] inception_6a/1x1/scale1 <- inception_6a/1x1
I0316 12:04:36.846557 55708 net.cpp:367] inception_6a/1x1/scale1 -> inception_6a/1x1 (in-place)
I0316 12:04:36.846587 55708 layer_factory.hpp:77] Creating layer inception_6a/1x1/scale1
I0316 12:04:36.846688 55708 net.cpp:122] Setting up inception_6a/1x1/scale1
I0316 12:04:36.846695 55708 net.cpp:129] Top shape: 32 96 16 16 (786432)
I0316 12:04:36.846699 55708 net.cpp:137] Memory required for data: 282984576
I0316 12:04:36.846714 55708 layer_factory.hpp:77] Creating layer inception_6a/1x1/relu1
I0316 12:04:36.846720 55708 net.cpp:84] Creating Layer inception_6a/1x1/relu1
I0316 12:04:36.846724 55708 net.cpp:406] inception_6a/1x1/relu1 <- inception_6a/1x1
I0316 12:04:36.846729 55708 net.cpp:367] inception_6a/1x1/relu1 -> inception_6a/1x1 (in-place)
I0316 12:04:36.846733 55708 net.cpp:122] Setting up inception_6a/1x1/relu1
I0316 12:04:36.846737 55708 net.cpp:129] Top shape: 32 96 16 16 (786432)
I0316 12:04:36.846740 55708 net.cpp:137] Memory required for data: 286130304
I0316 12:04:36.846745 55708 layer_factory.hpp:77] Creating layer inception_6a/3x3
I0316 12:04:36.846751 55708 net.cpp:84] Creating Layer inception_6a/3x3
I0316 12:04:36.846755 55708 net.cpp:406] inception_6a/3x3 <- inception_5a/output_inception_5a/output_0_split_1
I0316 12:04:36.846760 55708 net.cpp:380] inception_6a/3x3 -> inception_6a/3x3
I0316 12:04:36.847524 55708 net.cpp:122] Setting up inception_6a/3x3
I0316 12:04:36.847532 55708 net.cpp:129] Top shape: 32 64 16 16 (524288)
I0316 12:04:36.847537 55708 net.cpp:137] Memory required for data: 288227456
I0316 12:04:36.847548 55708 layer_factory.hpp:77] Creating layer inception_6a/3x3/bn1
I0316 12:04:36.847555 55708 net.cpp:84] Creating Layer inception_6a/3x3/bn1
I0316 12:04:36.847559 55708 net.cpp:406] inception_6a/3x3/bn1 <- inception_6a/3x3
I0316 12:04:36.847564 55708 net.cpp:367] inception_6a/3x3/bn1 -> inception_6a/3x3 (in-place)
I0316 12:04:36.847735 55708 net.cpp:122] Setting up inception_6a/3x3/bn1
I0316 12:04:36.847743 55708 net.cpp:129] Top shape: 32 64 16 16 (524288)
I0316 12:04:36.847746 55708 net.cpp:137] Memory required for data: 290324608
I0316 12:04:36.847754 55708 layer_factory.hpp:77] Creating layer inception_6a/3x3/scale1
I0316 12:04:36.847760 55708 net.cpp:84] Creating Layer inception_6a/3x3/scale1
I0316 12:04:36.847764 55708 net.cpp:406] inception_6a/3x3/scale1 <- inception_6a/3x3
I0316 12:04:36.847769 55708 net.cpp:367] inception_6a/3x3/scale1 -> inception_6a/3x3 (in-place)
I0316 12:04:36.847800 55708 layer_factory.hpp:77] Creating layer inception_6a/3x3/scale1
I0316 12:04:36.847887 55708 net.cpp:122] Setting up inception_6a/3x3/scale1
I0316 12:04:36.847893 55708 net.cpp:129] Top shape: 32 64 16 16 (524288)
I0316 12:04:36.847896 55708 net.cpp:137] Memory required for data: 292421760
I0316 12:04:36.847901 55708 layer_factory.hpp:77] Creating layer inception_6a/3x3/relu1
I0316 12:04:36.847906 55708 net.cpp:84] Creating Layer inception_6a/3x3/relu1
I0316 12:04:36.847910 55708 net.cpp:406] inception_6a/3x3/relu1 <- inception_6a/3x3
I0316 12:04:36.847914 55708 net.cpp:367] inception_6a/3x3/relu1 -> inception_6a/3x3 (in-place)
I0316 12:04:36.847919 55708 net.cpp:122] Setting up inception_6a/3x3/relu1
I0316 12:04:36.847923 55708 net.cpp:129] Top shape: 32 64 16 16 (524288)
I0316 12:04:36.847927 55708 net.cpp:137] Memory required for data: 294518912
I0316 12:04:36.847929 55708 layer_factory.hpp:77] Creating layer inception_6a/output
I0316 12:04:36.847934 55708 net.cpp:84] Creating Layer inception_6a/output
I0316 12:04:36.847937 55708 net.cpp:406] inception_6a/output <- inception_6a/1x1
I0316 12:04:36.847941 55708 net.cpp:406] inception_6a/output <- inception_6a/3x3
I0316 12:04:36.847946 55708 net.cpp:380] inception_6a/output -> inception_6a/output
I0316 12:04:36.847959 55708 net.cpp:122] Setting up inception_6a/output
I0316 12:04:36.847963 55708 net.cpp:129] Top shape: 32 160 16 16 (1310720)
I0316 12:04:36.847967 55708 net.cpp:137] Memory required for data: 299761792
I0316 12:04:36.847970 55708 layer_factory.hpp:77] Creating layer inception_6a/output_inception_6a/output_0_split
I0316 12:04:36.847975 55708 net.cpp:84] Creating Layer inception_6a/output_inception_6a/output_0_split
I0316 12:04:36.847978 55708 net.cpp:406] inception_6a/output_inception_6a/output_0_split <- inception_6a/output
I0316 12:04:36.847983 55708 net.cpp:380] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_0
I0316 12:04:36.847990 55708 net.cpp:380] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_1
I0316 12:04:36.848024 55708 net.cpp:122] Setting up inception_6a/output_inception_6a/output_0_split
I0316 12:04:36.848032 55708 net.cpp:129] Top shape: 32 160 16 16 (1310720)
I0316 12:04:36.848037 55708 net.cpp:129] Top shape: 32 160 16 16 (1310720)
I0316 12:04:36.848039 55708 net.cpp:137] Memory required for data: 310247552
I0316 12:04:36.848042 55708 layer_factory.hpp:77] Creating layer inception_7a/1x1
I0316 12:04:36.848050 55708 net.cpp:84] Creating Layer inception_7a/1x1
I0316 12:04:36.848054 55708 net.cpp:406] inception_7a/1x1 <- inception_6a/output_inception_6a/output_0_split_0
I0316 12:04:36.848059 55708 net.cpp:380] inception_7a/1x1 -> inception_7a/1x1
I0316 12:04:36.848322 55708 net.cpp:122] Setting up inception_7a/1x1
I0316 12:04:36.848328 55708 net.cpp:129] Top shape: 32 80 16 16 (655360)
I0316 12:04:36.848332 55708 net.cpp:137] Memory required for data: 312868992
I0316 12:04:36.848337 55708 layer_factory.hpp:77] Creating layer inception_7a/1x1/bn1
I0316 12:04:36.848342 55708 net.cpp:84] Creating Layer inception_7a/1x1/bn1
I0316 12:04:36.848346 55708 net.cpp:406] inception_7a/1x1/bn1 <- inception_7a/1x1
I0316 12:04:36.848351 55708 net.cpp:367] inception_7a/1x1/bn1 -> inception_7a/1x1 (in-place)
I0316 12:04:36.848522 55708 net.cpp:122] Setting up inception_7a/1x1/bn1
I0316 12:04:36.848536 55708 net.cpp:129] Top shape: 32 80 16 16 (655360)
I0316 12:04:36.848541 55708 net.cpp:137] Memory required for data: 315490432
I0316 12:04:36.848551 55708 layer_factory.hpp:77] Creating layer inception_7a/1x1/scale1
I0316 12:04:36.848557 55708 net.cpp:84] Creating Layer inception_7a/1x1/scale1
I0316 12:04:36.848562 55708 net.cpp:406] inception_7a/1x1/scale1 <- inception_7a/1x1
I0316 12:04:36.848568 55708 net.cpp:367] inception_7a/1x1/scale1 -> inception_7a/1x1 (in-place)
I0316 12:04:36.848723 55708 layer_factory.hpp:77] Creating layer inception_7a/1x1/scale1
I0316 12:04:36.848815 55708 net.cpp:122] Setting up inception_7a/1x1/scale1
I0316 12:04:36.848824 55708 net.cpp:129] Top shape: 32 80 16 16 (655360)
I0316 12:04:36.848827 55708 net.cpp:137] Memory required for data: 318111872
I0316 12:04:36.848834 55708 layer_factory.hpp:77] Creating layer inception_7a/1x1/relu1
I0316 12:04:36.848839 55708 net.cpp:84] Creating Layer inception_7a/1x1/relu1
I0316 12:04:36.848842 55708 net.cpp:406] inception_7a/1x1/relu1 <- inception_7a/1x1
I0316 12:04:36.848846 55708 net.cpp:367] inception_7a/1x1/relu1 -> inception_7a/1x1 (in-place)
I0316 12:04:36.848852 55708 net.cpp:122] Setting up inception_7a/1x1/relu1
I0316 12:04:36.848856 55708 net.cpp:129] Top shape: 32 80 16 16 (655360)
I0316 12:04:36.848860 55708 net.cpp:137] Memory required for data: 320733312
I0316 12:04:36.848862 55708 layer_factory.hpp:77] Creating layer inception_7a/3x3
I0316 12:04:36.848870 55708 net.cpp:84] Creating Layer inception_7a/3x3
I0316 12:04:36.848873 55708 net.cpp:406] inception_7a/3x3 <- inception_6a/output_inception_6a/output_0_split_1
I0316 12:04:36.848878 55708 net.cpp:380] inception_7a/3x3 -> inception_7a/3x3
I0316 12:04:36.849786 55708 net.cpp:122] Setting up inception_7a/3x3
I0316 12:04:36.849794 55708 net.cpp:129] Top shape: 32 80 16 16 (655360)
I0316 12:04:36.849798 55708 net.cpp:137] Memory required for data: 323354752
I0316 12:04:36.849813 55708 layer_factory.hpp:77] Creating layer inception_7a/3x3/bn1
I0316 12:04:36.849819 55708 net.cpp:84] Creating Layer inception_7a/3x3/bn1
I0316 12:04:36.849824 55708 net.cpp:406] inception_7a/3x3/bn1 <- inception_7a/3x3
I0316 12:04:36.849828 55708 net.cpp:367] inception_7a/3x3/bn1 -> inception_7a/3x3 (in-place)
I0316 12:04:36.849980 55708 net.cpp:122] Setting up inception_7a/3x3/bn1
I0316 12:04:36.849987 55708 net.cpp:129] Top shape: 32 80 16 16 (655360)
I0316 12:04:36.849992 55708 net.cpp:137] Memory required for data: 325976192
I0316 12:04:36.849998 55708 layer_factory.hpp:77] Creating layer inception_7a/3x3/scale1
I0316 12:04:36.850003 55708 net.cpp:84] Creating Layer inception_7a/3x3/scale1
I0316 12:04:36.850005 55708 net.cpp:406] inception_7a/3x3/scale1 <- inception_7a/3x3
I0316 12:04:36.850028 55708 net.cpp:367] inception_7a/3x3/scale1 -> inception_7a/3x3 (in-place)
I0316 12:04:36.850056 55708 layer_factory.hpp:77] Creating layer inception_7a/3x3/scale1
I0316 12:04:36.850145 55708 net.cpp:122] Setting up inception_7a/3x3/scale1
I0316 12:04:36.850152 55708 net.cpp:129] Top shape: 32 80 16 16 (655360)
I0316 12:04:36.850157 55708 net.cpp:137] Memory required for data: 328597632
I0316 12:04:36.850162 55708 layer_factory.hpp:77] Creating layer inception_7a/3x3/relu1
I0316 12:04:36.850167 55708 net.cpp:84] Creating Layer inception_7a/3x3/relu1
I0316 12:04:36.850169 55708 net.cpp:406] inception_7a/3x3/relu1 <- inception_7a/3x3
I0316 12:04:36.850175 55708 net.cpp:367] inception_7a/3x3/relu1 -> inception_7a/3x3 (in-place)
I0316 12:04:36.850179 55708 net.cpp:122] Setting up inception_7a/3x3/relu1
I0316 12:04:36.850183 55708 net.cpp:129] Top shape: 32 80 16 16 (655360)
I0316 12:04:36.850188 55708 net.cpp:137] Memory required for data: 331219072
I0316 12:04:36.850191 55708 layer_factory.hpp:77] Creating layer inception_7a/output
I0316 12:04:36.850195 55708 net.cpp:84] Creating Layer inception_7a/output
I0316 12:04:36.850198 55708 net.cpp:406] inception_7a/output <- inception_7a/1x1
I0316 12:04:36.850203 55708 net.cpp:406] inception_7a/output <- inception_7a/3x3
I0316 12:04:36.850208 55708 net.cpp:380] inception_7a/output -> inception_7a/output
I0316 12:04:36.850239 55708 net.cpp:122] Setting up inception_7a/output
I0316 12:04:36.850243 55708 net.cpp:129] Top shape: 32 160 16 16 (1310720)
I0316 12:04:36.850246 55708 net.cpp:137] Memory required for data: 336461952
I0316 12:04:36.850252 55708 layer_factory.hpp:77] Creating layer inception_7a/output_inception_7a/output_0_split
I0316 12:04:36.850257 55708 net.cpp:84] Creating Layer inception_7a/output_inception_7a/output_0_split
I0316 12:04:36.850261 55708 net.cpp:406] inception_7a/output_inception_7a/output_0_split <- inception_7a/output
I0316 12:04:36.850265 55708 net.cpp:380] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_0
I0316 12:04:36.850272 55708 net.cpp:380] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_1
I0316 12:04:36.850297 55708 net.cpp:122] Setting up inception_7a/output_inception_7a/output_0_split
I0316 12:04:36.850306 55708 net.cpp:129] Top shape: 32 160 16 16 (1310720)
I0316 12:04:36.850309 55708 net.cpp:129] Top shape: 32 160 16 16 (1310720)
I0316 12:04:36.850313 55708 net.cpp:137] Memory required for data: 346947712
I0316 12:04:36.850317 55708 layer_factory.hpp:77] Creating layer inception_8a/1x1
I0316 12:04:36.850322 55708 net.cpp:84] Creating Layer inception_8a/1x1
I0316 12:04:36.850325 55708 net.cpp:406] inception_8a/1x1 <- inception_7a/output_inception_7a/output_0_split_0
I0316 12:04:36.850332 55708 net.cpp:380] inception_8a/1x1 -> inception_8a/1x1
I0316 12:04:36.850562 55708 net.cpp:122] Setting up inception_8a/1x1
I0316 12:04:36.850569 55708 net.cpp:129] Top shape: 32 48 16 16 (393216)
I0316 12:04:36.850571 55708 net.cpp:137] Memory required for data: 348520576
I0316 12:04:36.850577 55708 layer_factory.hpp:77] Creating layer inception_8a/1x1/bn1
I0316 12:04:36.850592 55708 net.cpp:84] Creating Layer inception_8a/1x1/bn1
I0316 12:04:36.850596 55708 net.cpp:406] inception_8a/1x1/bn1 <- inception_8a/1x1
I0316 12:04:36.850601 55708 net.cpp:367] inception_8a/1x1/bn1 -> inception_8a/1x1 (in-place)
I0316 12:04:36.850751 55708 net.cpp:122] Setting up inception_8a/1x1/bn1
I0316 12:04:36.850759 55708 net.cpp:129] Top shape: 32 48 16 16 (393216)
I0316 12:04:36.850761 55708 net.cpp:137] Memory required for data: 350093440
I0316 12:04:36.850767 55708 layer_factory.hpp:77] Creating layer inception_8a/1x1/scale1
I0316 12:04:36.850772 55708 net.cpp:84] Creating Layer inception_8a/1x1/scale1
I0316 12:04:36.850775 55708 net.cpp:406] inception_8a/1x1/scale1 <- inception_8a/1x1
I0316 12:04:36.850780 55708 net.cpp:367] inception_8a/1x1/scale1 -> inception_8a/1x1 (in-place)
I0316 12:04:36.850806 55708 layer_factory.hpp:77] Creating layer inception_8a/1x1/scale1
I0316 12:04:36.850901 55708 net.cpp:122] Setting up inception_8a/1x1/scale1
I0316 12:04:36.850908 55708 net.cpp:129] Top shape: 32 48 16 16 (393216)
I0316 12:04:36.850912 55708 net.cpp:137] Memory required for data: 351666304
I0316 12:04:36.850919 55708 layer_factory.hpp:77] Creating layer inception_8a/1x1/relu1
I0316 12:04:36.850925 55708 net.cpp:84] Creating Layer inception_8a/1x1/relu1
I0316 12:04:36.850929 55708 net.cpp:406] inception_8a/1x1/relu1 <- inception_8a/1x1
I0316 12:04:36.850932 55708 net.cpp:367] inception_8a/1x1/relu1 -> inception_8a/1x1 (in-place)
I0316 12:04:36.850937 55708 net.cpp:122] Setting up inception_8a/1x1/relu1
I0316 12:04:36.850942 55708 net.cpp:129] Top shape: 32 48 16 16 (393216)
I0316 12:04:36.850945 55708 net.cpp:137] Memory required for data: 353239168
I0316 12:04:36.850948 55708 layer_factory.hpp:77] Creating layer inception_8a/3x3
I0316 12:04:36.850955 55708 net.cpp:84] Creating Layer inception_8a/3x3
I0316 12:04:36.850958 55708 net.cpp:406] inception_8a/3x3 <- inception_7a/output_inception_7a/output_0_split_1
I0316 12:04:36.850963 55708 net.cpp:380] inception_8a/3x3 -> inception_8a/3x3
I0316 12:04:36.853360 55708 net.cpp:122] Setting up inception_8a/3x3
I0316 12:04:36.853377 55708 net.cpp:129] Top shape: 32 96 16 16 (786432)
I0316 12:04:36.853381 55708 net.cpp:137] Memory required for data: 356384896
I0316 12:04:36.853389 55708 layer_factory.hpp:77] Creating layer inception_8a/3x3/bn1
I0316 12:04:36.853395 55708 net.cpp:84] Creating Layer inception_8a/3x3/bn1
I0316 12:04:36.853399 55708 net.cpp:406] inception_8a/3x3/bn1 <- inception_8a/3x3
I0316 12:04:36.853406 55708 net.cpp:367] inception_8a/3x3/bn1 -> inception_8a/3x3 (in-place)
I0316 12:04:36.853569 55708 net.cpp:122] Setting up inception_8a/3x3/bn1
I0316 12:04:36.853576 55708 net.cpp:129] Top shape: 32 96 16 16 (786432)
I0316 12:04:36.853579 55708 net.cpp:137] Memory required for data: 359530624
I0316 12:04:36.853586 55708 layer_factory.hpp:77] Creating layer inception_8a/3x3/scale1
I0316 12:04:36.853591 55708 net.cpp:84] Creating Layer inception_8a/3x3/scale1
I0316 12:04:36.853595 55708 net.cpp:406] inception_8a/3x3/scale1 <- inception_8a/3x3
I0316 12:04:36.853600 55708 net.cpp:367] inception_8a/3x3/scale1 -> inception_8a/3x3 (in-place)
I0316 12:04:36.853629 55708 layer_factory.hpp:77] Creating layer inception_8a/3x3/scale1
I0316 12:04:36.853720 55708 net.cpp:122] Setting up inception_8a/3x3/scale1
I0316 12:04:36.853726 55708 net.cpp:129] Top shape: 32 96 16 16 (786432)
I0316 12:04:36.853729 55708 net.cpp:137] Memory required for data: 362676352
I0316 12:04:36.853735 55708 layer_factory.hpp:77] Creating layer inception_8a/3x3/relu1
I0316 12:04:36.853739 55708 net.cpp:84] Creating Layer inception_8a/3x3/relu1
I0316 12:04:36.853742 55708 net.cpp:406] inception_8a/3x3/relu1 <- inception_8a/3x3
I0316 12:04:36.853746 55708 net.cpp:367] inception_8a/3x3/relu1 -> inception_8a/3x3 (in-place)
I0316 12:04:36.853752 55708 net.cpp:122] Setting up inception_8a/3x3/relu1
I0316 12:04:36.853756 55708 net.cpp:129] Top shape: 32 96 16 16 (786432)
I0316 12:04:36.853760 55708 net.cpp:137] Memory required for data: 365822080
I0316 12:04:36.853762 55708 layer_factory.hpp:77] Creating layer inception_8a/output
I0316 12:04:36.853767 55708 net.cpp:84] Creating Layer inception_8a/output
I0316 12:04:36.853771 55708 net.cpp:406] inception_8a/output <- inception_8a/1x1
I0316 12:04:36.853775 55708 net.cpp:406] inception_8a/output <- inception_8a/3x3
I0316 12:04:36.853780 55708 net.cpp:380] inception_8a/output -> inception_8a/output
I0316 12:04:36.853794 55708 net.cpp:122] Setting up inception_8a/output
I0316 12:04:36.853798 55708 net.cpp:129] Top shape: 32 144 16 16 (1179648)
I0316 12:04:36.853801 55708 net.cpp:137] Memory required for data: 370540672
I0316 12:04:36.853804 55708 layer_factory.hpp:77] Creating layer inception_8a/output_inception_8a/output_0_split
I0316 12:04:36.853811 55708 net.cpp:84] Creating Layer inception_8a/output_inception_8a/output_0_split
I0316 12:04:36.853813 55708 net.cpp:406] inception_8a/output_inception_8a/output_0_split <- inception_8a/output
I0316 12:04:36.853830 55708 net.cpp:380] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_0
I0316 12:04:36.853837 55708 net.cpp:380] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_1
I0316 12:04:36.853863 55708 net.cpp:122] Setting up inception_8a/output_inception_8a/output_0_split
I0316 12:04:36.853871 55708 net.cpp:129] Top shape: 32 144 16 16 (1179648)
I0316 12:04:36.853875 55708 net.cpp:129] Top shape: 32 144 16 16 (1179648)
I0316 12:04:36.853878 55708 net.cpp:137] Memory required for data: 379977856
I0316 12:04:36.853883 55708 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2
I0316 12:04:36.853890 55708 net.cpp:84] Creating Layer downsample_9/3x3_s2
I0316 12:04:36.853893 55708 net.cpp:406] downsample_9/3x3_s2 <- inception_8a/output_inception_8a/output_0_split_0
I0316 12:04:36.853899 55708 net.cpp:380] downsample_9/3x3_s2 -> downsample_9/3x3_s2
I0316 12:04:36.854890 55708 net.cpp:122] Setting up downsample_9/3x3_s2
I0316 12:04:36.854899 55708 net.cpp:129] Top shape: 32 96 8 8 (196608)
I0316 12:04:36.854903 55708 net.cpp:137] Memory required for data: 380764288
I0316 12:04:36.854908 55708 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/bn1
I0316 12:04:36.854915 55708 net.cpp:84] Creating Layer downsample_9/3x3_s2/bn1
I0316 12:04:36.854918 55708 net.cpp:406] downsample_9/3x3_s2/bn1 <- downsample_9/3x3_s2
I0316 12:04:36.854924 55708 net.cpp:367] downsample_9/3x3_s2/bn1 -> downsample_9/3x3_s2 (in-place)
I0316 12:04:36.855087 55708 net.cpp:122] Setting up downsample_9/3x3_s2/bn1
I0316 12:04:36.855094 55708 net.cpp:129] Top shape: 32 96 8 8 (196608)
I0316 12:04:36.855098 55708 net.cpp:137] Memory required for data: 381550720
I0316 12:04:36.855103 55708 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/scale1
I0316 12:04:36.855108 55708 net.cpp:84] Creating Layer downsample_9/3x3_s2/scale1
I0316 12:04:36.855113 55708 net.cpp:406] downsample_9/3x3_s2/scale1 <- downsample_9/3x3_s2
I0316 12:04:36.855116 55708 net.cpp:367] downsample_9/3x3_s2/scale1 -> downsample_9/3x3_s2 (in-place)
I0316 12:04:36.855145 55708 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/scale1
I0316 12:04:36.855239 55708 net.cpp:122] Setting up downsample_9/3x3_s2/scale1
I0316 12:04:36.855247 55708 net.cpp:129] Top shape: 32 96 8 8 (196608)
I0316 12:04:36.855249 55708 net.cpp:137] Memory required for data: 382337152
I0316 12:04:36.855254 55708 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/relu1
I0316 12:04:36.855259 55708 net.cpp:84] Creating Layer downsample_9/3x3_s2/relu1
I0316 12:04:36.855263 55708 net.cpp:406] downsample_9/3x3_s2/relu1 <- downsample_9/3x3_s2
I0316 12:04:36.855268 55708 net.cpp:367] downsample_9/3x3_s2/relu1 -> downsample_9/3x3_s2 (in-place)
I0316 12:04:36.855273 55708 net.cpp:122] Setting up downsample_9/3x3_s2/relu1
I0316 12:04:36.855278 55708 net.cpp:129] Top shape: 32 96 8 8 (196608)
I0316 12:04:36.855280 55708 net.cpp:137] Memory required for data: 383123584
I0316 12:04:36.855283 55708 layer_factory.hpp:77] Creating layer downsample_9/pool_s2
I0316 12:04:36.855288 55708 net.cpp:84] Creating Layer downsample_9/pool_s2
I0316 12:04:36.855293 55708 net.cpp:406] downsample_9/pool_s2 <- inception_8a/output_inception_8a/output_0_split_1
I0316 12:04:36.855298 55708 net.cpp:380] downsample_9/pool_s2 -> downsample_9/pool_s2
I0316 12:04:36.855326 55708 net.cpp:122] Setting up downsample_9/pool_s2
I0316 12:04:36.855331 55708 net.cpp:129] Top shape: 32 144 8 8 (294912)
I0316 12:04:36.855334 55708 net.cpp:137] Memory required for data: 384303232
I0316 12:04:36.855338 55708 layer_factory.hpp:77] Creating layer downsample_9/output
I0316 12:04:36.855342 55708 net.cpp:84] Creating Layer downsample_9/output
I0316 12:04:36.855345 55708 net.cpp:406] downsample_9/output <- downsample_9/3x3_s2
I0316 12:04:36.855350 55708 net.cpp:406] downsample_9/output <- downsample_9/pool_s2
I0316 12:04:36.855355 55708 net.cpp:380] downsample_9/output -> downsample_9/output
I0316 12:04:36.855389 55708 net.cpp:122] Setting up downsample_9/output
I0316 12:04:36.855393 55708 net.cpp:129] Top shape: 32 240 8 8 (491520)
I0316 12:04:36.855396 55708 net.cpp:137] Memory required for data: 386269312
I0316 12:04:36.855401 55708 layer_factory.hpp:77] Creating layer downsample_9/output_downsample_9/output_0_split
I0316 12:04:36.855405 55708 net.cpp:84] Creating Layer downsample_9/output_downsample_9/output_0_split
I0316 12:04:36.855408 55708 net.cpp:406] downsample_9/output_downsample_9/output_0_split <- downsample_9/output
I0316 12:04:36.855412 55708 net.cpp:380] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_0
I0316 12:04:36.855419 55708 net.cpp:380] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_1
I0316 12:04:36.855444 55708 net.cpp:122] Setting up downsample_9/output_downsample_9/output_0_split
I0316 12:04:36.855451 55708 net.cpp:129] Top shape: 32 240 8 8 (491520)
I0316 12:04:36.855455 55708 net.cpp:129] Top shape: 32 240 8 8 (491520)
I0316 12:04:36.855459 55708 net.cpp:137] Memory required for data: 390201472
I0316 12:04:36.855463 55708 layer_factory.hpp:77] Creating layer inception_10a/1x1
I0316 12:04:36.855469 55708 net.cpp:84] Creating Layer inception_10a/1x1
I0316 12:04:36.855473 55708 net.cpp:406] inception_10a/1x1 <- downsample_9/output_downsample_9/output_0_split_0
I0316 12:04:36.855479 55708 net.cpp:380] inception_10a/1x1 -> inception_10a/1x1
I0316 12:04:36.855927 55708 net.cpp:122] Setting up inception_10a/1x1
I0316 12:04:36.855933 55708 net.cpp:129] Top shape: 32 176 8 8 (360448)
I0316 12:04:36.855937 55708 net.cpp:137] Memory required for data: 391643264
I0316 12:04:36.855942 55708 layer_factory.hpp:77] Creating layer inception_10a/1x1/bn1
I0316 12:04:36.855952 55708 net.cpp:84] Creating Layer inception_10a/1x1/bn1
I0316 12:04:36.855955 55708 net.cpp:406] inception_10a/1x1/bn1 <- inception_10a/1x1
I0316 12:04:36.855960 55708 net.cpp:367] inception_10a/1x1/bn1 -> inception_10a/1x1 (in-place)
I0316 12:04:36.856123 55708 net.cpp:122] Setting up inception_10a/1x1/bn1
I0316 12:04:36.856130 55708 net.cpp:129] Top shape: 32 176 8 8 (360448)
I0316 12:04:36.856132 55708 net.cpp:137] Memory required for data: 393085056
I0316 12:04:36.856139 55708 layer_factory.hpp:77] Creating layer inception_10a/1x1/scale1
I0316 12:04:36.856144 55708 net.cpp:84] Creating Layer inception_10a/1x1/scale1
I0316 12:04:36.856148 55708 net.cpp:406] inception_10a/1x1/scale1 <- inception_10a/1x1
I0316 12:04:36.856151 55708 net.cpp:367] inception_10a/1x1/scale1 -> inception_10a/1x1 (in-place)
I0316 12:04:36.856179 55708 layer_factory.hpp:77] Creating layer inception_10a/1x1/scale1
I0316 12:04:36.856274 55708 net.cpp:122] Setting up inception_10a/1x1/scale1
I0316 12:04:36.856281 55708 net.cpp:129] Top shape: 32 176 8 8 (360448)
I0316 12:04:36.856283 55708 net.cpp:137] Memory required for data: 394526848
I0316 12:04:36.856288 55708 layer_factory.hpp:77] Creating layer inception_10a/1x1/relu1
I0316 12:04:36.856294 55708 net.cpp:84] Creating Layer inception_10a/1x1/relu1
I0316 12:04:36.856297 55708 net.cpp:406] inception_10a/1x1/relu1 <- inception_10a/1x1
I0316 12:04:36.856302 55708 net.cpp:367] inception_10a/1x1/relu1 -> inception_10a/1x1 (in-place)
I0316 12:04:36.856305 55708 net.cpp:122] Setting up inception_10a/1x1/relu1
I0316 12:04:36.856310 55708 net.cpp:129] Top shape: 32 176 8 8 (360448)
I0316 12:04:36.856313 55708 net.cpp:137] Memory required for data: 395968640
I0316 12:04:36.856317 55708 layer_factory.hpp:77] Creating layer inception_10a/3x3
I0316 12:04:36.856323 55708 net.cpp:84] Creating Layer inception_10a/3x3
I0316 12:04:36.856328 55708 net.cpp:406] inception_10a/3x3 <- downsample_9/output_downsample_9/output_0_split_1
I0316 12:04:36.856333 55708 net.cpp:380] inception_10a/3x3 -> inception_10a/3x3
I0316 12:04:36.859901 55708 net.cpp:122] Setting up inception_10a/3x3
I0316 12:04:36.859918 55708 net.cpp:129] Top shape: 32 160 8 8 (327680)
I0316 12:04:36.859922 55708 net.cpp:137] Memory required for data: 397279360
I0316 12:04:36.859946 55708 layer_factory.hpp:77] Creating layer inception_10a/3x3/bn1
I0316 12:04:36.859954 55708 net.cpp:84] Creating Layer inception_10a/3x3/bn1
I0316 12:04:36.859958 55708 net.cpp:406] inception_10a/3x3/bn1 <- inception_10a/3x3
I0316 12:04:36.859964 55708 net.cpp:367] inception_10a/3x3/bn1 -> inception_10a/3x3 (in-place)
I0316 12:04:36.860129 55708 net.cpp:122] Setting up inception_10a/3x3/bn1
I0316 12:04:36.860136 55708 net.cpp:129] Top shape: 32 160 8 8 (327680)
I0316 12:04:36.860141 55708 net.cpp:137] Memory required for data: 398590080
I0316 12:04:36.860147 55708 layer_factory.hpp:77] Creating layer inception_10a/3x3/scale1
I0316 12:04:36.860152 55708 net.cpp:84] Creating Layer inception_10a/3x3/scale1
I0316 12:04:36.860157 55708 net.cpp:406] inception_10a/3x3/scale1 <- inception_10a/3x3
I0316 12:04:36.860160 55708 net.cpp:367] inception_10a/3x3/scale1 -> inception_10a/3x3 (in-place)
I0316 12:04:36.860190 55708 layer_factory.hpp:77] Creating layer inception_10a/3x3/scale1
I0316 12:04:36.860285 55708 net.cpp:122] Setting up inception_10a/3x3/scale1
I0316 12:04:36.860292 55708 net.cpp:129] Top shape: 32 160 8 8 (327680)
I0316 12:04:36.860296 55708 net.cpp:137] Memory required for data: 399900800
I0316 12:04:36.860302 55708 layer_factory.hpp:77] Creating layer inception_10a/3x3/relu1
I0316 12:04:36.860307 55708 net.cpp:84] Creating Layer inception_10a/3x3/relu1
I0316 12:04:36.860311 55708 net.cpp:406] inception_10a/3x3/relu1 <- inception_10a/3x3
I0316 12:04:36.860314 55708 net.cpp:367] inception_10a/3x3/relu1 -> inception_10a/3x3 (in-place)
I0316 12:04:36.860320 55708 net.cpp:122] Setting up inception_10a/3x3/relu1
I0316 12:04:36.860325 55708 net.cpp:129] Top shape: 32 160 8 8 (327680)
I0316 12:04:36.860327 55708 net.cpp:137] Memory required for data: 401211520
I0316 12:04:36.860330 55708 layer_factory.hpp:77] Creating layer inception_10a/output
I0316 12:04:36.860335 55708 net.cpp:84] Creating Layer inception_10a/output
I0316 12:04:36.860338 55708 net.cpp:406] inception_10a/output <- inception_10a/1x1
I0316 12:04:36.860342 55708 net.cpp:406] inception_10a/output <- inception_10a/3x3
I0316 12:04:36.860347 55708 net.cpp:380] inception_10a/output -> inception_10a/output
I0316 12:04:36.860374 55708 net.cpp:122] Setting up inception_10a/output
I0316 12:04:36.860379 55708 net.cpp:129] Top shape: 32 336 8 8 (688128)
I0316 12:04:36.860383 55708 net.cpp:137] Memory required for data: 403964032
I0316 12:04:36.860385 55708 layer_factory.hpp:77] Creating layer inception_10a/output_inception_10a/output_0_split
I0316 12:04:36.860391 55708 net.cpp:84] Creating Layer inception_10a/output_inception_10a/output_0_split
I0316 12:04:36.860394 55708 net.cpp:406] inception_10a/output_inception_10a/output_0_split <- inception_10a/output
I0316 12:04:36.860399 55708 net.cpp:380] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_0
I0316 12:04:36.860404 55708 net.cpp:380] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_1
I0316 12:04:36.860432 55708 net.cpp:122] Setting up inception_10a/output_inception_10a/output_0_split
I0316 12:04:36.860437 55708 net.cpp:129] Top shape: 32 336 8 8 (688128)
I0316 12:04:36.860440 55708 net.cpp:129] Top shape: 32 336 8 8 (688128)
I0316 12:04:36.860443 55708 net.cpp:137] Memory required for data: 409469056
I0316 12:04:36.860447 55708 layer_factory.hpp:77] Creating layer inception_11a/1x1
I0316 12:04:36.860455 55708 net.cpp:84] Creating Layer inception_11a/1x1
I0316 12:04:36.860460 55708 net.cpp:406] inception_11a/1x1 <- inception_10a/output_inception_10a/output_0_split_0
I0316 12:04:36.860464 55708 net.cpp:380] inception_11a/1x1 -> inception_11a/1x1
I0316 12:04:36.861023 55708 net.cpp:122] Setting up inception_11a/1x1
I0316 12:04:36.861032 55708 net.cpp:129] Top shape: 32 176 8 8 (360448)
I0316 12:04:36.861034 55708 net.cpp:137] Memory required for data: 410910848
I0316 12:04:36.861039 55708 layer_factory.hpp:77] Creating layer inception_11a/1x1/bn1
I0316 12:04:36.861047 55708 net.cpp:84] Creating Layer inception_11a/1x1/bn1
I0316 12:04:36.861059 55708 net.cpp:406] inception_11a/1x1/bn1 <- inception_11a/1x1
I0316 12:04:36.861064 55708 net.cpp:367] inception_11a/1x1/bn1 -> inception_11a/1x1 (in-place)
I0316 12:04:36.861224 55708 net.cpp:122] Setting up inception_11a/1x1/bn1
I0316 12:04:36.861232 55708 net.cpp:129] Top shape: 32 176 8 8 (360448)
I0316 12:04:36.861234 55708 net.cpp:137] Memory required for data: 412352640
I0316 12:04:36.861243 55708 layer_factory.hpp:77] Creating layer inception_11a/1x1/scale1
I0316 12:04:36.861248 55708 net.cpp:84] Creating Layer inception_11a/1x1/scale1
I0316 12:04:36.861251 55708 net.cpp:406] inception_11a/1x1/scale1 <- inception_11a/1x1
I0316 12:04:36.861256 55708 net.cpp:367] inception_11a/1x1/scale1 -> inception_11a/1x1 (in-place)
I0316 12:04:36.861284 55708 layer_factory.hpp:77] Creating layer inception_11a/1x1/scale1
I0316 12:04:36.861377 55708 net.cpp:122] Setting up inception_11a/1x1/scale1
I0316 12:04:36.861384 55708 net.cpp:129] Top shape: 32 176 8 8 (360448)
I0316 12:04:36.861387 55708 net.cpp:137] Memory required for data: 413794432
I0316 12:04:36.861392 55708 layer_factory.hpp:77] Creating layer inception_11a/1x1/relu1
I0316 12:04:36.861397 55708 net.cpp:84] Creating Layer inception_11a/1x1/relu1
I0316 12:04:36.861402 55708 net.cpp:406] inception_11a/1x1/relu1 <- inception_11a/1x1
I0316 12:04:36.861405 55708 net.cpp:367] inception_11a/1x1/relu1 -> inception_11a/1x1 (in-place)
I0316 12:04:36.861410 55708 net.cpp:122] Setting up inception_11a/1x1/relu1
I0316 12:04:36.861414 55708 net.cpp:129] Top shape: 32 176 8 8 (360448)
I0316 12:04:36.861418 55708 net.cpp:137] Memory required for data: 415236224
I0316 12:04:36.861420 55708 layer_factory.hpp:77] Creating layer inception_11a/3x3
I0316 12:04:36.861426 55708 net.cpp:84] Creating Layer inception_11a/3x3
I0316 12:04:36.861430 55708 net.cpp:406] inception_11a/3x3 <- inception_10a/output_inception_10a/output_0_split_1
I0316 12:04:36.861436 55708 net.cpp:380] inception_11a/3x3 -> inception_11a/3x3
I0316 12:04:36.865957 55708 net.cpp:122] Setting up inception_11a/3x3
I0316 12:04:36.865972 55708 net.cpp:129] Top shape: 32 160 8 8 (327680)
I0316 12:04:36.865975 55708 net.cpp:137] Memory required for data: 416546944
I0316 12:04:36.865983 55708 layer_factory.hpp:77] Creating layer inception_11a/3x3/bn1
I0316 12:04:36.865990 55708 net.cpp:84] Creating Layer inception_11a/3x3/bn1
I0316 12:04:36.865994 55708 net.cpp:406] inception_11a/3x3/bn1 <- inception_11a/3x3
I0316 12:04:36.866000 55708 net.cpp:367] inception_11a/3x3/bn1 -> inception_11a/3x3 (in-place)
I0316 12:04:36.866166 55708 net.cpp:122] Setting up inception_11a/3x3/bn1
I0316 12:04:36.866173 55708 net.cpp:129] Top shape: 32 160 8 8 (327680)
I0316 12:04:36.866176 55708 net.cpp:137] Memory required for data: 417857664
I0316 12:04:36.866194 55708 layer_factory.hpp:77] Creating layer inception_11a/3x3/scale1
I0316 12:04:36.866201 55708 net.cpp:84] Creating Layer inception_11a/3x3/scale1
I0316 12:04:36.866204 55708 net.cpp:406] inception_11a/3x3/scale1 <- inception_11a/3x3
I0316 12:04:36.866209 55708 net.cpp:367] inception_11a/3x3/scale1 -> inception_11a/3x3 (in-place)
I0316 12:04:36.866237 55708 layer_factory.hpp:77] Creating layer inception_11a/3x3/scale1
I0316 12:04:36.866341 55708 net.cpp:122] Setting up inception_11a/3x3/scale1
I0316 12:04:36.866348 55708 net.cpp:129] Top shape: 32 160 8 8 (327680)
I0316 12:04:36.866350 55708 net.cpp:137] Memory required for data: 419168384
I0316 12:04:36.866356 55708 layer_factory.hpp:77] Creating layer inception_11a/3x3/relu1
I0316 12:04:36.866361 55708 net.cpp:84] Creating Layer inception_11a/3x3/relu1
I0316 12:04:36.866364 55708 net.cpp:406] inception_11a/3x3/relu1 <- inception_11a/3x3
I0316 12:04:36.866369 55708 net.cpp:367] inception_11a/3x3/relu1 -> inception_11a/3x3 (in-place)
I0316 12:04:36.866374 55708 net.cpp:122] Setting up inception_11a/3x3/relu1
I0316 12:04:36.866377 55708 net.cpp:129] Top shape: 32 160 8 8 (327680)
I0316 12:04:36.866380 55708 net.cpp:137] Memory required for data: 420479104
I0316 12:04:36.866402 55708 layer_factory.hpp:77] Creating layer inception_11a/output
I0316 12:04:36.866407 55708 net.cpp:84] Creating Layer inception_11a/output
I0316 12:04:36.866411 55708 net.cpp:406] inception_11a/output <- inception_11a/1x1
I0316 12:04:36.866415 55708 net.cpp:406] inception_11a/output <- inception_11a/3x3
I0316 12:04:36.866420 55708 net.cpp:380] inception_11a/output -> inception_11a/output
I0316 12:04:36.866437 55708 net.cpp:122] Setting up inception_11a/output
I0316 12:04:36.866442 55708 net.cpp:129] Top shape: 32 336 8 8 (688128)
I0316 12:04:36.866446 55708 net.cpp:137] Memory required for data: 423231616
I0316 12:04:36.866448 55708 layer_factory.hpp:77] Creating layer avg_pool_12/8x8_s1
I0316 12:04:36.866453 55708 net.cpp:84] Creating Layer avg_pool_12/8x8_s1
I0316 12:04:36.866458 55708 net.cpp:406] avg_pool_12/8x8_s1 <- inception_11a/output
I0316 12:04:36.866462 55708 net.cpp:380] avg_pool_12/8x8_s1 -> avg_pool_12/8x8_s1
I0316 12:04:36.866479 55708 net.cpp:122] Setting up avg_pool_12/8x8_s1
I0316 12:04:36.866483 55708 net.cpp:129] Top shape: 32 336 1 1 (10752)
I0316 12:04:36.866487 55708 net.cpp:137] Memory required for data: 423274624
I0316 12:04:36.866490 55708 layer_factory.hpp:77] Creating layer drop_8x8_s1
I0316 12:04:36.866497 55708 net.cpp:84] Creating Layer drop_8x8_s1
I0316 12:04:36.866500 55708 net.cpp:406] drop_8x8_s1 <- avg_pool_12/8x8_s1
I0316 12:04:36.866505 55708 net.cpp:367] drop_8x8_s1 -> avg_pool_12/8x8_s1 (in-place)
I0316 12:04:36.866524 55708 net.cpp:122] Setting up drop_8x8_s1
I0316 12:04:36.866528 55708 net.cpp:129] Top shape: 32 336 1 1 (10752)
I0316 12:04:36.866531 55708 net.cpp:137] Memory required for data: 423317632
I0316 12:04:36.866535 55708 layer_factory.hpp:77] Creating layer latent
I0316 12:04:36.866542 55708 net.cpp:84] Creating Layer latent
I0316 12:04:36.866545 55708 net.cpp:406] latent <- avg_pool_12/8x8_s1
I0316 12:04:36.866550 55708 net.cpp:380] latent -> latent
I0316 12:04:36.866951 55708 net.cpp:122] Setting up latent
I0316 12:04:36.866958 55708 net.cpp:129] Top shape: 32 48 (1536)
I0316 12:04:36.866961 55708 net.cpp:137] Memory required for data: 423323776
I0316 12:04:36.866966 55708 layer_factory.hpp:77] Creating layer latent_sigmoid
I0316 12:04:36.866971 55708 net.cpp:84] Creating Layer latent_sigmoid
I0316 12:04:36.866976 55708 net.cpp:406] latent_sigmoid <- latent
I0316 12:04:36.866979 55708 net.cpp:380] latent_sigmoid -> latent_sigmoid
I0316 12:04:36.866995 55708 net.cpp:122] Setting up latent_sigmoid
I0316 12:04:36.867000 55708 net.cpp:129] Top shape: 32 48 (1536)
I0316 12:04:36.867003 55708 net.cpp:137] Memory required for data: 423329920
I0316 12:04:36.867007 55708 layer_factory.hpp:77] Creating layer latent_sigmoid_latent_sigmoid_0_split
I0316 12:04:36.867012 55708 net.cpp:84] Creating Layer latent_sigmoid_latent_sigmoid_0_split
I0316 12:04:36.867015 55708 net.cpp:406] latent_sigmoid_latent_sigmoid_0_split <- latent_sigmoid
I0316 12:04:36.867020 55708 net.cpp:380] latent_sigmoid_latent_sigmoid_0_split -> latent_sigmoid_latent_sigmoid_0_split_0
I0316 12:04:36.867025 55708 net.cpp:380] latent_sigmoid_latent_sigmoid_0_split -> latent_sigmoid_latent_sigmoid_0_split_1
I0316 12:04:36.867031 55708 net.cpp:380] latent_sigmoid_latent_sigmoid_0_split -> latent_sigmoid_latent_sigmoid_0_split_2
I0316 12:04:36.867038 55708 net.cpp:380] latent_sigmoid_latent_sigmoid_0_split -> latent_sigmoid_latent_sigmoid_0_split_3
I0316 12:04:36.867082 55708 net.cpp:122] Setting up latent_sigmoid_latent_sigmoid_0_split
I0316 12:04:36.867089 55708 net.cpp:129] Top shape: 32 48 (1536)
I0316 12:04:36.867092 55708 net.cpp:129] Top shape: 32 48 (1536)
I0316 12:04:36.867096 55708 net.cpp:129] Top shape: 32 48 (1536)
I0316 12:04:36.867100 55708 net.cpp:129] Top shape: 32 48 (1536)
I0316 12:04:36.867102 55708 net.cpp:137] Memory required for data: 423354496
I0316 12:04:36.867105 55708 layer_factory.hpp:77] Creating layer loss_1
I0316 12:04:36.867115 55708 net.cpp:84] Creating Layer loss_1
I0316 12:04:36.867120 55708 net.cpp:406] loss_1 <- latent_sigmoid_latent_sigmoid_0_split_0
I0316 12:04:36.867123 55708 net.cpp:406] loss_1 <- latent_sigmoid_latent_sigmoid_0_split_1
I0316 12:04:36.867136 55708 net.cpp:380] loss_1 -> loss: forcing-binary
I0316 12:04:36.867166 55708 net.cpp:122] Setting up loss_1
I0316 12:04:36.867172 55708 net.cpp:129] Top shape: (1)
I0316 12:04:36.867175 55708 net.cpp:132]     with loss weight 1
I0316 12:04:36.867192 55708 net.cpp:137] Memory required for data: 423354500
I0316 12:04:36.867197 55708 layer_factory.hpp:77] Creating layer latent_sigmoid_reshape
I0316 12:04:36.867204 55708 net.cpp:84] Creating Layer latent_sigmoid_reshape
I0316 12:04:36.867208 55708 net.cpp:406] latent_sigmoid_reshape <- latent_sigmoid_latent_sigmoid_0_split_2
I0316 12:04:36.867213 55708 net.cpp:380] latent_sigmoid_reshape -> latent_sigmoid_reshape
I0316 12:04:36.867239 55708 net.cpp:122] Setting up latent_sigmoid_reshape
I0316 12:04:36.867245 55708 net.cpp:129] Top shape: 32 1 1 48 (1536)
I0316 12:04:36.867249 55708 net.cpp:137] Memory required for data: 423360644
I0316 12:04:36.867251 55708 layer_factory.hpp:77] Creating layer latent_sigmoid_avg
I0316 12:04:36.867259 55708 net.cpp:84] Creating Layer latent_sigmoid_avg
I0316 12:04:36.867261 55708 net.cpp:406] latent_sigmoid_avg <- latent_sigmoid_reshape
I0316 12:04:36.867267 55708 net.cpp:380] latent_sigmoid_avg -> latent_sigmoid_avg
I0316 12:04:36.867285 55708 net.cpp:122] Setting up latent_sigmoid_avg
I0316 12:04:36.867290 55708 net.cpp:129] Top shape: 32 1 1 1 (32)
I0316 12:04:36.867292 55708 net.cpp:137] Memory required for data: 423360772
I0316 12:04:36.867295 55708 layer_factory.hpp:77] Creating layer latent_sigmoid_avg_latent_sigmoid_avg_0_split
I0316 12:04:36.867300 55708 net.cpp:84] Creating Layer latent_sigmoid_avg_latent_sigmoid_avg_0_split
I0316 12:04:36.867305 55708 net.cpp:406] latent_sigmoid_avg_latent_sigmoid_avg_0_split <- latent_sigmoid_avg
I0316 12:04:36.867319 55708 net.cpp:380] latent_sigmoid_avg_latent_sigmoid_avg_0_split -> latent_sigmoid_avg_latent_sigmoid_avg_0_split_0
I0316 12:04:36.867326 55708 net.cpp:380] latent_sigmoid_avg_latent_sigmoid_avg_0_split -> latent_sigmoid_avg_latent_sigmoid_avg_0_split_1
I0316 12:04:36.867363 55708 net.cpp:122] Setting up latent_sigmoid_avg_latent_sigmoid_avg_0_split
I0316 12:04:36.867370 55708 net.cpp:129] Top shape: 32 1 1 1 (32)
I0316 12:04:36.867374 55708 net.cpp:129] Top shape: 32 1 1 1 (32)
I0316 12:04:36.867377 55708 net.cpp:137] Memory required for data: 423361028
I0316 12:04:36.867380 55708 layer_factory.hpp:77] Creating layer loss_2
I0316 12:04:36.867386 55708 net.cpp:84] Creating Layer loss_2
I0316 12:04:36.867389 55708 net.cpp:406] loss_2 <- latent_sigmoid_avg_latent_sigmoid_avg_0_split_0
I0316 12:04:36.867393 55708 net.cpp:406] loss_2 <- latent_sigmoid_avg_latent_sigmoid_avg_0_split_1
I0316 12:04:36.867398 55708 net.cpp:380] loss_2 -> loss: 50%-fire-rate
I0316 12:04:36.867425 55708 net.cpp:122] Setting up loss_2
I0316 12:04:36.867430 55708 net.cpp:129] Top shape: (1)
I0316 12:04:36.867432 55708 net.cpp:132]     with loss weight 1
I0316 12:04:36.867437 55708 net.cpp:137] Memory required for data: 423361032
I0316 12:04:36.867440 55708 layer_factory.hpp:77] Creating layer fc10
I0316 12:04:36.867445 55708 net.cpp:84] Creating Layer fc10
I0316 12:04:36.867449 55708 net.cpp:406] fc10 <- latent_sigmoid_latent_sigmoid_0_split_3
I0316 12:04:36.867455 55708 net.cpp:380] fc10 -> fc10
I0316 12:04:36.867560 55708 net.cpp:122] Setting up fc10
I0316 12:04:36.867566 55708 net.cpp:129] Top shape: 32 10 (320)
I0316 12:04:36.867569 55708 net.cpp:137] Memory required for data: 423362312
I0316 12:04:36.867574 55708 layer_factory.hpp:77] Creating layer loss
I0316 12:04:36.867580 55708 net.cpp:84] Creating Layer loss
I0316 12:04:36.867583 55708 net.cpp:406] loss <- fc10
I0316 12:04:36.867588 55708 net.cpp:406] loss <- label
I0316 12:04:36.867592 55708 net.cpp:380] loss -> loss
I0316 12:04:36.867599 55708 layer_factory.hpp:77] Creating layer loss
I0316 12:04:36.867669 55708 net.cpp:122] Setting up loss
I0316 12:04:36.867676 55708 net.cpp:129] Top shape: (1)
I0316 12:04:36.867678 55708 net.cpp:132]     with loss weight 1
I0316 12:04:36.867693 55708 net.cpp:137] Memory required for data: 423362316
I0316 12:04:36.867697 55708 net.cpp:198] loss needs backward computation.
I0316 12:04:36.867702 55708 net.cpp:198] fc10 needs backward computation.
I0316 12:04:36.867705 55708 net.cpp:198] loss_2 needs backward computation.
I0316 12:04:36.867712 55708 net.cpp:198] latent_sigmoid_avg_latent_sigmoid_avg_0_split needs backward computation.
I0316 12:04:36.867714 55708 net.cpp:198] latent_sigmoid_avg needs backward computation.
I0316 12:04:36.867717 55708 net.cpp:198] latent_sigmoid_reshape needs backward computation.
I0316 12:04:36.867720 55708 net.cpp:198] loss_1 needs backward computation.
I0316 12:04:36.867725 55708 net.cpp:198] latent_sigmoid_latent_sigmoid_0_split needs backward computation.
I0316 12:04:36.867729 55708 net.cpp:198] latent_sigmoid needs backward computation.
I0316 12:04:36.867733 55708 net.cpp:198] latent needs backward computation.
I0316 12:04:36.867736 55708 net.cpp:198] drop_8x8_s1 needs backward computation.
I0316 12:04:36.867740 55708 net.cpp:198] avg_pool_12/8x8_s1 needs backward computation.
I0316 12:04:36.867744 55708 net.cpp:198] inception_11a/output needs backward computation.
I0316 12:04:36.867748 55708 net.cpp:198] inception_11a/3x3/relu1 needs backward computation.
I0316 12:04:36.867751 55708 net.cpp:198] inception_11a/3x3/scale1 needs backward computation.
I0316 12:04:36.867755 55708 net.cpp:198] inception_11a/3x3/bn1 needs backward computation.
I0316 12:04:36.867758 55708 net.cpp:198] inception_11a/3x3 needs backward computation.
I0316 12:04:36.867763 55708 net.cpp:198] inception_11a/1x1/relu1 needs backward computation.
I0316 12:04:36.867765 55708 net.cpp:198] inception_11a/1x1/scale1 needs backward computation.
I0316 12:04:36.867769 55708 net.cpp:198] inception_11a/1x1/bn1 needs backward computation.
I0316 12:04:36.867772 55708 net.cpp:198] inception_11a/1x1 needs backward computation.
I0316 12:04:36.867776 55708 net.cpp:198] inception_10a/output_inception_10a/output_0_split needs backward computation.
I0316 12:04:36.867779 55708 net.cpp:198] inception_10a/output needs backward computation.
I0316 12:04:36.867784 55708 net.cpp:198] inception_10a/3x3/relu1 needs backward computation.
I0316 12:04:36.867789 55708 net.cpp:198] inception_10a/3x3/scale1 needs backward computation.
I0316 12:04:36.867791 55708 net.cpp:198] inception_10a/3x3/bn1 needs backward computation.
I0316 12:04:36.867794 55708 net.cpp:198] inception_10a/3x3 needs backward computation.
I0316 12:04:36.867799 55708 net.cpp:198] inception_10a/1x1/relu1 needs backward computation.
I0316 12:04:36.867801 55708 net.cpp:198] inception_10a/1x1/scale1 needs backward computation.
I0316 12:04:36.867805 55708 net.cpp:198] inception_10a/1x1/bn1 needs backward computation.
I0316 12:04:36.867808 55708 net.cpp:198] inception_10a/1x1 needs backward computation.
I0316 12:04:36.867812 55708 net.cpp:198] downsample_9/output_downsample_9/output_0_split needs backward computation.
I0316 12:04:36.867816 55708 net.cpp:198] downsample_9/output needs backward computation.
I0316 12:04:36.867820 55708 net.cpp:198] downsample_9/pool_s2 needs backward computation.
I0316 12:04:36.867823 55708 net.cpp:198] downsample_9/3x3_s2/relu1 needs backward computation.
I0316 12:04:36.867828 55708 net.cpp:198] downsample_9/3x3_s2/scale1 needs backward computation.
I0316 12:04:36.867831 55708 net.cpp:198] downsample_9/3x3_s2/bn1 needs backward computation.
I0316 12:04:36.867834 55708 net.cpp:198] downsample_9/3x3_s2 needs backward computation.
I0316 12:04:36.867837 55708 net.cpp:198] inception_8a/output_inception_8a/output_0_split needs backward computation.
I0316 12:04:36.867842 55708 net.cpp:198] inception_8a/output needs backward computation.
I0316 12:04:36.867846 55708 net.cpp:198] inception_8a/3x3/relu1 needs backward computation.
I0316 12:04:36.867849 55708 net.cpp:198] inception_8a/3x3/scale1 needs backward computation.
I0316 12:04:36.867852 55708 net.cpp:198] inception_8a/3x3/bn1 needs backward computation.
I0316 12:04:36.867857 55708 net.cpp:198] inception_8a/3x3 needs backward computation.
I0316 12:04:36.867866 55708 net.cpp:198] inception_8a/1x1/relu1 needs backward computation.
I0316 12:04:36.867869 55708 net.cpp:198] inception_8a/1x1/scale1 needs backward computation.
I0316 12:04:36.867872 55708 net.cpp:198] inception_8a/1x1/bn1 needs backward computation.
I0316 12:04:36.867877 55708 net.cpp:198] inception_8a/1x1 needs backward computation.
I0316 12:04:36.867880 55708 net.cpp:198] inception_7a/output_inception_7a/output_0_split needs backward computation.
I0316 12:04:36.867883 55708 net.cpp:198] inception_7a/output needs backward computation.
I0316 12:04:36.867887 55708 net.cpp:198] inception_7a/3x3/relu1 needs backward computation.
I0316 12:04:36.867892 55708 net.cpp:198] inception_7a/3x3/scale1 needs backward computation.
I0316 12:04:36.867895 55708 net.cpp:198] inception_7a/3x3/bn1 needs backward computation.
I0316 12:04:36.867898 55708 net.cpp:198] inception_7a/3x3 needs backward computation.
I0316 12:04:36.867902 55708 net.cpp:198] inception_7a/1x1/relu1 needs backward computation.
I0316 12:04:36.867906 55708 net.cpp:198] inception_7a/1x1/scale1 needs backward computation.
I0316 12:04:36.867909 55708 net.cpp:198] inception_7a/1x1/bn1 needs backward computation.
I0316 12:04:36.867913 55708 net.cpp:198] inception_7a/1x1 needs backward computation.
I0316 12:04:36.867915 55708 net.cpp:198] inception_6a/output_inception_6a/output_0_split needs backward computation.
I0316 12:04:36.867920 55708 net.cpp:198] inception_6a/output needs backward computation.
I0316 12:04:36.867924 55708 net.cpp:198] inception_6a/3x3/relu1 needs backward computation.
I0316 12:04:36.867928 55708 net.cpp:198] inception_6a/3x3/scale1 needs backward computation.
I0316 12:04:36.867931 55708 net.cpp:198] inception_6a/3x3/bn1 needs backward computation.
I0316 12:04:36.867935 55708 net.cpp:198] inception_6a/3x3 needs backward computation.
I0316 12:04:36.867938 55708 net.cpp:198] inception_6a/1x1/relu1 needs backward computation.
I0316 12:04:36.867941 55708 net.cpp:198] inception_6a/1x1/scale1 needs backward computation.
I0316 12:04:36.867944 55708 net.cpp:198] inception_6a/1x1/bn1 needs backward computation.
I0316 12:04:36.867949 55708 net.cpp:198] inception_6a/1x1 needs backward computation.
I0316 12:04:36.867952 55708 net.cpp:198] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0316 12:04:36.867955 55708 net.cpp:198] inception_5a/output needs backward computation.
I0316 12:04:36.867959 55708 net.cpp:198] inception_5a/3x3/relu1 needs backward computation.
I0316 12:04:36.867964 55708 net.cpp:198] inception_5a/3x3/scale1 needs backward computation.
I0316 12:04:36.867966 55708 net.cpp:198] inception_5a/3x3/bn1 needs backward computation.
I0316 12:04:36.867969 55708 net.cpp:198] inception_5a/3x3 needs backward computation.
I0316 12:04:36.867974 55708 net.cpp:198] inception_5a/1x1/relu1 needs backward computation.
I0316 12:04:36.867977 55708 net.cpp:198] inception_5a/1x1/scale1 needs backward computation.
I0316 12:04:36.867981 55708 net.cpp:198] inception_5a/1x1/bn1 needs backward computation.
I0316 12:04:36.867985 55708 net.cpp:198] inception_5a/1x1 needs backward computation.
I0316 12:04:36.867988 55708 net.cpp:198] downsample_4/output_downsample_4/output_0_split needs backward computation.
I0316 12:04:36.867992 55708 net.cpp:198] downsample_4/output needs backward computation.
I0316 12:04:36.867996 55708 net.cpp:198] downsample_4/pool_s2 needs backward computation.
I0316 12:04:36.868000 55708 net.cpp:198] downsample_4/3x3_s2/relu1 needs backward computation.
I0316 12:04:36.868003 55708 net.cpp:198] downsample_4/3x3_s2/scale1 needs backward computation.
I0316 12:04:36.868007 55708 net.cpp:198] downsample_4/3x3_s2/bn1 needs backward computation.
I0316 12:04:36.868010 55708 net.cpp:198] downsample_4/3x3_s2 needs backward computation.
I0316 12:04:36.868013 55708 net.cpp:198] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0316 12:04:36.868017 55708 net.cpp:198] inception_3a/output needs backward computation.
I0316 12:04:36.868022 55708 net.cpp:198] inception_3a/3x3/relu1 needs backward computation.
I0316 12:04:36.868031 55708 net.cpp:198] inception_3a/3x3/scale1 needs backward computation.
I0316 12:04:36.868034 55708 net.cpp:198] inception_3a/3x3/bn1 needs backward computation.
I0316 12:04:36.868037 55708 net.cpp:198] inception_3a/3x3 needs backward computation.
I0316 12:04:36.868041 55708 net.cpp:198] inception_3a/1x1/relu1 needs backward computation.
I0316 12:04:36.868044 55708 net.cpp:198] inception_3a/1x1/scale1 needs backward computation.
I0316 12:04:36.868047 55708 net.cpp:198] inception_3a/1x1/bn1 needs backward computation.
I0316 12:04:36.868050 55708 net.cpp:198] inception_3a/1x1 needs backward computation.
I0316 12:04:36.868055 55708 net.cpp:198] inception_2a/output_inception_2a/output_0_split needs backward computation.
I0316 12:04:36.868058 55708 net.cpp:198] inception_2a/output needs backward computation.
I0316 12:04:36.868062 55708 net.cpp:198] inception_2a/3x3/relu1 needs backward computation.
I0316 12:04:36.868067 55708 net.cpp:198] inception_2a/3x3/scale1 needs backward computation.
I0316 12:04:36.868070 55708 net.cpp:198] inception_2a/3x3/bn1 needs backward computation.
I0316 12:04:36.868073 55708 net.cpp:198] inception_2a/3x3 needs backward computation.
I0316 12:04:36.868077 55708 net.cpp:198] inception_2a/1x1/relu1 needs backward computation.
I0316 12:04:36.868081 55708 net.cpp:198] inception_2a/1x1/scale1 needs backward computation.
I0316 12:04:36.868085 55708 net.cpp:198] inception_2a/1x1/bn1 needs backward computation.
I0316 12:04:36.868088 55708 net.cpp:198] inception_2a/1x1 needs backward computation.
I0316 12:04:36.868093 55708 net.cpp:198] conv1/3x3_s1_conv1/relu1_0_split needs backward computation.
I0316 12:04:36.868096 55708 net.cpp:198] conv1/relu1 needs backward computation.
I0316 12:04:36.868100 55708 net.cpp:198] conv1/scale1 needs backward computation.
I0316 12:04:36.868103 55708 net.cpp:198] conv1/bn1 needs backward computation.
I0316 12:04:36.868108 55708 net.cpp:198] conv1/3x3_s1 needs backward computation.
I0316 12:04:36.868111 55708 net.cpp:200] data does not need backward computation.
I0316 12:04:36.868115 55708 net.cpp:242] This network produces output loss
I0316 12:04:36.868119 55708 net.cpp:242] This network produces output loss: 50%-fire-rate
I0316 12:04:36.868122 55708 net.cpp:242] This network produces output loss: forcing-binary
I0316 12:04:36.868191 55708 net.cpp:255] Network initialization done.
I0316 12:04:36.868479 55708 solver.cpp:72] Finetuning from googlenet.caffemodel
I0316 12:04:37.079329 55708 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: googlenet.caffemodel
I0316 12:04:37.079383 55708 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0316 12:04:37.082234 55708 net.cpp:744] Ignoring source layer loss/classifier
I0316 12:04:37.084658 55708 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: dpu_googlenet_hash48.prototxt
I0316 12:04:37.084678 55708 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0316 12:04:37.084687 55708 solver.cpp:190] Creating test net (#0) specified by net file: dpu_googlenet_hash48.prototxt
I0316 12:04:37.084842 55708 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0316 12:04:37.085561 55708 net.cpp:51] Initializing net from parameters: 
name: "miniGoogleNet for CIFAR10, model 3"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 32
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "../../data/cifar10/cifar10_val_leveldb"
    batch_size: 32
  }
}
layer {
  name: "conv1/3x3_s1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/bn1"
  type: "BatchNorm"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1/scale1"
  type: "Scale"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1/relu1"
  type: "ReLU"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
}
layer {
  name: "inception_2a/1x1"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_2a/1x1/scale1"
  type: "Scale"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_2a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
}
layer {
  name: "inception_2a/3x3"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_2a/3x3/scale1"
  type: "Scale"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_2a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
}
layer {
  name: "inception_2a/output"
  type: "Concat"
  bottom: "inception_2a/1x1"
  bottom: "inception_2a/3x3"
  top: "inception_2a/output"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_3a/1x1/scale1"
  type: "Scale"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_3a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_3a/3x3/scale1"
  type: "Scale"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_3a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1"
  bottom: "inception_3a/3x3"
  top: "inception_3a/output"
}
layer {
  name: "downsample_4/3x3_s2"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "downsample_4/3x3_s2/scale1"
  type: "Scale"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "downsample_4/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
}
layer {
  name: "downsample_4/pool_s2"
  type: "Pooling"
  bottom: "inception_3a/output"
  top: "downsample_4/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_4/output"
  type: "Concat"
  bottom: "downsample_4/3x3_s2"
  bottom: "downsample_4/pool_s2"
  top: "downsample_4/output"
}
layer {
  name: "inception_5a/1x1"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_5a/1x1/scale1"
  type: "Scale"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_5a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
}
layer {
  name: "inception_5a/3x3"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_5a/3x3/scale1"
  type: "Scale"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_5a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
}
layer {
  name: "inception_5a/output"
  type: "Concat"
  bottom: "inception_5a/1x1"
  bottom: "inception_5a/3x3"
  top: "inception_5a/output"
}
layer {
  name: "inception_6a/1x1"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_6a/1x1/scale1"
  type: "Scale"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_6a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
}
layer {
  name: "inception_6a/3x3"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_6a/3x3/scale1"
  type: "Scale"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_6a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
}
layer {
  name: "inception_6a/output"
  type: "Concat"
  bottom: "inception_6a/1x1"
  bottom: "inception_6a/3x3"
  top: "inception_6a/output"
}
layer {
  name: "inception_7a/1x1"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_7a/1x1/scale1"
  type: "Scale"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_7a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
}
layer {
  name: "inception_7a/3x3"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_7a/3x3/scale1"
  type: "Scale"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_7a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
}
layer {
  name: "inception_7a/output"
  type: "Concat"
  bottom: "inception_7a/1x1"
  bottom: "inception_7a/3x3"
  top: "inception_7a/output"
}
layer {
  name: "inception_8a/1x1"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_8a/1x1/scale1"
  type: "Scale"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_8a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
}
layer {
  name: "inception_8a/3x3"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_8a/3x3/scale1"
  type: "Scale"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_8a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
}
layer {
  name: "inception_8a/output"
  type: "Concat"
  bottom: "inception_8a/1x1"
  bottom: "inception_8a/3x3"
  top: "inception_8a/output"
}
layer {
  name: "downsample_9/3x3_s2"
  type: "Convolution"
  bottom: "inception_8a/output"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "downsample_9/3x3_s2/scale1"
  type: "Scale"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "downsample_9/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
}
layer {
  name: "downsample_9/pool_s2"
  type: "Pooling"
  bottom: "inception_8a/output"
  top: "downsample_9/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_9/output"
  type: "Concat"
  bottom: "downsample_9/3x3_s2"
  bottom: "downsample_9/pool_s2"
  top: "downsample_9/output"
}
layer {
  name: "inception_10a/1x1"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_10a/1x1/scale1"
  type: "Scale"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_10a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
}
layer {
  name: "inception_10a/3x3"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_10a/3x3/scale1"
  type: "Scale"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_10a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
}
layer {
  name: "inception_10a/output"
  type: "Concat"
  bottom: "inception_10a/1x1"
  bottom: "inception_10a/3x3"
  top: "inception_10a/output"
}
layer {
  name: "inception_11a/1x1"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_11a/1x1/scale1"
  type: "Scale"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_11a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
}
layer {
  name: "inception_11a/3x3"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_11a/3x3/scale1"
  type: "Scale"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_11a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
}
layer {
  name: "inception_11a/output"
  type: "Concat"
  bottom: "inception_11a/1x1"
  bottom: "inception_11a/3x3"
  top: "inception_11a/output"
}
layer {
  name: "avg_pool_12/8x8_s1"
  type: "Pooling"
  bottom: "inception_11a/output"
  top: "avg_pool_12/8x8_s1"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "drop_8x8_s1"
  type: "Dropout"
  bottom: "avg_pool_12/8x8_s1"
  top: "avg_pool_12/8x8_s1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "latent"
  type: "InnerProduct"
  bottom: "avg_pool_12/8x8_s1"
  top: "latent"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 48
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "latent_sigmoid"
  type: "Sigmoid"
  bottom: "latent"
  top: "latent_sigmoid"
}
layer {
  name: "loss_1"
  type: "K1_EuclideanLoss"
  bottom: "latent_sigmoid"
  bottom: "latent_sigmoid"
  top: "loss: forcing-binary"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
}
layer {
  name: "latent_sigmoid_reshape"
  type: "Reshape"
  bottom: "latent_sigmoid"
  top: "latent_sigmoid_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 1
      dim: -1
    }
  }
}
layer {
  name: "latent_sigmoid_avg"
  type: "Pooling"
  bottom: "latent_sigmoid_reshape"
  top: "latent_sigmoid_avg"
  pooling_param {
    pool: AVE
    kernel_h: 1
    kernel_w: 48
  }
}
layer {
  name: "loss_2"
  type: "K2_EuclideanLoss"
  bottom: "latent_sigmoid_avg"
  bottom: "latent_sigmoid_avg"
  top: "loss: 50%-fire-rate"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
}
layer {
  name: "fc10"
  type: "InnerProduct"
  bottom: "latent_sigmoid"
  top: "fc10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc10"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc10"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top5"
  type: "Accuracy"
  bottom: "fc10"
  bottom: "label"
  top: "top-5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0316 12:04:37.086205 55708 layer_factory.hpp:77] Creating layer data
I0316 12:04:37.473491 55708 db_leveldb.cpp:18] Opened leveldb ../../data/cifar10/cifar10_val_leveldb
I0316 12:04:37.473577 55708 net.cpp:84] Creating Layer data
I0316 12:04:37.473600 55708 net.cpp:380] data -> data
I0316 12:04:37.473628 55708 net.cpp:380] data -> label
I0316 12:04:37.473934 55708 data_layer.cpp:45] output data size: 32,3,32,32
I0316 12:04:37.478363 55708 net.cpp:122] Setting up data
I0316 12:04:37.478394 55708 net.cpp:129] Top shape: 32 3 32 32 (98304)
I0316 12:04:37.478403 55708 net.cpp:129] Top shape: 32 (32)
I0316 12:04:37.478410 55708 net.cpp:137] Memory required for data: 393344
I0316 12:04:37.478418 55708 layer_factory.hpp:77] Creating layer label_data_1_split
I0316 12:04:37.478436 55708 net.cpp:84] Creating Layer label_data_1_split
I0316 12:04:37.478446 55708 net.cpp:406] label_data_1_split <- label
I0316 12:04:37.478456 55708 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0316 12:04:37.478471 55708 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0316 12:04:37.478484 55708 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0316 12:04:37.478610 55708 net.cpp:122] Setting up label_data_1_split
I0316 12:04:37.478624 55708 net.cpp:129] Top shape: 32 (32)
I0316 12:04:37.478633 55708 net.cpp:129] Top shape: 32 (32)
I0316 12:04:37.478646 55708 net.cpp:129] Top shape: 32 (32)
I0316 12:04:37.478655 55708 net.cpp:137] Memory required for data: 393728
I0316 12:04:37.478664 55708 layer_factory.hpp:77] Creating layer conv1/3x3_s1
I0316 12:04:37.478693 55708 net.cpp:84] Creating Layer conv1/3x3_s1
I0316 12:04:37.478705 55708 net.cpp:406] conv1/3x3_s1 <- data
I0316 12:04:37.478720 55708 net.cpp:380] conv1/3x3_s1 -> conv1/3x3_s1
I0316 12:04:37.479487 55708 net.cpp:122] Setting up conv1/3x3_s1
I0316 12:04:37.479504 55708 net.cpp:129] Top shape: 32 96 32 32 (3145728)
I0316 12:04:37.479552 55708 net.cpp:137] Memory required for data: 12976640
I0316 12:04:37.479573 55708 layer_factory.hpp:77] Creating layer conv1/bn1
I0316 12:04:37.479593 55708 net.cpp:84] Creating Layer conv1/bn1
I0316 12:04:37.479602 55708 net.cpp:406] conv1/bn1 <- conv1/3x3_s1
I0316 12:04:37.479626 55708 net.cpp:367] conv1/bn1 -> conv1/3x3_s1 (in-place)
I0316 12:04:37.480015 55708 net.cpp:122] Setting up conv1/bn1
I0316 12:04:37.480027 55708 net.cpp:129] Top shape: 32 96 32 32 (3145728)
I0316 12:04:37.480034 55708 net.cpp:137] Memory required for data: 25559552
I0316 12:04:37.480064 55708 layer_factory.hpp:77] Creating layer conv1/scale1
I0316 12:04:37.480083 55708 net.cpp:84] Creating Layer conv1/scale1
I0316 12:04:37.480091 55708 net.cpp:406] conv1/scale1 <- conv1/3x3_s1
I0316 12:04:37.480104 55708 net.cpp:367] conv1/scale1 -> conv1/3x3_s1 (in-place)
I0316 12:04:37.480191 55708 layer_factory.hpp:77] Creating layer conv1/scale1
I0316 12:04:37.480422 55708 net.cpp:122] Setting up conv1/scale1
I0316 12:04:37.480439 55708 net.cpp:129] Top shape: 32 96 32 32 (3145728)
I0316 12:04:37.480445 55708 net.cpp:137] Memory required for data: 38142464
I0316 12:04:37.480463 55708 layer_factory.hpp:77] Creating layer conv1/relu1
I0316 12:04:37.480475 55708 net.cpp:84] Creating Layer conv1/relu1
I0316 12:04:37.480484 55708 net.cpp:406] conv1/relu1 <- conv1/3x3_s1
I0316 12:04:37.480492 55708 net.cpp:367] conv1/relu1 -> conv1/3x3_s1 (in-place)
I0316 12:04:37.480505 55708 net.cpp:122] Setting up conv1/relu1
I0316 12:04:37.480517 55708 net.cpp:129] Top shape: 32 96 32 32 (3145728)
I0316 12:04:37.480525 55708 net.cpp:137] Memory required for data: 50725376
I0316 12:04:37.480533 55708 layer_factory.hpp:77] Creating layer conv1/3x3_s1_conv1/relu1_0_split
I0316 12:04:37.480549 55708 net.cpp:84] Creating Layer conv1/3x3_s1_conv1/relu1_0_split
I0316 12:04:37.480561 55708 net.cpp:406] conv1/3x3_s1_conv1/relu1_0_split <- conv1/3x3_s1
I0316 12:04:37.480574 55708 net.cpp:380] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_0
I0316 12:04:37.480592 55708 net.cpp:380] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_1
I0316 12:04:37.480669 55708 net.cpp:122] Setting up conv1/3x3_s1_conv1/relu1_0_split
I0316 12:04:37.480684 55708 net.cpp:129] Top shape: 32 96 32 32 (3145728)
I0316 12:04:37.480691 55708 net.cpp:129] Top shape: 32 96 32 32 (3145728)
I0316 12:04:37.480698 55708 net.cpp:137] Memory required for data: 75891200
I0316 12:04:37.480711 55708 layer_factory.hpp:77] Creating layer inception_2a/1x1
I0316 12:04:37.480731 55708 net.cpp:84] Creating Layer inception_2a/1x1
I0316 12:04:37.480746 55708 net.cpp:406] inception_2a/1x1 <- conv1/3x3_s1_conv1/relu1_0_split_0
I0316 12:04:37.480759 55708 net.cpp:380] inception_2a/1x1 -> inception_2a/1x1
I0316 12:04:37.481323 55708 net.cpp:122] Setting up inception_2a/1x1
I0316 12:04:37.481343 55708 net.cpp:129] Top shape: 32 32 32 32 (1048576)
I0316 12:04:37.481351 55708 net.cpp:137] Memory required for data: 80085504
I0316 12:04:37.481372 55708 layer_factory.hpp:77] Creating layer inception_2a/1x1/bn1
I0316 12:04:37.481393 55708 net.cpp:84] Creating Layer inception_2a/1x1/bn1
I0316 12:04:37.481405 55708 net.cpp:406] inception_2a/1x1/bn1 <- inception_2a/1x1
I0316 12:04:37.481417 55708 net.cpp:367] inception_2a/1x1/bn1 -> inception_2a/1x1 (in-place)
I0316 12:04:37.481750 55708 net.cpp:122] Setting up inception_2a/1x1/bn1
I0316 12:04:37.481762 55708 net.cpp:129] Top shape: 32 32 32 32 (1048576)
I0316 12:04:37.481770 55708 net.cpp:137] Memory required for data: 84279808
I0316 12:04:37.481782 55708 layer_factory.hpp:77] Creating layer inception_2a/1x1/scale1
I0316 12:04:37.481796 55708 net.cpp:84] Creating Layer inception_2a/1x1/scale1
I0316 12:04:37.481807 55708 net.cpp:406] inception_2a/1x1/scale1 <- inception_2a/1x1
I0316 12:04:37.481817 55708 net.cpp:367] inception_2a/1x1/scale1 -> inception_2a/1x1 (in-place)
I0316 12:04:37.481878 55708 layer_factory.hpp:77] Creating layer inception_2a/1x1/scale1
I0316 12:04:37.482085 55708 net.cpp:122] Setting up inception_2a/1x1/scale1
I0316 12:04:37.482120 55708 net.cpp:129] Top shape: 32 32 32 32 (1048576)
I0316 12:04:37.482126 55708 net.cpp:137] Memory required for data: 88474112
I0316 12:04:37.482137 55708 layer_factory.hpp:77] Creating layer inception_2a/1x1/relu1
I0316 12:04:37.482147 55708 net.cpp:84] Creating Layer inception_2a/1x1/relu1
I0316 12:04:37.482156 55708 net.cpp:406] inception_2a/1x1/relu1 <- inception_2a/1x1
I0316 12:04:37.482165 55708 net.cpp:367] inception_2a/1x1/relu1 -> inception_2a/1x1 (in-place)
I0316 12:04:37.482175 55708 net.cpp:122] Setting up inception_2a/1x1/relu1
I0316 12:04:37.482183 55708 net.cpp:129] Top shape: 32 32 32 32 (1048576)
I0316 12:04:37.482192 55708 net.cpp:137] Memory required for data: 92668416
I0316 12:04:37.482197 55708 layer_factory.hpp:77] Creating layer inception_2a/3x3
I0316 12:04:37.482211 55708 net.cpp:84] Creating Layer inception_2a/3x3
I0316 12:04:37.482218 55708 net.cpp:406] inception_2a/3x3 <- conv1/3x3_s1_conv1/relu1_0_split_1
I0316 12:04:37.482231 55708 net.cpp:380] inception_2a/3x3 -> inception_2a/3x3
I0316 12:04:37.483043 55708 net.cpp:122] Setting up inception_2a/3x3
I0316 12:04:37.483057 55708 net.cpp:129] Top shape: 32 32 32 32 (1048576)
I0316 12:04:37.483063 55708 net.cpp:137] Memory required for data: 96862720
I0316 12:04:37.483076 55708 layer_factory.hpp:77] Creating layer inception_2a/3x3/bn1
I0316 12:04:37.483088 55708 net.cpp:84] Creating Layer inception_2a/3x3/bn1
I0316 12:04:37.483095 55708 net.cpp:406] inception_2a/3x3/bn1 <- inception_2a/3x3
I0316 12:04:37.483105 55708 net.cpp:367] inception_2a/3x3/bn1 -> inception_2a/3x3 (in-place)
I0316 12:04:37.483537 55708 net.cpp:122] Setting up inception_2a/3x3/bn1
I0316 12:04:37.483551 55708 net.cpp:129] Top shape: 32 32 32 32 (1048576)
I0316 12:04:37.483557 55708 net.cpp:137] Memory required for data: 101057024
I0316 12:04:37.483577 55708 layer_factory.hpp:77] Creating layer inception_2a/3x3/scale1
I0316 12:04:37.483592 55708 net.cpp:84] Creating Layer inception_2a/3x3/scale1
I0316 12:04:37.483599 55708 net.cpp:406] inception_2a/3x3/scale1 <- inception_2a/3x3
I0316 12:04:37.483609 55708 net.cpp:367] inception_2a/3x3/scale1 -> inception_2a/3x3 (in-place)
I0316 12:04:37.483747 55708 layer_factory.hpp:77] Creating layer inception_2a/3x3/scale1
I0316 12:04:37.483944 55708 net.cpp:122] Setting up inception_2a/3x3/scale1
I0316 12:04:37.483958 55708 net.cpp:129] Top shape: 32 32 32 32 (1048576)
I0316 12:04:37.483964 55708 net.cpp:137] Memory required for data: 105251328
I0316 12:04:37.483975 55708 layer_factory.hpp:77] Creating layer inception_2a/3x3/relu1
I0316 12:04:37.483986 55708 net.cpp:84] Creating Layer inception_2a/3x3/relu1
I0316 12:04:37.483994 55708 net.cpp:406] inception_2a/3x3/relu1 <- inception_2a/3x3
I0316 12:04:37.484002 55708 net.cpp:367] inception_2a/3x3/relu1 -> inception_2a/3x3 (in-place)
I0316 12:04:37.484012 55708 net.cpp:122] Setting up inception_2a/3x3/relu1
I0316 12:04:37.484023 55708 net.cpp:129] Top shape: 32 32 32 32 (1048576)
I0316 12:04:37.484030 55708 net.cpp:137] Memory required for data: 109445632
I0316 12:04:37.484035 55708 layer_factory.hpp:77] Creating layer inception_2a/output
I0316 12:04:37.484045 55708 net.cpp:84] Creating Layer inception_2a/output
I0316 12:04:37.484055 55708 net.cpp:406] inception_2a/output <- inception_2a/1x1
I0316 12:04:37.484062 55708 net.cpp:406] inception_2a/output <- inception_2a/3x3
I0316 12:04:37.484072 55708 net.cpp:380] inception_2a/output -> inception_2a/output
I0316 12:04:37.484100 55708 net.cpp:122] Setting up inception_2a/output
I0316 12:04:37.484114 55708 net.cpp:129] Top shape: 32 64 32 32 (2097152)
I0316 12:04:37.484120 55708 net.cpp:137] Memory required for data: 117834240
I0316 12:04:37.484126 55708 layer_factory.hpp:77] Creating layer inception_2a/output_inception_2a/output_0_split
I0316 12:04:37.484143 55708 net.cpp:84] Creating Layer inception_2a/output_inception_2a/output_0_split
I0316 12:04:37.484151 55708 net.cpp:406] inception_2a/output_inception_2a/output_0_split <- inception_2a/output
I0316 12:04:37.484161 55708 net.cpp:380] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_0
I0316 12:04:37.484194 55708 net.cpp:380] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_1
I0316 12:04:37.484253 55708 net.cpp:122] Setting up inception_2a/output_inception_2a/output_0_split
I0316 12:04:37.484267 55708 net.cpp:129] Top shape: 32 64 32 32 (2097152)
I0316 12:04:37.484275 55708 net.cpp:129] Top shape: 32 64 32 32 (2097152)
I0316 12:04:37.484282 55708 net.cpp:137] Memory required for data: 134611456
I0316 12:04:37.484289 55708 layer_factory.hpp:77] Creating layer inception_3a/1x1
I0316 12:04:37.484305 55708 net.cpp:84] Creating Layer inception_3a/1x1
I0316 12:04:37.484313 55708 net.cpp:406] inception_3a/1x1 <- inception_2a/output_inception_2a/output_0_split_0
I0316 12:04:37.484323 55708 net.cpp:380] inception_3a/1x1 -> inception_3a/1x1
I0316 12:04:37.484809 55708 net.cpp:122] Setting up inception_3a/1x1
I0316 12:04:37.484828 55708 net.cpp:129] Top shape: 32 32 32 32 (1048576)
I0316 12:04:37.484834 55708 net.cpp:137] Memory required for data: 138805760
I0316 12:04:37.484845 55708 layer_factory.hpp:77] Creating layer inception_3a/1x1/bn1
I0316 12:04:37.484860 55708 net.cpp:84] Creating Layer inception_3a/1x1/bn1
I0316 12:04:37.484874 55708 net.cpp:406] inception_3a/1x1/bn1 <- inception_3a/1x1
I0316 12:04:37.484884 55708 net.cpp:367] inception_3a/1x1/bn1 -> inception_3a/1x1 (in-place)
I0316 12:04:37.485278 55708 net.cpp:122] Setting up inception_3a/1x1/bn1
I0316 12:04:37.485291 55708 net.cpp:129] Top shape: 32 32 32 32 (1048576)
I0316 12:04:37.485299 55708 net.cpp:137] Memory required for data: 143000064
I0316 12:04:37.485313 55708 layer_factory.hpp:77] Creating layer inception_3a/1x1/scale1
I0316 12:04:37.485323 55708 net.cpp:84] Creating Layer inception_3a/1x1/scale1
I0316 12:04:37.485330 55708 net.cpp:406] inception_3a/1x1/scale1 <- inception_3a/1x1
I0316 12:04:37.485342 55708 net.cpp:367] inception_3a/1x1/scale1 -> inception_3a/1x1 (in-place)
I0316 12:04:37.485445 55708 layer_factory.hpp:77] Creating layer inception_3a/1x1/scale1
I0316 12:04:37.485664 55708 net.cpp:122] Setting up inception_3a/1x1/scale1
I0316 12:04:37.485677 55708 net.cpp:129] Top shape: 32 32 32 32 (1048576)
I0316 12:04:37.485685 55708 net.cpp:137] Memory required for data: 147194368
I0316 12:04:37.485697 55708 layer_factory.hpp:77] Creating layer inception_3a/1x1/relu1
I0316 12:04:37.485707 55708 net.cpp:84] Creating Layer inception_3a/1x1/relu1
I0316 12:04:37.485713 55708 net.cpp:406] inception_3a/1x1/relu1 <- inception_3a/1x1
I0316 12:04:37.485724 55708 net.cpp:367] inception_3a/1x1/relu1 -> inception_3a/1x1 (in-place)
I0316 12:04:37.485735 55708 net.cpp:122] Setting up inception_3a/1x1/relu1
I0316 12:04:37.485744 55708 net.cpp:129] Top shape: 32 32 32 32 (1048576)
I0316 12:04:37.485750 55708 net.cpp:137] Memory required for data: 151388672
I0316 12:04:37.485759 55708 layer_factory.hpp:77] Creating layer inception_3a/3x3
I0316 12:04:37.485771 55708 net.cpp:84] Creating Layer inception_3a/3x3
I0316 12:04:37.485780 55708 net.cpp:406] inception_3a/3x3 <- inception_2a/output_inception_2a/output_0_split_1
I0316 12:04:37.485790 55708 net.cpp:380] inception_3a/3x3 -> inception_3a/3x3
I0316 12:04:37.486634 55708 net.cpp:122] Setting up inception_3a/3x3
I0316 12:04:37.486647 55708 net.cpp:129] Top shape: 32 48 32 32 (1572864)
I0316 12:04:37.486654 55708 net.cpp:137] Memory required for data: 157680128
I0316 12:04:37.486665 55708 layer_factory.hpp:77] Creating layer inception_3a/3x3/bn1
I0316 12:04:37.486678 55708 net.cpp:84] Creating Layer inception_3a/3x3/bn1
I0316 12:04:37.486685 55708 net.cpp:406] inception_3a/3x3/bn1 <- inception_3a/3x3
I0316 12:04:37.486696 55708 net.cpp:367] inception_3a/3x3/bn1 -> inception_3a/3x3 (in-place)
I0316 12:04:37.487077 55708 net.cpp:122] Setting up inception_3a/3x3/bn1
I0316 12:04:37.487092 55708 net.cpp:129] Top shape: 32 48 32 32 (1572864)
I0316 12:04:37.487097 55708 net.cpp:137] Memory required for data: 163971584
I0316 12:04:37.487118 55708 layer_factory.hpp:77] Creating layer inception_3a/3x3/scale1
I0316 12:04:37.487152 55708 net.cpp:84] Creating Layer inception_3a/3x3/scale1
I0316 12:04:37.487161 55708 net.cpp:406] inception_3a/3x3/scale1 <- inception_3a/3x3
I0316 12:04:37.487170 55708 net.cpp:367] inception_3a/3x3/scale1 -> inception_3a/3x3 (in-place)
I0316 12:04:37.487236 55708 layer_factory.hpp:77] Creating layer inception_3a/3x3/scale1
I0316 12:04:37.487429 55708 net.cpp:122] Setting up inception_3a/3x3/scale1
I0316 12:04:37.487457 55708 net.cpp:129] Top shape: 32 48 32 32 (1572864)
I0316 12:04:37.487462 55708 net.cpp:137] Memory required for data: 170263040
I0316 12:04:37.487469 55708 layer_factory.hpp:77] Creating layer inception_3a/3x3/relu1
I0316 12:04:37.487476 55708 net.cpp:84] Creating Layer inception_3a/3x3/relu1
I0316 12:04:37.487481 55708 net.cpp:406] inception_3a/3x3/relu1 <- inception_3a/3x3
I0316 12:04:37.487488 55708 net.cpp:367] inception_3a/3x3/relu1 -> inception_3a/3x3 (in-place)
I0316 12:04:37.487493 55708 net.cpp:122] Setting up inception_3a/3x3/relu1
I0316 12:04:37.487501 55708 net.cpp:129] Top shape: 32 48 32 32 (1572864)
I0316 12:04:37.487507 55708 net.cpp:137] Memory required for data: 176554496
I0316 12:04:37.487511 55708 layer_factory.hpp:77] Creating layer inception_3a/output
I0316 12:04:37.487517 55708 net.cpp:84] Creating Layer inception_3a/output
I0316 12:04:37.487521 55708 net.cpp:406] inception_3a/output <- inception_3a/1x1
I0316 12:04:37.487529 55708 net.cpp:406] inception_3a/output <- inception_3a/3x3
I0316 12:04:37.487534 55708 net.cpp:380] inception_3a/output -> inception_3a/output
I0316 12:04:37.487553 55708 net.cpp:122] Setting up inception_3a/output
I0316 12:04:37.487560 55708 net.cpp:129] Top shape: 32 80 32 32 (2621440)
I0316 12:04:37.487565 55708 net.cpp:137] Memory required for data: 187040256
I0316 12:04:37.487569 55708 layer_factory.hpp:77] Creating layer inception_3a/output_inception_3a/output_0_split
I0316 12:04:37.487576 55708 net.cpp:84] Creating Layer inception_3a/output_inception_3a/output_0_split
I0316 12:04:37.487579 55708 net.cpp:406] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0316 12:04:37.487588 55708 net.cpp:380] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0316 12:04:37.487599 55708 net.cpp:380] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0316 12:04:37.487637 55708 net.cpp:122] Setting up inception_3a/output_inception_3a/output_0_split
I0316 12:04:37.487646 55708 net.cpp:129] Top shape: 32 80 32 32 (2621440)
I0316 12:04:37.487653 55708 net.cpp:129] Top shape: 32 80 32 32 (2621440)
I0316 12:04:37.487658 55708 net.cpp:137] Memory required for data: 208011776
I0316 12:04:37.487661 55708 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2
I0316 12:04:37.487670 55708 net.cpp:84] Creating Layer downsample_4/3x3_s2
I0316 12:04:37.487676 55708 net.cpp:406] downsample_4/3x3_s2 <- inception_3a/output_inception_3a/output_0_split_0
I0316 12:04:37.487684 55708 net.cpp:380] downsample_4/3x3_s2 -> downsample_4/3x3_s2
I0316 12:04:37.488472 55708 net.cpp:122] Setting up downsample_4/3x3_s2
I0316 12:04:37.488483 55708 net.cpp:129] Top shape: 32 80 16 16 (655360)
I0316 12:04:37.488489 55708 net.cpp:137] Memory required for data: 210633216
I0316 12:04:37.488497 55708 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/bn1
I0316 12:04:37.488504 55708 net.cpp:84] Creating Layer downsample_4/3x3_s2/bn1
I0316 12:04:37.488509 55708 net.cpp:406] downsample_4/3x3_s2/bn1 <- downsample_4/3x3_s2
I0316 12:04:37.488518 55708 net.cpp:367] downsample_4/3x3_s2/bn1 -> downsample_4/3x3_s2 (in-place)
I0316 12:04:37.488744 55708 net.cpp:122] Setting up downsample_4/3x3_s2/bn1
I0316 12:04:37.488752 55708 net.cpp:129] Top shape: 32 80 16 16 (655360)
I0316 12:04:37.488757 55708 net.cpp:137] Memory required for data: 213254656
I0316 12:04:37.488767 55708 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/scale1
I0316 12:04:37.488775 55708 net.cpp:84] Creating Layer downsample_4/3x3_s2/scale1
I0316 12:04:37.488790 55708 net.cpp:406] downsample_4/3x3_s2/scale1 <- downsample_4/3x3_s2
I0316 12:04:37.488797 55708 net.cpp:367] downsample_4/3x3_s2/scale1 -> downsample_4/3x3_s2 (in-place)
I0316 12:04:37.488842 55708 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/scale1
I0316 12:04:37.488968 55708 net.cpp:122] Setting up downsample_4/3x3_s2/scale1
I0316 12:04:37.488978 55708 net.cpp:129] Top shape: 32 80 16 16 (655360)
I0316 12:04:37.488982 55708 net.cpp:137] Memory required for data: 215876096
I0316 12:04:37.488991 55708 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/relu1
I0316 12:04:37.488997 55708 net.cpp:84] Creating Layer downsample_4/3x3_s2/relu1
I0316 12:04:37.489002 55708 net.cpp:406] downsample_4/3x3_s2/relu1 <- downsample_4/3x3_s2
I0316 12:04:37.489008 55708 net.cpp:367] downsample_4/3x3_s2/relu1 -> downsample_4/3x3_s2 (in-place)
I0316 12:04:37.489017 55708 net.cpp:122] Setting up downsample_4/3x3_s2/relu1
I0316 12:04:37.489022 55708 net.cpp:129] Top shape: 32 80 16 16 (655360)
I0316 12:04:37.489025 55708 net.cpp:137] Memory required for data: 218497536
I0316 12:04:37.489029 55708 layer_factory.hpp:77] Creating layer downsample_4/pool_s2
I0316 12:04:37.489038 55708 net.cpp:84] Creating Layer downsample_4/pool_s2
I0316 12:04:37.489043 55708 net.cpp:406] downsample_4/pool_s2 <- inception_3a/output_inception_3a/output_0_split_1
I0316 12:04:37.489049 55708 net.cpp:380] downsample_4/pool_s2 -> downsample_4/pool_s2
I0316 12:04:37.489085 55708 net.cpp:122] Setting up downsample_4/pool_s2
I0316 12:04:37.489094 55708 net.cpp:129] Top shape: 32 80 16 16 (655360)
I0316 12:04:37.489099 55708 net.cpp:137] Memory required for data: 221118976
I0316 12:04:37.489102 55708 layer_factory.hpp:77] Creating layer downsample_4/output
I0316 12:04:37.489115 55708 net.cpp:84] Creating Layer downsample_4/output
I0316 12:04:37.489121 55708 net.cpp:406] downsample_4/output <- downsample_4/3x3_s2
I0316 12:04:37.489126 55708 net.cpp:406] downsample_4/output <- downsample_4/pool_s2
I0316 12:04:37.489133 55708 net.cpp:380] downsample_4/output -> downsample_4/output
I0316 12:04:37.489157 55708 net.cpp:122] Setting up downsample_4/output
I0316 12:04:37.489166 55708 net.cpp:129] Top shape: 32 160 16 16 (1310720)
I0316 12:04:37.489171 55708 net.cpp:137] Memory required for data: 226361856
I0316 12:04:37.489174 55708 layer_factory.hpp:77] Creating layer downsample_4/output_downsample_4/output_0_split
I0316 12:04:37.489181 55708 net.cpp:84] Creating Layer downsample_4/output_downsample_4/output_0_split
I0316 12:04:37.489187 55708 net.cpp:406] downsample_4/output_downsample_4/output_0_split <- downsample_4/output
I0316 12:04:37.489193 55708 net.cpp:380] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_0
I0316 12:04:37.489202 55708 net.cpp:380] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_1
I0316 12:04:37.489239 55708 net.cpp:122] Setting up downsample_4/output_downsample_4/output_0_split
I0316 12:04:37.489248 55708 net.cpp:129] Top shape: 32 160 16 16 (1310720)
I0316 12:04:37.489254 55708 net.cpp:129] Top shape: 32 160 16 16 (1310720)
I0316 12:04:37.489259 55708 net.cpp:137] Memory required for data: 236847616
I0316 12:04:37.489262 55708 layer_factory.hpp:77] Creating layer inception_5a/1x1
I0316 12:04:37.489272 55708 net.cpp:84] Creating Layer inception_5a/1x1
I0316 12:04:37.489279 55708 net.cpp:406] inception_5a/1x1 <- downsample_4/output_downsample_4/output_0_split_0
I0316 12:04:37.489284 55708 net.cpp:380] inception_5a/1x1 -> inception_5a/1x1
I0316 12:04:37.489722 55708 net.cpp:122] Setting up inception_5a/1x1
I0316 12:04:37.489732 55708 net.cpp:129] Top shape: 32 112 16 16 (917504)
I0316 12:04:37.489737 55708 net.cpp:137] Memory required for data: 240517632
I0316 12:04:37.489743 55708 layer_factory.hpp:77] Creating layer inception_5a/1x1/bn1
I0316 12:04:37.489751 55708 net.cpp:84] Creating Layer inception_5a/1x1/bn1
I0316 12:04:37.489758 55708 net.cpp:406] inception_5a/1x1/bn1 <- inception_5a/1x1
I0316 12:04:37.489763 55708 net.cpp:367] inception_5a/1x1/bn1 -> inception_5a/1x1 (in-place)
I0316 12:04:37.489990 55708 net.cpp:122] Setting up inception_5a/1x1/bn1
I0316 12:04:37.490000 55708 net.cpp:129] Top shape: 32 112 16 16 (917504)
I0316 12:04:37.490005 55708 net.cpp:137] Memory required for data: 244187648
I0316 12:04:37.490013 55708 layer_factory.hpp:77] Creating layer inception_5a/1x1/scale1
I0316 12:04:37.490020 55708 net.cpp:84] Creating Layer inception_5a/1x1/scale1
I0316 12:04:37.490025 55708 net.cpp:406] inception_5a/1x1/scale1 <- inception_5a/1x1
I0316 12:04:37.490032 55708 net.cpp:367] inception_5a/1x1/scale1 -> inception_5a/1x1 (in-place)
I0316 12:04:37.490072 55708 layer_factory.hpp:77] Creating layer inception_5a/1x1/scale1
I0316 12:04:37.490195 55708 net.cpp:122] Setting up inception_5a/1x1/scale1
I0316 12:04:37.490203 55708 net.cpp:129] Top shape: 32 112 16 16 (917504)
I0316 12:04:37.490208 55708 net.cpp:137] Memory required for data: 247857664
I0316 12:04:37.490216 55708 layer_factory.hpp:77] Creating layer inception_5a/1x1/relu1
I0316 12:04:37.490222 55708 net.cpp:84] Creating Layer inception_5a/1x1/relu1
I0316 12:04:37.490226 55708 net.cpp:406] inception_5a/1x1/relu1 <- inception_5a/1x1
I0316 12:04:37.490233 55708 net.cpp:367] inception_5a/1x1/relu1 -> inception_5a/1x1 (in-place)
I0316 12:04:37.490239 55708 net.cpp:122] Setting up inception_5a/1x1/relu1
I0316 12:04:37.490244 55708 net.cpp:129] Top shape: 32 112 16 16 (917504)
I0316 12:04:37.490249 55708 net.cpp:137] Memory required for data: 251527680
I0316 12:04:37.490254 55708 layer_factory.hpp:77] Creating layer inception_5a/3x3
I0316 12:04:37.490262 55708 net.cpp:84] Creating Layer inception_5a/3x3
I0316 12:04:37.490267 55708 net.cpp:406] inception_5a/3x3 <- downsample_4/output_downsample_4/output_0_split_1
I0316 12:04:37.490274 55708 net.cpp:380] inception_5a/3x3 -> inception_5a/3x3
I0316 12:04:37.491130 55708 net.cpp:122] Setting up inception_5a/3x3
I0316 12:04:37.491139 55708 net.cpp:129] Top shape: 32 48 16 16 (393216)
I0316 12:04:37.491143 55708 net.cpp:137] Memory required for data: 253100544
I0316 12:04:37.491150 55708 layer_factory.hpp:77] Creating layer inception_5a/3x3/bn1
I0316 12:04:37.491159 55708 net.cpp:84] Creating Layer inception_5a/3x3/bn1
I0316 12:04:37.491163 55708 net.cpp:406] inception_5a/3x3/bn1 <- inception_5a/3x3
I0316 12:04:37.491170 55708 net.cpp:367] inception_5a/3x3/bn1 -> inception_5a/3x3 (in-place)
I0316 12:04:37.491389 55708 net.cpp:122] Setting up inception_5a/3x3/bn1
I0316 12:04:37.491401 55708 net.cpp:129] Top shape: 32 48 16 16 (393216)
I0316 12:04:37.491406 55708 net.cpp:137] Memory required for data: 254673408
I0316 12:04:37.491415 55708 layer_factory.hpp:77] Creating layer inception_5a/3x3/scale1
I0316 12:04:37.491421 55708 net.cpp:84] Creating Layer inception_5a/3x3/scale1
I0316 12:04:37.491427 55708 net.cpp:406] inception_5a/3x3/scale1 <- inception_5a/3x3
I0316 12:04:37.491433 55708 net.cpp:367] inception_5a/3x3/scale1 -> inception_5a/3x3 (in-place)
I0316 12:04:37.491473 55708 layer_factory.hpp:77] Creating layer inception_5a/3x3/scale1
I0316 12:04:37.491602 55708 net.cpp:122] Setting up inception_5a/3x3/scale1
I0316 12:04:37.491612 55708 net.cpp:129] Top shape: 32 48 16 16 (393216)
I0316 12:04:37.491616 55708 net.cpp:137] Memory required for data: 256246272
I0316 12:04:37.491623 55708 layer_factory.hpp:77] Creating layer inception_5a/3x3/relu1
I0316 12:04:37.491629 55708 net.cpp:84] Creating Layer inception_5a/3x3/relu1
I0316 12:04:37.491634 55708 net.cpp:406] inception_5a/3x3/relu1 <- inception_5a/3x3
I0316 12:04:37.491641 55708 net.cpp:367] inception_5a/3x3/relu1 -> inception_5a/3x3 (in-place)
I0316 12:04:37.491647 55708 net.cpp:122] Setting up inception_5a/3x3/relu1
I0316 12:04:37.491652 55708 net.cpp:129] Top shape: 32 48 16 16 (393216)
I0316 12:04:37.491657 55708 net.cpp:137] Memory required for data: 257819136
I0316 12:04:37.491662 55708 layer_factory.hpp:77] Creating layer inception_5a/output
I0316 12:04:37.491667 55708 net.cpp:84] Creating Layer inception_5a/output
I0316 12:04:37.491672 55708 net.cpp:406] inception_5a/output <- inception_5a/1x1
I0316 12:04:37.491688 55708 net.cpp:406] inception_5a/output <- inception_5a/3x3
I0316 12:04:37.491694 55708 net.cpp:380] inception_5a/output -> inception_5a/output
I0316 12:04:37.491712 55708 net.cpp:122] Setting up inception_5a/output
I0316 12:04:37.491722 55708 net.cpp:129] Top shape: 32 160 16 16 (1310720)
I0316 12:04:37.491729 55708 net.cpp:137] Memory required for data: 263062016
I0316 12:04:37.491732 55708 layer_factory.hpp:77] Creating layer inception_5a/output_inception_5a/output_0_split
I0316 12:04:37.491739 55708 net.cpp:84] Creating Layer inception_5a/output_inception_5a/output_0_split
I0316 12:04:37.491744 55708 net.cpp:406] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0316 12:04:37.491755 55708 net.cpp:380] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0316 12:04:37.491765 55708 net.cpp:380] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0316 12:04:37.491804 55708 net.cpp:122] Setting up inception_5a/output_inception_5a/output_0_split
I0316 12:04:37.491811 55708 net.cpp:129] Top shape: 32 160 16 16 (1310720)
I0316 12:04:37.491818 55708 net.cpp:129] Top shape: 32 160 16 16 (1310720)
I0316 12:04:37.491822 55708 net.cpp:137] Memory required for data: 273547776
I0316 12:04:37.491827 55708 layer_factory.hpp:77] Creating layer inception_6a/1x1
I0316 12:04:37.491835 55708 net.cpp:84] Creating Layer inception_6a/1x1
I0316 12:04:37.491842 55708 net.cpp:406] inception_6a/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0316 12:04:37.491848 55708 net.cpp:380] inception_6a/1x1 -> inception_6a/1x1
I0316 12:04:37.492247 55708 net.cpp:122] Setting up inception_6a/1x1
I0316 12:04:37.492256 55708 net.cpp:129] Top shape: 32 96 16 16 (786432)
I0316 12:04:37.492261 55708 net.cpp:137] Memory required for data: 276693504
I0316 12:04:37.492269 55708 layer_factory.hpp:77] Creating layer inception_6a/1x1/bn1
I0316 12:04:37.492276 55708 net.cpp:84] Creating Layer inception_6a/1x1/bn1
I0316 12:04:37.492280 55708 net.cpp:406] inception_6a/1x1/bn1 <- inception_6a/1x1
I0316 12:04:37.492288 55708 net.cpp:367] inception_6a/1x1/bn1 -> inception_6a/1x1 (in-place)
I0316 12:04:37.492520 55708 net.cpp:122] Setting up inception_6a/1x1/bn1
I0316 12:04:37.492530 55708 net.cpp:129] Top shape: 32 96 16 16 (786432)
I0316 12:04:37.492535 55708 net.cpp:137] Memory required for data: 279839232
I0316 12:04:37.492544 55708 layer_factory.hpp:77] Creating layer inception_6a/1x1/scale1
I0316 12:04:37.492552 55708 net.cpp:84] Creating Layer inception_6a/1x1/scale1
I0316 12:04:37.492556 55708 net.cpp:406] inception_6a/1x1/scale1 <- inception_6a/1x1
I0316 12:04:37.492563 55708 net.cpp:367] inception_6a/1x1/scale1 -> inception_6a/1x1 (in-place)
I0316 12:04:37.492604 55708 layer_factory.hpp:77] Creating layer inception_6a/1x1/scale1
I0316 12:04:37.492733 55708 net.cpp:122] Setting up inception_6a/1x1/scale1
I0316 12:04:37.492741 55708 net.cpp:129] Top shape: 32 96 16 16 (786432)
I0316 12:04:37.492746 55708 net.cpp:137] Memory required for data: 282984960
I0316 12:04:37.492754 55708 layer_factory.hpp:77] Creating layer inception_6a/1x1/relu1
I0316 12:04:37.492760 55708 net.cpp:84] Creating Layer inception_6a/1x1/relu1
I0316 12:04:37.492764 55708 net.cpp:406] inception_6a/1x1/relu1 <- inception_6a/1x1
I0316 12:04:37.492770 55708 net.cpp:367] inception_6a/1x1/relu1 -> inception_6a/1x1 (in-place)
I0316 12:04:37.492777 55708 net.cpp:122] Setting up inception_6a/1x1/relu1
I0316 12:04:37.492784 55708 net.cpp:129] Top shape: 32 96 16 16 (786432)
I0316 12:04:37.492786 55708 net.cpp:137] Memory required for data: 286130688
I0316 12:04:37.492790 55708 layer_factory.hpp:77] Creating layer inception_6a/3x3
I0316 12:04:37.492800 55708 net.cpp:84] Creating Layer inception_6a/3x3
I0316 12:04:37.492805 55708 net.cpp:406] inception_6a/3x3 <- inception_5a/output_inception_5a/output_0_split_1
I0316 12:04:37.492812 55708 net.cpp:380] inception_6a/3x3 -> inception_6a/3x3
I0316 12:04:37.493853 55708 net.cpp:122] Setting up inception_6a/3x3
I0316 12:04:37.493877 55708 net.cpp:129] Top shape: 32 64 16 16 (524288)
I0316 12:04:37.493881 55708 net.cpp:137] Memory required for data: 288227840
I0316 12:04:37.493896 55708 layer_factory.hpp:77] Creating layer inception_6a/3x3/bn1
I0316 12:04:37.493904 55708 net.cpp:84] Creating Layer inception_6a/3x3/bn1
I0316 12:04:37.493911 55708 net.cpp:406] inception_6a/3x3/bn1 <- inception_6a/3x3
I0316 12:04:37.493918 55708 net.cpp:367] inception_6a/3x3/bn1 -> inception_6a/3x3 (in-place)
I0316 12:04:37.494129 55708 net.cpp:122] Setting up inception_6a/3x3/bn1
I0316 12:04:37.494138 55708 net.cpp:129] Top shape: 32 64 16 16 (524288)
I0316 12:04:37.494143 55708 net.cpp:137] Memory required for data: 290324992
I0316 12:04:37.494151 55708 layer_factory.hpp:77] Creating layer inception_6a/3x3/scale1
I0316 12:04:37.494158 55708 net.cpp:84] Creating Layer inception_6a/3x3/scale1
I0316 12:04:37.494163 55708 net.cpp:406] inception_6a/3x3/scale1 <- inception_6a/3x3
I0316 12:04:37.494170 55708 net.cpp:367] inception_6a/3x3/scale1 -> inception_6a/3x3 (in-place)
I0316 12:04:37.494210 55708 layer_factory.hpp:77] Creating layer inception_6a/3x3/scale1
I0316 12:04:37.494330 55708 net.cpp:122] Setting up inception_6a/3x3/scale1
I0316 12:04:37.494338 55708 net.cpp:129] Top shape: 32 64 16 16 (524288)
I0316 12:04:37.494343 55708 net.cpp:137] Memory required for data: 292422144
I0316 12:04:37.494350 55708 layer_factory.hpp:77] Creating layer inception_6a/3x3/relu1
I0316 12:04:37.494356 55708 net.cpp:84] Creating Layer inception_6a/3x3/relu1
I0316 12:04:37.494360 55708 net.cpp:406] inception_6a/3x3/relu1 <- inception_6a/3x3
I0316 12:04:37.494369 55708 net.cpp:367] inception_6a/3x3/relu1 -> inception_6a/3x3 (in-place)
I0316 12:04:37.494375 55708 net.cpp:122] Setting up inception_6a/3x3/relu1
I0316 12:04:37.494381 55708 net.cpp:129] Top shape: 32 64 16 16 (524288)
I0316 12:04:37.494385 55708 net.cpp:137] Memory required for data: 294519296
I0316 12:04:37.494390 55708 layer_factory.hpp:77] Creating layer inception_6a/output
I0316 12:04:37.494396 55708 net.cpp:84] Creating Layer inception_6a/output
I0316 12:04:37.494400 55708 net.cpp:406] inception_6a/output <- inception_6a/1x1
I0316 12:04:37.494406 55708 net.cpp:406] inception_6a/output <- inception_6a/3x3
I0316 12:04:37.494413 55708 net.cpp:380] inception_6a/output -> inception_6a/output
I0316 12:04:37.494431 55708 net.cpp:122] Setting up inception_6a/output
I0316 12:04:37.494438 55708 net.cpp:129] Top shape: 32 160 16 16 (1310720)
I0316 12:04:37.494442 55708 net.cpp:137] Memory required for data: 299762176
I0316 12:04:37.494447 55708 layer_factory.hpp:77] Creating layer inception_6a/output_inception_6a/output_0_split
I0316 12:04:37.494453 55708 net.cpp:84] Creating Layer inception_6a/output_inception_6a/output_0_split
I0316 12:04:37.494457 55708 net.cpp:406] inception_6a/output_inception_6a/output_0_split <- inception_6a/output
I0316 12:04:37.494464 55708 net.cpp:380] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_0
I0316 12:04:37.494473 55708 net.cpp:380] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_1
I0316 12:04:37.494518 55708 net.cpp:122] Setting up inception_6a/output_inception_6a/output_0_split
I0316 12:04:37.494525 55708 net.cpp:129] Top shape: 32 160 16 16 (1310720)
I0316 12:04:37.494532 55708 net.cpp:129] Top shape: 32 160 16 16 (1310720)
I0316 12:04:37.494537 55708 net.cpp:137] Memory required for data: 310247936
I0316 12:04:37.494541 55708 layer_factory.hpp:77] Creating layer inception_7a/1x1
I0316 12:04:37.494550 55708 net.cpp:84] Creating Layer inception_7a/1x1
I0316 12:04:37.494555 55708 net.cpp:406] inception_7a/1x1 <- inception_6a/output_inception_6a/output_0_split_0
I0316 12:04:37.494565 55708 net.cpp:380] inception_7a/1x1 -> inception_7a/1x1
I0316 12:04:37.494944 55708 net.cpp:122] Setting up inception_7a/1x1
I0316 12:04:37.494953 55708 net.cpp:129] Top shape: 32 80 16 16 (655360)
I0316 12:04:37.494957 55708 net.cpp:137] Memory required for data: 312869376
I0316 12:04:37.494976 55708 layer_factory.hpp:77] Creating layer inception_7a/1x1/bn1
I0316 12:04:37.494983 55708 net.cpp:84] Creating Layer inception_7a/1x1/bn1
I0316 12:04:37.494988 55708 net.cpp:406] inception_7a/1x1/bn1 <- inception_7a/1x1
I0316 12:04:37.494995 55708 net.cpp:367] inception_7a/1x1/bn1 -> inception_7a/1x1 (in-place)
I0316 12:04:37.495210 55708 net.cpp:122] Setting up inception_7a/1x1/bn1
I0316 12:04:37.495218 55708 net.cpp:129] Top shape: 32 80 16 16 (655360)
I0316 12:04:37.495222 55708 net.cpp:137] Memory required for data: 315490816
I0316 12:04:37.495231 55708 layer_factory.hpp:77] Creating layer inception_7a/1x1/scale1
I0316 12:04:37.495239 55708 net.cpp:84] Creating Layer inception_7a/1x1/scale1
I0316 12:04:37.495244 55708 net.cpp:406] inception_7a/1x1/scale1 <- inception_7a/1x1
I0316 12:04:37.495249 55708 net.cpp:367] inception_7a/1x1/scale1 -> inception_7a/1x1 (in-place)
I0316 12:04:37.495288 55708 layer_factory.hpp:77] Creating layer inception_7a/1x1/scale1
I0316 12:04:37.495416 55708 net.cpp:122] Setting up inception_7a/1x1/scale1
I0316 12:04:37.495425 55708 net.cpp:129] Top shape: 32 80 16 16 (655360)
I0316 12:04:37.495430 55708 net.cpp:137] Memory required for data: 318112256
I0316 12:04:37.495437 55708 layer_factory.hpp:77] Creating layer inception_7a/1x1/relu1
I0316 12:04:37.495445 55708 net.cpp:84] Creating Layer inception_7a/1x1/relu1
I0316 12:04:37.495448 55708 net.cpp:406] inception_7a/1x1/relu1 <- inception_7a/1x1
I0316 12:04:37.495455 55708 net.cpp:367] inception_7a/1x1/relu1 -> inception_7a/1x1 (in-place)
I0316 12:04:37.495460 55708 net.cpp:122] Setting up inception_7a/1x1/relu1
I0316 12:04:37.495467 55708 net.cpp:129] Top shape: 32 80 16 16 (655360)
I0316 12:04:37.495471 55708 net.cpp:137] Memory required for data: 320733696
I0316 12:04:37.495476 55708 layer_factory.hpp:77] Creating layer inception_7a/3x3
I0316 12:04:37.495483 55708 net.cpp:84] Creating Layer inception_7a/3x3
I0316 12:04:37.495489 55708 net.cpp:406] inception_7a/3x3 <- inception_6a/output_inception_6a/output_0_split_1
I0316 12:04:37.495496 55708 net.cpp:380] inception_7a/3x3 -> inception_7a/3x3
I0316 12:04:37.496752 55708 net.cpp:122] Setting up inception_7a/3x3
I0316 12:04:37.496764 55708 net.cpp:129] Top shape: 32 80 16 16 (655360)
I0316 12:04:37.496769 55708 net.cpp:137] Memory required for data: 323355136
I0316 12:04:37.496778 55708 layer_factory.hpp:77] Creating layer inception_7a/3x3/bn1
I0316 12:04:37.496786 55708 net.cpp:84] Creating Layer inception_7a/3x3/bn1
I0316 12:04:37.496790 55708 net.cpp:406] inception_7a/3x3/bn1 <- inception_7a/3x3
I0316 12:04:37.496799 55708 net.cpp:367] inception_7a/3x3/bn1 -> inception_7a/3x3 (in-place)
I0316 12:04:37.497014 55708 net.cpp:122] Setting up inception_7a/3x3/bn1
I0316 12:04:37.497023 55708 net.cpp:129] Top shape: 32 80 16 16 (655360)
I0316 12:04:37.497028 55708 net.cpp:137] Memory required for data: 325976576
I0316 12:04:37.497037 55708 layer_factory.hpp:77] Creating layer inception_7a/3x3/scale1
I0316 12:04:37.497045 55708 net.cpp:84] Creating Layer inception_7a/3x3/scale1
I0316 12:04:37.497048 55708 net.cpp:406] inception_7a/3x3/scale1 <- inception_7a/3x3
I0316 12:04:37.497054 55708 net.cpp:367] inception_7a/3x3/scale1 -> inception_7a/3x3 (in-place)
I0316 12:04:37.497097 55708 layer_factory.hpp:77] Creating layer inception_7a/3x3/scale1
I0316 12:04:37.497220 55708 net.cpp:122] Setting up inception_7a/3x3/scale1
I0316 12:04:37.497228 55708 net.cpp:129] Top shape: 32 80 16 16 (655360)
I0316 12:04:37.497232 55708 net.cpp:137] Memory required for data: 328598016
I0316 12:04:37.497241 55708 layer_factory.hpp:77] Creating layer inception_7a/3x3/relu1
I0316 12:04:37.497246 55708 net.cpp:84] Creating Layer inception_7a/3x3/relu1
I0316 12:04:37.497251 55708 net.cpp:406] inception_7a/3x3/relu1 <- inception_7a/3x3
I0316 12:04:37.497256 55708 net.cpp:367] inception_7a/3x3/relu1 -> inception_7a/3x3 (in-place)
I0316 12:04:37.497263 55708 net.cpp:122] Setting up inception_7a/3x3/relu1
I0316 12:04:37.497269 55708 net.cpp:129] Top shape: 32 80 16 16 (655360)
I0316 12:04:37.497273 55708 net.cpp:137] Memory required for data: 331219456
I0316 12:04:37.497289 55708 layer_factory.hpp:77] Creating layer inception_7a/output
I0316 12:04:37.497296 55708 net.cpp:84] Creating Layer inception_7a/output
I0316 12:04:37.497300 55708 net.cpp:406] inception_7a/output <- inception_7a/1x1
I0316 12:04:37.497306 55708 net.cpp:406] inception_7a/output <- inception_7a/3x3
I0316 12:04:37.497313 55708 net.cpp:380] inception_7a/output -> inception_7a/output
I0316 12:04:37.497332 55708 net.cpp:122] Setting up inception_7a/output
I0316 12:04:37.497340 55708 net.cpp:129] Top shape: 32 160 16 16 (1310720)
I0316 12:04:37.497344 55708 net.cpp:137] Memory required for data: 336462336
I0316 12:04:37.497349 55708 layer_factory.hpp:77] Creating layer inception_7a/output_inception_7a/output_0_split
I0316 12:04:37.497356 55708 net.cpp:84] Creating Layer inception_7a/output_inception_7a/output_0_split
I0316 12:04:37.497360 55708 net.cpp:406] inception_7a/output_inception_7a/output_0_split <- inception_7a/output
I0316 12:04:37.497366 55708 net.cpp:380] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_0
I0316 12:04:37.497375 55708 net.cpp:380] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_1
I0316 12:04:37.497412 55708 net.cpp:122] Setting up inception_7a/output_inception_7a/output_0_split
I0316 12:04:37.497421 55708 net.cpp:129] Top shape: 32 160 16 16 (1310720)
I0316 12:04:37.497426 55708 net.cpp:129] Top shape: 32 160 16 16 (1310720)
I0316 12:04:37.497431 55708 net.cpp:137] Memory required for data: 346948096
I0316 12:04:37.497435 55708 layer_factory.hpp:77] Creating layer inception_8a/1x1
I0316 12:04:37.497458 55708 net.cpp:84] Creating Layer inception_8a/1x1
I0316 12:04:37.497463 55708 net.cpp:406] inception_8a/1x1 <- inception_7a/output_inception_7a/output_0_split_0
I0316 12:04:37.497470 55708 net.cpp:380] inception_8a/1x1 -> inception_8a/1x1
I0316 12:04:37.497742 55708 net.cpp:122] Setting up inception_8a/1x1
I0316 12:04:37.497748 55708 net.cpp:129] Top shape: 32 48 16 16 (393216)
I0316 12:04:37.497751 55708 net.cpp:137] Memory required for data: 348520960
I0316 12:04:37.497757 55708 layer_factory.hpp:77] Creating layer inception_8a/1x1/bn1
I0316 12:04:37.497763 55708 net.cpp:84] Creating Layer inception_8a/1x1/bn1
I0316 12:04:37.497766 55708 net.cpp:406] inception_8a/1x1/bn1 <- inception_8a/1x1
I0316 12:04:37.497771 55708 net.cpp:367] inception_8a/1x1/bn1 -> inception_8a/1x1 (in-place)
I0316 12:04:37.497929 55708 net.cpp:122] Setting up inception_8a/1x1/bn1
I0316 12:04:37.497936 55708 net.cpp:129] Top shape: 32 48 16 16 (393216)
I0316 12:04:37.497939 55708 net.cpp:137] Memory required for data: 350093824
I0316 12:04:37.497946 55708 layer_factory.hpp:77] Creating layer inception_8a/1x1/scale1
I0316 12:04:37.497951 55708 net.cpp:84] Creating Layer inception_8a/1x1/scale1
I0316 12:04:37.497954 55708 net.cpp:406] inception_8a/1x1/scale1 <- inception_8a/1x1
I0316 12:04:37.497959 55708 net.cpp:367] inception_8a/1x1/scale1 -> inception_8a/1x1 (in-place)
I0316 12:04:37.497987 55708 layer_factory.hpp:77] Creating layer inception_8a/1x1/scale1
I0316 12:04:37.498075 55708 net.cpp:122] Setting up inception_8a/1x1/scale1
I0316 12:04:37.498083 55708 net.cpp:129] Top shape: 32 48 16 16 (393216)
I0316 12:04:37.498086 55708 net.cpp:137] Memory required for data: 351666688
I0316 12:04:37.498090 55708 layer_factory.hpp:77] Creating layer inception_8a/1x1/relu1
I0316 12:04:37.498095 55708 net.cpp:84] Creating Layer inception_8a/1x1/relu1
I0316 12:04:37.498100 55708 net.cpp:406] inception_8a/1x1/relu1 <- inception_8a/1x1
I0316 12:04:37.498103 55708 net.cpp:367] inception_8a/1x1/relu1 -> inception_8a/1x1 (in-place)
I0316 12:04:37.498108 55708 net.cpp:122] Setting up inception_8a/1x1/relu1
I0316 12:04:37.498112 55708 net.cpp:129] Top shape: 32 48 16 16 (393216)
I0316 12:04:37.498116 55708 net.cpp:137] Memory required for data: 353239552
I0316 12:04:37.498118 55708 layer_factory.hpp:77] Creating layer inception_8a/3x3
I0316 12:04:37.498126 55708 net.cpp:84] Creating Layer inception_8a/3x3
I0316 12:04:37.498136 55708 net.cpp:406] inception_8a/3x3 <- inception_7a/output_inception_7a/output_0_split_1
I0316 12:04:37.498143 55708 net.cpp:380] inception_8a/3x3 -> inception_8a/3x3
I0316 12:04:37.500471 55708 net.cpp:122] Setting up inception_8a/3x3
I0316 12:04:37.500486 55708 net.cpp:129] Top shape: 32 96 16 16 (786432)
I0316 12:04:37.500489 55708 net.cpp:137] Memory required for data: 356385280
I0316 12:04:37.500497 55708 layer_factory.hpp:77] Creating layer inception_8a/3x3/bn1
I0316 12:04:37.500504 55708 net.cpp:84] Creating Layer inception_8a/3x3/bn1
I0316 12:04:37.500509 55708 net.cpp:406] inception_8a/3x3/bn1 <- inception_8a/3x3
I0316 12:04:37.500514 55708 net.cpp:367] inception_8a/3x3/bn1 -> inception_8a/3x3 (in-place)
I0316 12:04:37.500676 55708 net.cpp:122] Setting up inception_8a/3x3/bn1
I0316 12:04:37.500684 55708 net.cpp:129] Top shape: 32 96 16 16 (786432)
I0316 12:04:37.500686 55708 net.cpp:137] Memory required for data: 359531008
I0316 12:04:37.500692 55708 layer_factory.hpp:77] Creating layer inception_8a/3x3/scale1
I0316 12:04:37.500699 55708 net.cpp:84] Creating Layer inception_8a/3x3/scale1
I0316 12:04:37.500702 55708 net.cpp:406] inception_8a/3x3/scale1 <- inception_8a/3x3
I0316 12:04:37.500707 55708 net.cpp:367] inception_8a/3x3/scale1 -> inception_8a/3x3 (in-place)
I0316 12:04:37.500736 55708 layer_factory.hpp:77] Creating layer inception_8a/3x3/scale1
I0316 12:04:37.500829 55708 net.cpp:122] Setting up inception_8a/3x3/scale1
I0316 12:04:37.500836 55708 net.cpp:129] Top shape: 32 96 16 16 (786432)
I0316 12:04:37.500839 55708 net.cpp:137] Memory required for data: 362676736
I0316 12:04:37.500844 55708 layer_factory.hpp:77] Creating layer inception_8a/3x3/relu1
I0316 12:04:37.500849 55708 net.cpp:84] Creating Layer inception_8a/3x3/relu1
I0316 12:04:37.500852 55708 net.cpp:406] inception_8a/3x3/relu1 <- inception_8a/3x3
I0316 12:04:37.500857 55708 net.cpp:367] inception_8a/3x3/relu1 -> inception_8a/3x3 (in-place)
I0316 12:04:37.500861 55708 net.cpp:122] Setting up inception_8a/3x3/relu1
I0316 12:04:37.500866 55708 net.cpp:129] Top shape: 32 96 16 16 (786432)
I0316 12:04:37.500869 55708 net.cpp:137] Memory required for data: 365822464
I0316 12:04:37.500872 55708 layer_factory.hpp:77] Creating layer inception_8a/output
I0316 12:04:37.500877 55708 net.cpp:84] Creating Layer inception_8a/output
I0316 12:04:37.500881 55708 net.cpp:406] inception_8a/output <- inception_8a/1x1
I0316 12:04:37.500885 55708 net.cpp:406] inception_8a/output <- inception_8a/3x3
I0316 12:04:37.500890 55708 net.cpp:380] inception_8a/output -> inception_8a/output
I0316 12:04:37.500903 55708 net.cpp:122] Setting up inception_8a/output
I0316 12:04:37.500908 55708 net.cpp:129] Top shape: 32 144 16 16 (1179648)
I0316 12:04:37.500911 55708 net.cpp:137] Memory required for data: 370541056
I0316 12:04:37.500916 55708 layer_factory.hpp:77] Creating layer inception_8a/output_inception_8a/output_0_split
I0316 12:04:37.500921 55708 net.cpp:84] Creating Layer inception_8a/output_inception_8a/output_0_split
I0316 12:04:37.500924 55708 net.cpp:406] inception_8a/output_inception_8a/output_0_split <- inception_8a/output
I0316 12:04:37.500929 55708 net.cpp:380] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_0
I0316 12:04:37.500934 55708 net.cpp:380] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_1
I0316 12:04:37.500962 55708 net.cpp:122] Setting up inception_8a/output_inception_8a/output_0_split
I0316 12:04:37.500967 55708 net.cpp:129] Top shape: 32 144 16 16 (1179648)
I0316 12:04:37.500970 55708 net.cpp:129] Top shape: 32 144 16 16 (1179648)
I0316 12:04:37.500973 55708 net.cpp:137] Memory required for data: 379978240
I0316 12:04:37.500977 55708 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2
I0316 12:04:37.500984 55708 net.cpp:84] Creating Layer downsample_9/3x3_s2
I0316 12:04:37.500988 55708 net.cpp:406] downsample_9/3x3_s2 <- inception_8a/output_inception_8a/output_0_split_0
I0316 12:04:37.501006 55708 net.cpp:380] downsample_9/3x3_s2 -> downsample_9/3x3_s2
I0316 12:04:37.502002 55708 net.cpp:122] Setting up downsample_9/3x3_s2
I0316 12:04:37.502010 55708 net.cpp:129] Top shape: 32 96 8 8 (196608)
I0316 12:04:37.502014 55708 net.cpp:137] Memory required for data: 380764672
I0316 12:04:37.502020 55708 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/bn1
I0316 12:04:37.502027 55708 net.cpp:84] Creating Layer downsample_9/3x3_s2/bn1
I0316 12:04:37.502032 55708 net.cpp:406] downsample_9/3x3_s2/bn1 <- downsample_9/3x3_s2
I0316 12:04:37.502036 55708 net.cpp:367] downsample_9/3x3_s2/bn1 -> downsample_9/3x3_s2 (in-place)
I0316 12:04:37.502198 55708 net.cpp:122] Setting up downsample_9/3x3_s2/bn1
I0316 12:04:37.502204 55708 net.cpp:129] Top shape: 32 96 8 8 (196608)
I0316 12:04:37.502208 55708 net.cpp:137] Memory required for data: 381551104
I0316 12:04:37.502215 55708 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/scale1
I0316 12:04:37.502220 55708 net.cpp:84] Creating Layer downsample_9/3x3_s2/scale1
I0316 12:04:37.502223 55708 net.cpp:406] downsample_9/3x3_s2/scale1 <- downsample_9/3x3_s2
I0316 12:04:37.502228 55708 net.cpp:367] downsample_9/3x3_s2/scale1 -> downsample_9/3x3_s2 (in-place)
I0316 12:04:37.502257 55708 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/scale1
I0316 12:04:37.502352 55708 net.cpp:122] Setting up downsample_9/3x3_s2/scale1
I0316 12:04:37.502358 55708 net.cpp:129] Top shape: 32 96 8 8 (196608)
I0316 12:04:37.502362 55708 net.cpp:137] Memory required for data: 382337536
I0316 12:04:37.502367 55708 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/relu1
I0316 12:04:37.502372 55708 net.cpp:84] Creating Layer downsample_9/3x3_s2/relu1
I0316 12:04:37.502374 55708 net.cpp:406] downsample_9/3x3_s2/relu1 <- downsample_9/3x3_s2
I0316 12:04:37.502380 55708 net.cpp:367] downsample_9/3x3_s2/relu1 -> downsample_9/3x3_s2 (in-place)
I0316 12:04:37.502384 55708 net.cpp:122] Setting up downsample_9/3x3_s2/relu1
I0316 12:04:37.502388 55708 net.cpp:129] Top shape: 32 96 8 8 (196608)
I0316 12:04:37.502393 55708 net.cpp:137] Memory required for data: 383123968
I0316 12:04:37.502396 55708 layer_factory.hpp:77] Creating layer downsample_9/pool_s2
I0316 12:04:37.502401 55708 net.cpp:84] Creating Layer downsample_9/pool_s2
I0316 12:04:37.502404 55708 net.cpp:406] downsample_9/pool_s2 <- inception_8a/output_inception_8a/output_0_split_1
I0316 12:04:37.502409 55708 net.cpp:380] downsample_9/pool_s2 -> downsample_9/pool_s2
I0316 12:04:37.502439 55708 net.cpp:122] Setting up downsample_9/pool_s2
I0316 12:04:37.502449 55708 net.cpp:129] Top shape: 32 144 8 8 (294912)
I0316 12:04:37.502450 55708 net.cpp:137] Memory required for data: 384303616
I0316 12:04:37.502454 55708 layer_factory.hpp:77] Creating layer downsample_9/output
I0316 12:04:37.502460 55708 net.cpp:84] Creating Layer downsample_9/output
I0316 12:04:37.502462 55708 net.cpp:406] downsample_9/output <- downsample_9/3x3_s2
I0316 12:04:37.502466 55708 net.cpp:406] downsample_9/output <- downsample_9/pool_s2
I0316 12:04:37.502471 55708 net.cpp:380] downsample_9/output -> downsample_9/output
I0316 12:04:37.502488 55708 net.cpp:122] Setting up downsample_9/output
I0316 12:04:37.502492 55708 net.cpp:129] Top shape: 32 240 8 8 (491520)
I0316 12:04:37.502496 55708 net.cpp:137] Memory required for data: 386269696
I0316 12:04:37.502498 55708 layer_factory.hpp:77] Creating layer downsample_9/output_downsample_9/output_0_split
I0316 12:04:37.502504 55708 net.cpp:84] Creating Layer downsample_9/output_downsample_9/output_0_split
I0316 12:04:37.502507 55708 net.cpp:406] downsample_9/output_downsample_9/output_0_split <- downsample_9/output
I0316 12:04:37.502512 55708 net.cpp:380] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_0
I0316 12:04:37.502517 55708 net.cpp:380] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_1
I0316 12:04:37.502547 55708 net.cpp:122] Setting up downsample_9/output_downsample_9/output_0_split
I0316 12:04:37.502552 55708 net.cpp:129] Top shape: 32 240 8 8 (491520)
I0316 12:04:37.502565 55708 net.cpp:129] Top shape: 32 240 8 8 (491520)
I0316 12:04:37.502568 55708 net.cpp:137] Memory required for data: 390201856
I0316 12:04:37.502571 55708 layer_factory.hpp:77] Creating layer inception_10a/1x1
I0316 12:04:37.502578 55708 net.cpp:84] Creating Layer inception_10a/1x1
I0316 12:04:37.502583 55708 net.cpp:406] inception_10a/1x1 <- downsample_9/output_downsample_9/output_0_split_0
I0316 12:04:37.502588 55708 net.cpp:380] inception_10a/1x1 -> inception_10a/1x1
I0316 12:04:37.503072 55708 net.cpp:122] Setting up inception_10a/1x1
I0316 12:04:37.503079 55708 net.cpp:129] Top shape: 32 176 8 8 (360448)
I0316 12:04:37.503082 55708 net.cpp:137] Memory required for data: 391643648
I0316 12:04:37.503088 55708 layer_factory.hpp:77] Creating layer inception_10a/1x1/bn1
I0316 12:04:37.503094 55708 net.cpp:84] Creating Layer inception_10a/1x1/bn1
I0316 12:04:37.503098 55708 net.cpp:406] inception_10a/1x1/bn1 <- inception_10a/1x1
I0316 12:04:37.503103 55708 net.cpp:367] inception_10a/1x1/bn1 -> inception_10a/1x1 (in-place)
I0316 12:04:37.503266 55708 net.cpp:122] Setting up inception_10a/1x1/bn1
I0316 12:04:37.503273 55708 net.cpp:129] Top shape: 32 176 8 8 (360448)
I0316 12:04:37.503276 55708 net.cpp:137] Memory required for data: 393085440
I0316 12:04:37.503283 55708 layer_factory.hpp:77] Creating layer inception_10a/1x1/scale1
I0316 12:04:37.503288 55708 net.cpp:84] Creating Layer inception_10a/1x1/scale1
I0316 12:04:37.503291 55708 net.cpp:406] inception_10a/1x1/scale1 <- inception_10a/1x1
I0316 12:04:37.503295 55708 net.cpp:367] inception_10a/1x1/scale1 -> inception_10a/1x1 (in-place)
I0316 12:04:37.503324 55708 layer_factory.hpp:77] Creating layer inception_10a/1x1/scale1
I0316 12:04:37.503420 55708 net.cpp:122] Setting up inception_10a/1x1/scale1
I0316 12:04:37.503427 55708 net.cpp:129] Top shape: 32 176 8 8 (360448)
I0316 12:04:37.503430 55708 net.cpp:137] Memory required for data: 394527232
I0316 12:04:37.503435 55708 layer_factory.hpp:77] Creating layer inception_10a/1x1/relu1
I0316 12:04:37.503439 55708 net.cpp:84] Creating Layer inception_10a/1x1/relu1
I0316 12:04:37.503443 55708 net.cpp:406] inception_10a/1x1/relu1 <- inception_10a/1x1
I0316 12:04:37.503448 55708 net.cpp:367] inception_10a/1x1/relu1 -> inception_10a/1x1 (in-place)
I0316 12:04:37.503453 55708 net.cpp:122] Setting up inception_10a/1x1/relu1
I0316 12:04:37.503456 55708 net.cpp:129] Top shape: 32 176 8 8 (360448)
I0316 12:04:37.503460 55708 net.cpp:137] Memory required for data: 395969024
I0316 12:04:37.503463 55708 layer_factory.hpp:77] Creating layer inception_10a/3x3
I0316 12:04:37.503469 55708 net.cpp:84] Creating Layer inception_10a/3x3
I0316 12:04:37.503473 55708 net.cpp:406] inception_10a/3x3 <- downsample_9/output_downsample_9/output_0_split_1
I0316 12:04:37.503479 55708 net.cpp:380] inception_10a/3x3 -> inception_10a/3x3
I0316 12:04:37.507509 55708 net.cpp:122] Setting up inception_10a/3x3
I0316 12:04:37.507524 55708 net.cpp:129] Top shape: 32 160 8 8 (327680)
I0316 12:04:37.507529 55708 net.cpp:137] Memory required for data: 397279744
I0316 12:04:37.507535 55708 layer_factory.hpp:77] Creating layer inception_10a/3x3/bn1
I0316 12:04:37.507542 55708 net.cpp:84] Creating Layer inception_10a/3x3/bn1
I0316 12:04:37.507546 55708 net.cpp:406] inception_10a/3x3/bn1 <- inception_10a/3x3
I0316 12:04:37.507552 55708 net.cpp:367] inception_10a/3x3/bn1 -> inception_10a/3x3 (in-place)
I0316 12:04:37.507714 55708 net.cpp:122] Setting up inception_10a/3x3/bn1
I0316 12:04:37.507720 55708 net.cpp:129] Top shape: 32 160 8 8 (327680)
I0316 12:04:37.507723 55708 net.cpp:137] Memory required for data: 398590464
I0316 12:04:37.507730 55708 layer_factory.hpp:77] Creating layer inception_10a/3x3/scale1
I0316 12:04:37.507736 55708 net.cpp:84] Creating Layer inception_10a/3x3/scale1
I0316 12:04:37.507740 55708 net.cpp:406] inception_10a/3x3/scale1 <- inception_10a/3x3
I0316 12:04:37.507745 55708 net.cpp:367] inception_10a/3x3/scale1 -> inception_10a/3x3 (in-place)
I0316 12:04:37.507773 55708 layer_factory.hpp:77] Creating layer inception_10a/3x3/scale1
I0316 12:04:37.507879 55708 net.cpp:122] Setting up inception_10a/3x3/scale1
I0316 12:04:37.507885 55708 net.cpp:129] Top shape: 32 160 8 8 (327680)
I0316 12:04:37.507889 55708 net.cpp:137] Memory required for data: 399901184
I0316 12:04:37.507894 55708 layer_factory.hpp:77] Creating layer inception_10a/3x3/relu1
I0316 12:04:37.507899 55708 net.cpp:84] Creating Layer inception_10a/3x3/relu1
I0316 12:04:37.507902 55708 net.cpp:406] inception_10a/3x3/relu1 <- inception_10a/3x3
I0316 12:04:37.507906 55708 net.cpp:367] inception_10a/3x3/relu1 -> inception_10a/3x3 (in-place)
I0316 12:04:37.507911 55708 net.cpp:122] Setting up inception_10a/3x3/relu1
I0316 12:04:37.507916 55708 net.cpp:129] Top shape: 32 160 8 8 (327680)
I0316 12:04:37.507920 55708 net.cpp:137] Memory required for data: 401211904
I0316 12:04:37.507922 55708 layer_factory.hpp:77] Creating layer inception_10a/output
I0316 12:04:37.507926 55708 net.cpp:84] Creating Layer inception_10a/output
I0316 12:04:37.507930 55708 net.cpp:406] inception_10a/output <- inception_10a/1x1
I0316 12:04:37.507934 55708 net.cpp:406] inception_10a/output <- inception_10a/3x3
I0316 12:04:37.507938 55708 net.cpp:380] inception_10a/output -> inception_10a/output
I0316 12:04:37.507956 55708 net.cpp:122] Setting up inception_10a/output
I0316 12:04:37.507961 55708 net.cpp:129] Top shape: 32 336 8 8 (688128)
I0316 12:04:37.507963 55708 net.cpp:137] Memory required for data: 403964416
I0316 12:04:37.507966 55708 layer_factory.hpp:77] Creating layer inception_10a/output_inception_10a/output_0_split
I0316 12:04:37.507972 55708 net.cpp:84] Creating Layer inception_10a/output_inception_10a/output_0_split
I0316 12:04:37.507977 55708 net.cpp:406] inception_10a/output_inception_10a/output_0_split <- inception_10a/output
I0316 12:04:37.507980 55708 net.cpp:380] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_0
I0316 12:04:37.507987 55708 net.cpp:380] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_1
I0316 12:04:37.508013 55708 net.cpp:122] Setting up inception_10a/output_inception_10a/output_0_split
I0316 12:04:37.508018 55708 net.cpp:129] Top shape: 32 336 8 8 (688128)
I0316 12:04:37.508021 55708 net.cpp:129] Top shape: 32 336 8 8 (688128)
I0316 12:04:37.508024 55708 net.cpp:137] Memory required for data: 409469440
I0316 12:04:37.508026 55708 layer_factory.hpp:77] Creating layer inception_11a/1x1
I0316 12:04:37.508034 55708 net.cpp:84] Creating Layer inception_11a/1x1
I0316 12:04:37.508038 55708 net.cpp:406] inception_11a/1x1 <- inception_10a/output_inception_10a/output_0_split_0
I0316 12:04:37.508044 55708 net.cpp:380] inception_11a/1x1 -> inception_11a/1x1
I0316 12:04:37.508608 55708 net.cpp:122] Setting up inception_11a/1x1
I0316 12:04:37.508618 55708 net.cpp:129] Top shape: 32 176 8 8 (360448)
I0316 12:04:37.508621 55708 net.cpp:137] Memory required for data: 410911232
I0316 12:04:37.508626 55708 layer_factory.hpp:77] Creating layer inception_11a/1x1/bn1
I0316 12:04:37.508632 55708 net.cpp:84] Creating Layer inception_11a/1x1/bn1
I0316 12:04:37.508637 55708 net.cpp:406] inception_11a/1x1/bn1 <- inception_11a/1x1
I0316 12:04:37.508642 55708 net.cpp:367] inception_11a/1x1/bn1 -> inception_11a/1x1 (in-place)
I0316 12:04:37.508800 55708 net.cpp:122] Setting up inception_11a/1x1/bn1
I0316 12:04:37.508805 55708 net.cpp:129] Top shape: 32 176 8 8 (360448)
I0316 12:04:37.508810 55708 net.cpp:137] Memory required for data: 412353024
I0316 12:04:37.508816 55708 layer_factory.hpp:77] Creating layer inception_11a/1x1/scale1
I0316 12:04:37.508821 55708 net.cpp:84] Creating Layer inception_11a/1x1/scale1
I0316 12:04:37.508824 55708 net.cpp:406] inception_11a/1x1/scale1 <- inception_11a/1x1
I0316 12:04:37.508829 55708 net.cpp:367] inception_11a/1x1/scale1 -> inception_11a/1x1 (in-place)
I0316 12:04:37.508857 55708 layer_factory.hpp:77] Creating layer inception_11a/1x1/scale1
I0316 12:04:37.508945 55708 net.cpp:122] Setting up inception_11a/1x1/scale1
I0316 12:04:37.508961 55708 net.cpp:129] Top shape: 32 176 8 8 (360448)
I0316 12:04:37.508965 55708 net.cpp:137] Memory required for data: 413794816
I0316 12:04:37.508970 55708 layer_factory.hpp:77] Creating layer inception_11a/1x1/relu1
I0316 12:04:37.508975 55708 net.cpp:84] Creating Layer inception_11a/1x1/relu1
I0316 12:04:37.508978 55708 net.cpp:406] inception_11a/1x1/relu1 <- inception_11a/1x1
I0316 12:04:37.508985 55708 net.cpp:367] inception_11a/1x1/relu1 -> inception_11a/1x1 (in-place)
I0316 12:04:37.508989 55708 net.cpp:122] Setting up inception_11a/1x1/relu1
I0316 12:04:37.508993 55708 net.cpp:129] Top shape: 32 176 8 8 (360448)
I0316 12:04:37.508996 55708 net.cpp:137] Memory required for data: 415236608
I0316 12:04:37.509001 55708 layer_factory.hpp:77] Creating layer inception_11a/3x3
I0316 12:04:37.509007 55708 net.cpp:84] Creating Layer inception_11a/3x3
I0316 12:04:37.509011 55708 net.cpp:406] inception_11a/3x3 <- inception_10a/output_inception_10a/output_0_split_1
I0316 12:04:37.509016 55708 net.cpp:380] inception_11a/3x3 -> inception_11a/3x3
I0316 12:04:37.513746 55708 net.cpp:122] Setting up inception_11a/3x3
I0316 12:04:37.513764 55708 net.cpp:129] Top shape: 32 160 8 8 (327680)
I0316 12:04:37.513768 55708 net.cpp:137] Memory required for data: 416547328
I0316 12:04:37.513775 55708 layer_factory.hpp:77] Creating layer inception_11a/3x3/bn1
I0316 12:04:37.513784 55708 net.cpp:84] Creating Layer inception_11a/3x3/bn1
I0316 12:04:37.513788 55708 net.cpp:406] inception_11a/3x3/bn1 <- inception_11a/3x3
I0316 12:04:37.513795 55708 net.cpp:367] inception_11a/3x3/bn1 -> inception_11a/3x3 (in-place)
I0316 12:04:37.513976 55708 net.cpp:122] Setting up inception_11a/3x3/bn1
I0316 12:04:37.513984 55708 net.cpp:129] Top shape: 32 160 8 8 (327680)
I0316 12:04:37.513988 55708 net.cpp:137] Memory required for data: 417858048
I0316 12:04:37.514005 55708 layer_factory.hpp:77] Creating layer inception_11a/3x3/scale1
I0316 12:04:37.514010 55708 net.cpp:84] Creating Layer inception_11a/3x3/scale1
I0316 12:04:37.514014 55708 net.cpp:406] inception_11a/3x3/scale1 <- inception_11a/3x3
I0316 12:04:37.514019 55708 net.cpp:367] inception_11a/3x3/scale1 -> inception_11a/3x3 (in-place)
I0316 12:04:37.514048 55708 layer_factory.hpp:77] Creating layer inception_11a/3x3/scale1
I0316 12:04:37.514138 55708 net.cpp:122] Setting up inception_11a/3x3/scale1
I0316 12:04:37.514145 55708 net.cpp:129] Top shape: 32 160 8 8 (327680)
I0316 12:04:37.514149 55708 net.cpp:137] Memory required for data: 419168768
I0316 12:04:37.514154 55708 layer_factory.hpp:77] Creating layer inception_11a/3x3/relu1
I0316 12:04:37.514158 55708 net.cpp:84] Creating Layer inception_11a/3x3/relu1
I0316 12:04:37.514163 55708 net.cpp:406] inception_11a/3x3/relu1 <- inception_11a/3x3
I0316 12:04:37.514168 55708 net.cpp:367] inception_11a/3x3/relu1 -> inception_11a/3x3 (in-place)
I0316 12:04:37.514171 55708 net.cpp:122] Setting up inception_11a/3x3/relu1
I0316 12:04:37.514175 55708 net.cpp:129] Top shape: 32 160 8 8 (327680)
I0316 12:04:37.514179 55708 net.cpp:137] Memory required for data: 420479488
I0316 12:04:37.514183 55708 layer_factory.hpp:77] Creating layer inception_11a/output
I0316 12:04:37.514186 55708 net.cpp:84] Creating Layer inception_11a/output
I0316 12:04:37.514189 55708 net.cpp:406] inception_11a/output <- inception_11a/1x1
I0316 12:04:37.514194 55708 net.cpp:406] inception_11a/output <- inception_11a/3x3
I0316 12:04:37.514199 55708 net.cpp:380] inception_11a/output -> inception_11a/output
I0316 12:04:37.514214 55708 net.cpp:122] Setting up inception_11a/output
I0316 12:04:37.514219 55708 net.cpp:129] Top shape: 32 336 8 8 (688128)
I0316 12:04:37.514223 55708 net.cpp:137] Memory required for data: 423232000
I0316 12:04:37.514225 55708 layer_factory.hpp:77] Creating layer avg_pool_12/8x8_s1
I0316 12:04:37.514230 55708 net.cpp:84] Creating Layer avg_pool_12/8x8_s1
I0316 12:04:37.514233 55708 net.cpp:406] avg_pool_12/8x8_s1 <- inception_11a/output
I0316 12:04:37.514240 55708 net.cpp:380] avg_pool_12/8x8_s1 -> avg_pool_12/8x8_s1
I0316 12:04:37.514256 55708 net.cpp:122] Setting up avg_pool_12/8x8_s1
I0316 12:04:37.514273 55708 net.cpp:129] Top shape: 32 336 1 1 (10752)
I0316 12:04:37.514276 55708 net.cpp:137] Memory required for data: 423275008
I0316 12:04:37.514281 55708 layer_factory.hpp:77] Creating layer drop_8x8_s1
I0316 12:04:37.514286 55708 net.cpp:84] Creating Layer drop_8x8_s1
I0316 12:04:37.514289 55708 net.cpp:406] drop_8x8_s1 <- avg_pool_12/8x8_s1
I0316 12:04:37.514293 55708 net.cpp:367] drop_8x8_s1 -> avg_pool_12/8x8_s1 (in-place)
I0316 12:04:37.514312 55708 net.cpp:122] Setting up drop_8x8_s1
I0316 12:04:37.514315 55708 net.cpp:129] Top shape: 32 336 1 1 (10752)
I0316 12:04:37.514318 55708 net.cpp:137] Memory required for data: 423318016
I0316 12:04:37.514322 55708 layer_factory.hpp:77] Creating layer latent
I0316 12:04:37.514328 55708 net.cpp:84] Creating Layer latent
I0316 12:04:37.514330 55708 net.cpp:406] latent <- avg_pool_12/8x8_s1
I0316 12:04:37.514335 55708 net.cpp:380] latent -> latent
I0316 12:04:37.514676 55708 net.cpp:122] Setting up latent
I0316 12:04:37.514690 55708 net.cpp:129] Top shape: 32 48 (1536)
I0316 12:04:37.514698 55708 net.cpp:137] Memory required for data: 423324160
I0316 12:04:37.514710 55708 layer_factory.hpp:77] Creating layer latent_sigmoid
I0316 12:04:37.514727 55708 net.cpp:84] Creating Layer latent_sigmoid
I0316 12:04:37.514737 55708 net.cpp:406] latent_sigmoid <- latent
I0316 12:04:37.514747 55708 net.cpp:380] latent_sigmoid -> latent_sigmoid
I0316 12:04:37.514778 55708 net.cpp:122] Setting up latent_sigmoid
I0316 12:04:37.514791 55708 net.cpp:129] Top shape: 32 48 (1536)
I0316 12:04:37.514799 55708 net.cpp:137] Memory required for data: 423330304
I0316 12:04:37.514804 55708 layer_factory.hpp:77] Creating layer latent_sigmoid_latent_sigmoid_0_split
I0316 12:04:37.514815 55708 net.cpp:84] Creating Layer latent_sigmoid_latent_sigmoid_0_split
I0316 12:04:37.514823 55708 net.cpp:406] latent_sigmoid_latent_sigmoid_0_split <- latent_sigmoid
I0316 12:04:37.514838 55708 net.cpp:380] latent_sigmoid_latent_sigmoid_0_split -> latent_sigmoid_latent_sigmoid_0_split_0
I0316 12:04:37.514851 55708 net.cpp:380] latent_sigmoid_latent_sigmoid_0_split -> latent_sigmoid_latent_sigmoid_0_split_1
I0316 12:04:37.514858 55708 net.cpp:380] latent_sigmoid_latent_sigmoid_0_split -> latent_sigmoid_latent_sigmoid_0_split_2
I0316 12:04:37.514863 55708 net.cpp:380] latent_sigmoid_latent_sigmoid_0_split -> latent_sigmoid_latent_sigmoid_0_split_3
I0316 12:04:37.514909 55708 net.cpp:122] Setting up latent_sigmoid_latent_sigmoid_0_split
I0316 12:04:37.514915 55708 net.cpp:129] Top shape: 32 48 (1536)
I0316 12:04:37.514919 55708 net.cpp:129] Top shape: 32 48 (1536)
I0316 12:04:37.514922 55708 net.cpp:129] Top shape: 32 48 (1536)
I0316 12:04:37.514926 55708 net.cpp:129] Top shape: 32 48 (1536)
I0316 12:04:37.514930 55708 net.cpp:137] Memory required for data: 423354880
I0316 12:04:37.514932 55708 layer_factory.hpp:77] Creating layer loss_1
I0316 12:04:37.514937 55708 net.cpp:84] Creating Layer loss_1
I0316 12:04:37.514941 55708 net.cpp:406] loss_1 <- latent_sigmoid_latent_sigmoid_0_split_0
I0316 12:04:37.514945 55708 net.cpp:406] loss_1 <- latent_sigmoid_latent_sigmoid_0_split_1
I0316 12:04:37.514950 55708 net.cpp:380] loss_1 -> loss: forcing-binary
I0316 12:04:37.514977 55708 net.cpp:122] Setting up loss_1
I0316 12:04:37.514984 55708 net.cpp:129] Top shape: (1)
I0316 12:04:37.514987 55708 net.cpp:132]     with loss weight 1
I0316 12:04:37.514997 55708 net.cpp:137] Memory required for data: 423354884
I0316 12:04:37.514999 55708 layer_factory.hpp:77] Creating layer latent_sigmoid_reshape
I0316 12:04:37.515007 55708 net.cpp:84] Creating Layer latent_sigmoid_reshape
I0316 12:04:37.515009 55708 net.cpp:406] latent_sigmoid_reshape <- latent_sigmoid_latent_sigmoid_0_split_2
I0316 12:04:37.515015 55708 net.cpp:380] latent_sigmoid_reshape -> latent_sigmoid_reshape
I0316 12:04:37.515074 55708 net.cpp:122] Setting up latent_sigmoid_reshape
I0316 12:04:37.515086 55708 net.cpp:129] Top shape: 32 1 1 48 (1536)
I0316 12:04:37.515089 55708 net.cpp:137] Memory required for data: 423361028
I0316 12:04:37.515110 55708 layer_factory.hpp:77] Creating layer latent_sigmoid_avg
I0316 12:04:37.515116 55708 net.cpp:84] Creating Layer latent_sigmoid_avg
I0316 12:04:37.515125 55708 net.cpp:406] latent_sigmoid_avg <- latent_sigmoid_reshape
I0316 12:04:37.515133 55708 net.cpp:380] latent_sigmoid_avg -> latent_sigmoid_avg
I0316 12:04:37.515173 55708 net.cpp:122] Setting up latent_sigmoid_avg
I0316 12:04:37.515180 55708 net.cpp:129] Top shape: 32 1 1 1 (32)
I0316 12:04:37.515184 55708 net.cpp:137] Memory required for data: 423361156
I0316 12:04:37.515187 55708 layer_factory.hpp:77] Creating layer latent_sigmoid_avg_latent_sigmoid_avg_0_split
I0316 12:04:37.515199 55708 net.cpp:84] Creating Layer latent_sigmoid_avg_latent_sigmoid_avg_0_split
I0316 12:04:37.515205 55708 net.cpp:406] latent_sigmoid_avg_latent_sigmoid_avg_0_split <- latent_sigmoid_avg
I0316 12:04:37.515218 55708 net.cpp:380] latent_sigmoid_avg_latent_sigmoid_avg_0_split -> latent_sigmoid_avg_latent_sigmoid_avg_0_split_0
I0316 12:04:37.515229 55708 net.cpp:380] latent_sigmoid_avg_latent_sigmoid_avg_0_split -> latent_sigmoid_avg_latent_sigmoid_avg_0_split_1
I0316 12:04:37.515290 55708 net.cpp:122] Setting up latent_sigmoid_avg_latent_sigmoid_avg_0_split
I0316 12:04:37.515305 55708 net.cpp:129] Top shape: 32 1 1 1 (32)
I0316 12:04:37.515311 55708 net.cpp:129] Top shape: 32 1 1 1 (32)
I0316 12:04:37.515314 55708 net.cpp:137] Memory required for data: 423361412
I0316 12:04:37.515318 55708 layer_factory.hpp:77] Creating layer loss_2
I0316 12:04:37.515329 55708 net.cpp:84] Creating Layer loss_2
I0316 12:04:37.515337 55708 net.cpp:406] loss_2 <- latent_sigmoid_avg_latent_sigmoid_avg_0_split_0
I0316 12:04:37.515341 55708 net.cpp:406] loss_2 <- latent_sigmoid_avg_latent_sigmoid_avg_0_split_1
I0316 12:04:37.515347 55708 net.cpp:380] loss_2 -> loss: 50%-fire-rate
I0316 12:04:37.515406 55708 net.cpp:122] Setting up loss_2
I0316 12:04:37.515416 55708 net.cpp:129] Top shape: (1)
I0316 12:04:37.515422 55708 net.cpp:132]     with loss weight 1
I0316 12:04:37.515432 55708 net.cpp:137] Memory required for data: 423361416
I0316 12:04:37.515436 55708 layer_factory.hpp:77] Creating layer fc10
I0316 12:04:37.515448 55708 net.cpp:84] Creating Layer fc10
I0316 12:04:37.515456 55708 net.cpp:406] fc10 <- latent_sigmoid_latent_sigmoid_0_split_3
I0316 12:04:37.515465 55708 net.cpp:380] fc10 -> fc10
I0316 12:04:37.515617 55708 net.cpp:122] Setting up fc10
I0316 12:04:37.515625 55708 net.cpp:129] Top shape: 32 10 (320)
I0316 12:04:37.515630 55708 net.cpp:137] Memory required for data: 423362696
I0316 12:04:37.515635 55708 layer_factory.hpp:77] Creating layer fc10_fc10_0_split
I0316 12:04:37.515641 55708 net.cpp:84] Creating Layer fc10_fc10_0_split
I0316 12:04:37.515647 55708 net.cpp:406] fc10_fc10_0_split <- fc10
I0316 12:04:37.515651 55708 net.cpp:380] fc10_fc10_0_split -> fc10_fc10_0_split_0
I0316 12:04:37.515659 55708 net.cpp:380] fc10_fc10_0_split -> fc10_fc10_0_split_1
I0316 12:04:37.515666 55708 net.cpp:380] fc10_fc10_0_split -> fc10_fc10_0_split_2
I0316 12:04:37.515714 55708 net.cpp:122] Setting up fc10_fc10_0_split
I0316 12:04:37.515722 55708 net.cpp:129] Top shape: 32 10 (320)
I0316 12:04:37.515728 55708 net.cpp:129] Top shape: 32 10 (320)
I0316 12:04:37.515734 55708 net.cpp:129] Top shape: 32 10 (320)
I0316 12:04:37.515740 55708 net.cpp:137] Memory required for data: 423366536
I0316 12:04:37.515748 55708 layer_factory.hpp:77] Creating layer loss
I0316 12:04:37.515756 55708 net.cpp:84] Creating Layer loss
I0316 12:04:37.515764 55708 net.cpp:406] loss <- fc10_fc10_0_split_0
I0316 12:04:37.515769 55708 net.cpp:406] loss <- label_data_1_split_0
I0316 12:04:37.515774 55708 net.cpp:380] loss -> loss
I0316 12:04:37.515780 55708 layer_factory.hpp:77] Creating layer loss
I0316 12:04:37.515848 55708 net.cpp:122] Setting up loss
I0316 12:04:37.515856 55708 net.cpp:129] Top shape: (1)
I0316 12:04:37.515858 55708 net.cpp:132]     with loss weight 1
I0316 12:04:37.515862 55708 net.cpp:137] Memory required for data: 423366540
I0316 12:04:37.515866 55708 layer_factory.hpp:77] Creating layer accuracy-top1
I0316 12:04:37.515879 55708 net.cpp:84] Creating Layer accuracy-top1
I0316 12:04:37.515882 55708 net.cpp:406] accuracy-top1 <- fc10_fc10_0_split_1
I0316 12:04:37.515887 55708 net.cpp:406] accuracy-top1 <- label_data_1_split_1
I0316 12:04:37.515892 55708 net.cpp:380] accuracy-top1 -> top-1
I0316 12:04:37.515898 55708 net.cpp:122] Setting up accuracy-top1
I0316 12:04:37.515902 55708 net.cpp:129] Top shape: (1)
I0316 12:04:37.515905 55708 net.cpp:137] Memory required for data: 423366544
I0316 12:04:37.515908 55708 layer_factory.hpp:77] Creating layer accuracy-top5
I0316 12:04:37.515916 55708 net.cpp:84] Creating Layer accuracy-top5
I0316 12:04:37.515920 55708 net.cpp:406] accuracy-top5 <- fc10_fc10_0_split_2
I0316 12:04:37.515923 55708 net.cpp:406] accuracy-top5 <- label_data_1_split_2
I0316 12:04:37.515928 55708 net.cpp:380] accuracy-top5 -> top-5
I0316 12:04:37.515934 55708 net.cpp:122] Setting up accuracy-top5
I0316 12:04:37.515938 55708 net.cpp:129] Top shape: (1)
I0316 12:04:37.515940 55708 net.cpp:137] Memory required for data: 423366548
I0316 12:04:37.515944 55708 net.cpp:200] accuracy-top5 does not need backward computation.
I0316 12:04:37.515949 55708 net.cpp:200] accuracy-top1 does not need backward computation.
I0316 12:04:37.515951 55708 net.cpp:198] loss needs backward computation.
I0316 12:04:37.515955 55708 net.cpp:198] fc10_fc10_0_split needs backward computation.
I0316 12:04:37.515959 55708 net.cpp:198] fc10 needs backward computation.
I0316 12:04:37.515964 55708 net.cpp:198] loss_2 needs backward computation.
I0316 12:04:37.515967 55708 net.cpp:198] latent_sigmoid_avg_latent_sigmoid_avg_0_split needs backward computation.
I0316 12:04:37.515970 55708 net.cpp:198] latent_sigmoid_avg needs backward computation.
I0316 12:04:37.515974 55708 net.cpp:198] latent_sigmoid_reshape needs backward computation.
I0316 12:04:37.515978 55708 net.cpp:198] loss_1 needs backward computation.
I0316 12:04:37.515982 55708 net.cpp:198] latent_sigmoid_latent_sigmoid_0_split needs backward computation.
I0316 12:04:37.515986 55708 net.cpp:198] latent_sigmoid needs backward computation.
I0316 12:04:37.515990 55708 net.cpp:198] latent needs backward computation.
I0316 12:04:37.515995 55708 net.cpp:198] drop_8x8_s1 needs backward computation.
I0316 12:04:37.515997 55708 net.cpp:198] avg_pool_12/8x8_s1 needs backward computation.
I0316 12:04:37.516001 55708 net.cpp:198] inception_11a/output needs backward computation.
I0316 12:04:37.516005 55708 net.cpp:198] inception_11a/3x3/relu1 needs backward computation.
I0316 12:04:37.516009 55708 net.cpp:198] inception_11a/3x3/scale1 needs backward computation.
I0316 12:04:37.516012 55708 net.cpp:198] inception_11a/3x3/bn1 needs backward computation.
I0316 12:04:37.516016 55708 net.cpp:198] inception_11a/3x3 needs backward computation.
I0316 12:04:37.516019 55708 net.cpp:198] inception_11a/1x1/relu1 needs backward computation.
I0316 12:04:37.516023 55708 net.cpp:198] inception_11a/1x1/scale1 needs backward computation.
I0316 12:04:37.516026 55708 net.cpp:198] inception_11a/1x1/bn1 needs backward computation.
I0316 12:04:37.516029 55708 net.cpp:198] inception_11a/1x1 needs backward computation.
I0316 12:04:37.516032 55708 net.cpp:198] inception_10a/output_inception_10a/output_0_split needs backward computation.
I0316 12:04:37.516037 55708 net.cpp:198] inception_10a/output needs backward computation.
I0316 12:04:37.516041 55708 net.cpp:198] inception_10a/3x3/relu1 needs backward computation.
I0316 12:04:37.516044 55708 net.cpp:198] inception_10a/3x3/scale1 needs backward computation.
I0316 12:04:37.516047 55708 net.cpp:198] inception_10a/3x3/bn1 needs backward computation.
I0316 12:04:37.516052 55708 net.cpp:198] inception_10a/3x3 needs backward computation.
I0316 12:04:37.516055 55708 net.cpp:198] inception_10a/1x1/relu1 needs backward computation.
I0316 12:04:37.516058 55708 net.cpp:198] inception_10a/1x1/scale1 needs backward computation.
I0316 12:04:37.516062 55708 net.cpp:198] inception_10a/1x1/bn1 needs backward computation.
I0316 12:04:37.516065 55708 net.cpp:198] inception_10a/1x1 needs backward computation.
I0316 12:04:37.516074 55708 net.cpp:198] downsample_9/output_downsample_9/output_0_split needs backward computation.
I0316 12:04:37.516078 55708 net.cpp:198] downsample_9/output needs backward computation.
I0316 12:04:37.516081 55708 net.cpp:198] downsample_9/pool_s2 needs backward computation.
I0316 12:04:37.516086 55708 net.cpp:198] downsample_9/3x3_s2/relu1 needs backward computation.
I0316 12:04:37.516089 55708 net.cpp:198] downsample_9/3x3_s2/scale1 needs backward computation.
I0316 12:04:37.516093 55708 net.cpp:198] downsample_9/3x3_s2/bn1 needs backward computation.
I0316 12:04:37.516095 55708 net.cpp:198] downsample_9/3x3_s2 needs backward computation.
I0316 12:04:37.516099 55708 net.cpp:198] inception_8a/output_inception_8a/output_0_split needs backward computation.
I0316 12:04:37.516103 55708 net.cpp:198] inception_8a/output needs backward computation.
I0316 12:04:37.516108 55708 net.cpp:198] inception_8a/3x3/relu1 needs backward computation.
I0316 12:04:37.516113 55708 net.cpp:198] inception_8a/3x3/scale1 needs backward computation.
I0316 12:04:37.516116 55708 net.cpp:198] inception_8a/3x3/bn1 needs backward computation.
I0316 12:04:37.516119 55708 net.cpp:198] inception_8a/3x3 needs backward computation.
I0316 12:04:37.516124 55708 net.cpp:198] inception_8a/1x1/relu1 needs backward computation.
I0316 12:04:37.516126 55708 net.cpp:198] inception_8a/1x1/scale1 needs backward computation.
I0316 12:04:37.516130 55708 net.cpp:198] inception_8a/1x1/bn1 needs backward computation.
I0316 12:04:37.516134 55708 net.cpp:198] inception_8a/1x1 needs backward computation.
I0316 12:04:37.516137 55708 net.cpp:198] inception_7a/output_inception_7a/output_0_split needs backward computation.
I0316 12:04:37.516140 55708 net.cpp:198] inception_7a/output needs backward computation.
I0316 12:04:37.516145 55708 net.cpp:198] inception_7a/3x3/relu1 needs backward computation.
I0316 12:04:37.516149 55708 net.cpp:198] inception_7a/3x3/scale1 needs backward computation.
I0316 12:04:37.516153 55708 net.cpp:198] inception_7a/3x3/bn1 needs backward computation.
I0316 12:04:37.516160 55708 net.cpp:198] inception_7a/3x3 needs backward computation.
I0316 12:04:37.516166 55708 net.cpp:198] inception_7a/1x1/relu1 needs backward computation.
I0316 12:04:37.516172 55708 net.cpp:198] inception_7a/1x1/scale1 needs backward computation.
I0316 12:04:37.516177 55708 net.cpp:198] inception_7a/1x1/bn1 needs backward computation.
I0316 12:04:37.516183 55708 net.cpp:198] inception_7a/1x1 needs backward computation.
I0316 12:04:37.516191 55708 net.cpp:198] inception_6a/output_inception_6a/output_0_split needs backward computation.
I0316 12:04:37.516197 55708 net.cpp:198] inception_6a/output needs backward computation.
I0316 12:04:37.516206 55708 net.cpp:198] inception_6a/3x3/relu1 needs backward computation.
I0316 12:04:37.516211 55708 net.cpp:198] inception_6a/3x3/scale1 needs backward computation.
I0316 12:04:37.516218 55708 net.cpp:198] inception_6a/3x3/bn1 needs backward computation.
I0316 12:04:37.516224 55708 net.cpp:198] inception_6a/3x3 needs backward computation.
I0316 12:04:37.516230 55708 net.cpp:198] inception_6a/1x1/relu1 needs backward computation.
I0316 12:04:37.516237 55708 net.cpp:198] inception_6a/1x1/scale1 needs backward computation.
I0316 12:04:37.516243 55708 net.cpp:198] inception_6a/1x1/bn1 needs backward computation.
I0316 12:04:37.516250 55708 net.cpp:198] inception_6a/1x1 needs backward computation.
I0316 12:04:37.516256 55708 net.cpp:198] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0316 12:04:37.516263 55708 net.cpp:198] inception_5a/output needs backward computation.
I0316 12:04:37.516268 55708 net.cpp:198] inception_5a/3x3/relu1 needs backward computation.
I0316 12:04:37.516270 55708 net.cpp:198] inception_5a/3x3/scale1 needs backward computation.
I0316 12:04:37.516273 55708 net.cpp:198] inception_5a/3x3/bn1 needs backward computation.
I0316 12:04:37.516278 55708 net.cpp:198] inception_5a/3x3 needs backward computation.
I0316 12:04:37.516289 55708 net.cpp:198] inception_5a/1x1/relu1 needs backward computation.
I0316 12:04:37.516306 55708 net.cpp:198] inception_5a/1x1/scale1 needs backward computation.
I0316 12:04:37.516314 55708 net.cpp:198] inception_5a/1x1/bn1 needs backward computation.
I0316 12:04:37.516322 55708 net.cpp:198] inception_5a/1x1 needs backward computation.
I0316 12:04:37.516332 55708 net.cpp:198] downsample_4/output_downsample_4/output_0_split needs backward computation.
I0316 12:04:37.516340 55708 net.cpp:198] downsample_4/output needs backward computation.
I0316 12:04:37.516350 55708 net.cpp:198] downsample_4/pool_s2 needs backward computation.
I0316 12:04:37.516360 55708 net.cpp:198] downsample_4/3x3_s2/relu1 needs backward computation.
I0316 12:04:37.516379 55708 net.cpp:198] downsample_4/3x3_s2/scale1 needs backward computation.
I0316 12:04:37.516386 55708 net.cpp:198] downsample_4/3x3_s2/bn1 needs backward computation.
I0316 12:04:37.516395 55708 net.cpp:198] downsample_4/3x3_s2 needs backward computation.
I0316 12:04:37.516402 55708 net.cpp:198] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0316 12:04:37.516413 55708 net.cpp:198] inception_3a/output needs backward computation.
I0316 12:04:37.516423 55708 net.cpp:198] inception_3a/3x3/relu1 needs backward computation.
I0316 12:04:37.516431 55708 net.cpp:198] inception_3a/3x3/scale1 needs backward computation.
I0316 12:04:37.516438 55708 net.cpp:198] inception_3a/3x3/bn1 needs backward computation.
I0316 12:04:37.516448 55708 net.cpp:198] inception_3a/3x3 needs backward computation.
I0316 12:04:37.516456 55708 net.cpp:198] inception_3a/1x1/relu1 needs backward computation.
I0316 12:04:37.516463 55708 net.cpp:198] inception_3a/1x1/scale1 needs backward computation.
I0316 12:04:37.516470 55708 net.cpp:198] inception_3a/1x1/bn1 needs backward computation.
I0316 12:04:37.516480 55708 net.cpp:198] inception_3a/1x1 needs backward computation.
I0316 12:04:37.516489 55708 net.cpp:198] inception_2a/output_inception_2a/output_0_split needs backward computation.
I0316 12:04:37.516497 55708 net.cpp:198] inception_2a/output needs backward computation.
I0316 12:04:37.516505 55708 net.cpp:198] inception_2a/3x3/relu1 needs backward computation.
I0316 12:04:37.516515 55708 net.cpp:198] inception_2a/3x3/scale1 needs backward computation.
I0316 12:04:37.516522 55708 net.cpp:198] inception_2a/3x3/bn1 needs backward computation.
I0316 12:04:37.516530 55708 net.cpp:198] inception_2a/3x3 needs backward computation.
I0316 12:04:37.516538 55708 net.cpp:198] inception_2a/1x1/relu1 needs backward computation.
I0316 12:04:37.516546 55708 net.cpp:198] inception_2a/1x1/scale1 needs backward computation.
I0316 12:04:37.516556 55708 net.cpp:198] inception_2a/1x1/bn1 needs backward computation.
I0316 12:04:37.516562 55708 net.cpp:198] inception_2a/1x1 needs backward computation.
I0316 12:04:37.516570 55708 net.cpp:198] conv1/3x3_s1_conv1/relu1_0_split needs backward computation.
I0316 12:04:37.516575 55708 net.cpp:198] conv1/relu1 needs backward computation.
I0316 12:04:37.516578 55708 net.cpp:198] conv1/scale1 needs backward computation.
I0316 12:04:37.516582 55708 net.cpp:198] conv1/bn1 needs backward computation.
I0316 12:04:37.516584 55708 net.cpp:198] conv1/3x3_s1 needs backward computation.
I0316 12:04:37.516589 55708 net.cpp:200] label_data_1_split does not need backward computation.
I0316 12:04:37.516595 55708 net.cpp:200] data does not need backward computation.
I0316 12:04:37.516597 55708 net.cpp:242] This network produces output loss
I0316 12:04:37.516602 55708 net.cpp:242] This network produces output loss: 50%-fire-rate
I0316 12:04:37.516605 55708 net.cpp:242] This network produces output loss: forcing-binary
I0316 12:04:37.516609 55708 net.cpp:242] This network produces output top-1
I0316 12:04:37.516613 55708 net.cpp:242] This network produces output top-5
I0316 12:04:37.516685 55708 net.cpp:255] Network initialization done.
I0316 12:04:37.516881 55708 solver.cpp:72] Finetuning from googlenet.caffemodel
I0316 12:04:37.522094 55708 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: googlenet.caffemodel
I0316 12:04:37.522128 55708 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0316 12:04:37.523387 55708 net.cpp:744] Ignoring source layer loss/classifier
I0316 12:04:37.523594 55708 solver.cpp:57] Solver scaffolding done.
I0316 12:04:37.527730 55708 caffe.cpp:239] Starting Optimization
I0316 12:04:37.527741 55708 solver.cpp:293] Solving miniGoogleNet for CIFAR10, model 3
I0316 12:04:37.527745 55708 solver.cpp:294] Learning Rate Policy: step
I0316 12:04:37.750581 55708 solver.cpp:239] Iteration 0 (0 iter/s, 0.222798s/100 iters), loss = 2.33735
I0316 12:04:37.750625 55708 solver.cpp:258]     Train net output #0: loss = 2.33751 (* 1 = 2.33751 loss)
I0316 12:04:37.750636 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 2.02966e-06 (* 1 = 2.02966e-06 loss)
I0316 12:04:37.750645 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.000162887 (* 1 = -0.000162887 loss)
I0316 12:04:37.750665 55708 sgd_solver.cpp:112] Iteration 0, lr = 0.001
I0316 12:04:45.745965 55708 solver.cpp:239] Iteration 100 (12.5072 iter/s, 7.99537s/100 iters), loss = 2.22374
I0316 12:04:45.746021 55708 solver.cpp:258]     Train net output #0: loss = 2.22399 (* 1 = 2.22399 loss)
I0316 12:04:45.746027 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 5.15771e-06 (* 1 = 5.15771e-06 loss)
I0316 12:04:45.746033 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.00026023 (* 1 = -0.00026023 loss)
I0316 12:04:45.746038 55708 sgd_solver.cpp:112] Iteration 100, lr = 0.001
I0316 12:04:53.676755 55708 solver.cpp:239] Iteration 200 (12.6091 iter/s, 7.93076s/100 iters), loss = 2.18193
I0316 12:04:53.676805 55708 solver.cpp:258]     Train net output #0: loss = 2.18251 (* 1 = 2.18251 loss)
I0316 12:04:53.676812 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 8.58601e-06 (* 1 = 8.58601e-06 loss)
I0316 12:04:53.676818 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.000595192 (* 1 = -0.000595192 loss)
I0316 12:04:53.676823 55708 sgd_solver.cpp:112] Iteration 200, lr = 0.001
I0316 12:05:01.609441 55708 solver.cpp:239] Iteration 300 (12.6061 iter/s, 7.93266s/100 iters), loss = 2.10893
I0316 12:05:01.609494 55708 solver.cpp:258]     Train net output #0: loss = 2.11008 (* 1 = 2.11008 loss)
I0316 12:05:01.609504 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 1.15366e-05 (* 1 = 1.15366e-05 loss)
I0316 12:05:01.609513 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.00115455 (* 1 = -0.00115455 loss)
I0316 12:05:01.609519 55708 sgd_solver.cpp:112] Iteration 300, lr = 0.001
I0316 12:05:09.538578 55708 solver.cpp:239] Iteration 400 (12.6117 iter/s, 7.92911s/100 iters), loss = 1.96863
I0316 12:05:09.539078 55708 solver.cpp:258]     Train net output #0: loss = 1.97073 (* 1 = 1.97073 loss)
I0316 12:05:09.539088 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 8.39844e-06 (* 1 = 8.39844e-06 loss)
I0316 12:05:09.539093 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.00211346 (* 1 = -0.00211346 loss)
I0316 12:05:09.539099 55708 sgd_solver.cpp:112] Iteration 400, lr = 0.001
I0316 12:05:17.470279 55708 solver.cpp:239] Iteration 500 (12.6084 iter/s, 7.93123s/100 iters), loss = 1.9298
I0316 12:05:17.470330 55708 solver.cpp:258]     Train net output #0: loss = 1.93387 (* 1 = 1.93387 loss)
I0316 12:05:17.470337 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 1.23346e-05 (* 1 = 1.23346e-05 loss)
I0316 12:05:17.470360 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.00408266 (* 1 = -0.00408266 loss)
I0316 12:05:17.470366 55708 sgd_solver.cpp:112] Iteration 500, lr = 0.001
I0316 12:05:25.404454 55708 solver.cpp:239] Iteration 600 (12.6037 iter/s, 7.93415s/100 iters), loss = 1.73759
I0316 12:05:25.404510 55708 solver.cpp:258]     Train net output #0: loss = 1.7428 (* 1 = 1.7428 loss)
I0316 12:05:25.404521 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 8.43133e-06 (* 1 = 8.43133e-06 loss)
I0316 12:05:25.404529 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.00521979 (* 1 = -0.00521979 loss)
I0316 12:05:25.404536 55708 sgd_solver.cpp:112] Iteration 600, lr = 0.001
I0316 12:05:33.334085 55708 solver.cpp:239] Iteration 700 (12.611 iter/s, 7.92961s/100 iters), loss = 1.70478
I0316 12:05:33.334136 55708 solver.cpp:258]     Train net output #0: loss = 1.71113 (* 1 = 1.71113 loss)
I0316 12:05:33.334144 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 1.33905e-05 (* 1 = 1.33905e-05 loss)
I0316 12:05:33.334153 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.00635728 (* 1 = -0.00635728 loss)
I0316 12:05:33.334159 55708 sgd_solver.cpp:112] Iteration 700, lr = 0.001
I0316 12:05:41.264405 55708 solver.cpp:239] Iteration 800 (12.6099 iter/s, 7.93028s/100 iters), loss = 1.62524
I0316 12:05:41.264786 55708 solver.cpp:258]     Train net output #0: loss = 1.63353 (* 1 = 1.63353 loss)
I0316 12:05:41.264798 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 1.185e-05 (* 1 = 1.185e-05 loss)
I0316 12:05:41.264811 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.00829929 (* 1 = -0.00829929 loss)
I0316 12:05:41.264819 55708 sgd_solver.cpp:112] Iteration 800, lr = 0.001
I0316 12:05:49.197113 55708 solver.cpp:239] Iteration 900 (12.6066 iter/s, 7.93237s/100 iters), loss = 1.43793
I0316 12:05:49.197163 55708 solver.cpp:258]     Train net output #0: loss = 1.44937 (* 1 = 1.44937 loss)
I0316 12:05:49.197175 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 1.68814e-05 (* 1 = 1.68814e-05 loss)
I0316 12:05:49.197185 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.011456 (* 1 = -0.011456 loss)
I0316 12:05:49.197191 55708 sgd_solver.cpp:112] Iteration 900, lr = 0.001
I0316 12:05:57.053984 55708 solver.cpp:351] Iteration 1000, Testing net (#0)
I0316 12:06:02.040493 55708 solver.cpp:418]     Test net output #0: loss = 1.38072 (* 1 = 1.38072 loss)
I0316 12:06:02.040522 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 1.71128e-05 (* 1 = 1.71128e-05 loss)
I0316 12:06:02.040529 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0136296 (* 1 = -0.0136296 loss)
I0316 12:06:02.040544 55708 solver.cpp:418]     Test net output #3: top-1 = 0.786406
I0316 12:06:02.040549 55708 solver.cpp:418]     Test net output #4: top-5 = 0.982656
I0316 12:06:02.118279 55708 solver.cpp:239] Iteration 1000 (7.73922 iter/s, 12.9212s/100 iters), loss = 1.36914
I0316 12:06:02.118306 55708 solver.cpp:258]     Train net output #0: loss = 1.38186 (* 1 = 1.38186 loss)
I0316 12:06:02.118312 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 2.86043e-05 (* 1 = 2.86043e-05 loss)
I0316 12:06:02.118319 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0127539 (* 1 = -0.0127539 loss)
I0316 12:06:02.118341 55708 sgd_solver.cpp:112] Iteration 1000, lr = 0.001
I0316 12:06:10.051484 55708 solver.cpp:239] Iteration 1100 (12.6052 iter/s, 7.93321s/100 iters), loss = 1.1428
I0316 12:06:10.051532 55708 solver.cpp:258]     Train net output #0: loss = 1.15979 (* 1 = 1.15979 loss)
I0316 12:06:10.051538 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 2.65444e-05 (* 1 = 2.65444e-05 loss)
I0316 12:06:10.051560 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0170097 (* 1 = -0.0170097 loss)
I0316 12:06:10.051565 55708 sgd_solver.cpp:112] Iteration 1100, lr = 0.001
I0316 12:06:17.980194 55708 solver.cpp:239] Iteration 1200 (12.6124 iter/s, 7.92869s/100 iters), loss = 1.10991
I0316 12:06:17.980525 55708 solver.cpp:258]     Train net output #0: loss = 1.12845 (* 1 = 1.12845 loss)
I0316 12:06:17.980535 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 2.44461e-05 (* 1 = 2.44461e-05 loss)
I0316 12:06:17.980541 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0185605 (* 1 = -0.0185605 loss)
I0316 12:06:17.980546 55708 sgd_solver.cpp:112] Iteration 1200, lr = 0.001
I0316 12:06:25.914162 55708 solver.cpp:239] Iteration 1300 (12.6045 iter/s, 7.93367s/100 iters), loss = 1.11791
I0316 12:06:25.914211 55708 solver.cpp:258]     Train net output #0: loss = 1.13697 (* 1 = 1.13697 loss)
I0316 12:06:25.914218 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 2.47638e-05 (* 1 = 2.47638e-05 loss)
I0316 12:06:25.914224 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.019088 (* 1 = -0.019088 loss)
I0316 12:06:25.914229 55708 sgd_solver.cpp:112] Iteration 1300, lr = 0.001
I0316 12:06:33.843757 55708 solver.cpp:239] Iteration 1400 (12.611 iter/s, 7.92958s/100 iters), loss = 0.965866
I0316 12:06:33.843806 55708 solver.cpp:258]     Train net output #0: loss = 0.987862 (* 1 = 0.987862 loss)
I0316 12:06:33.843812 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 3.35615e-05 (* 1 = 3.35615e-05 loss)
I0316 12:06:33.843818 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0220292 (* 1 = -0.0220292 loss)
I0316 12:06:33.843824 55708 sgd_solver.cpp:112] Iteration 1400, lr = 0.001
I0316 12:06:41.772977 55708 solver.cpp:239] Iteration 1500 (12.6116 iter/s, 7.92921s/100 iters), loss = 0.87412
I0316 12:06:41.773017 55708 solver.cpp:258]     Train net output #0: loss = 0.900119 (* 1 = 0.900119 loss)
I0316 12:06:41.773030 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 5.57993e-05 (* 1 = 5.57993e-05 loss)
I0316 12:06:41.773037 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0260552 (* 1 = -0.0260552 loss)
I0316 12:06:41.773042 55708 sgd_solver.cpp:112] Iteration 1500, lr = 0.001
I0316 12:06:46.374519 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:06:49.703559 55708 solver.cpp:239] Iteration 1600 (12.6094 iter/s, 7.93057s/100 iters), loss = 0.820468
I0316 12:06:49.703977 55708 solver.cpp:258]     Train net output #0: loss = 0.844545 (* 1 = 0.844545 loss)
I0316 12:06:49.703987 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 6.24667e-05 (* 1 = 6.24667e-05 loss)
I0316 12:06:49.703994 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0241395 (* 1 = -0.0241395 loss)
I0316 12:06:49.703999 55708 sgd_solver.cpp:112] Iteration 1600, lr = 0.001
I0316 12:06:57.633534 55708 solver.cpp:239] Iteration 1700 (12.611 iter/s, 7.92959s/100 iters), loss = 0.978819
I0316 12:06:57.633580 55708 solver.cpp:258]     Train net output #0: loss = 1.00327 (* 1 = 1.00327 loss)
I0316 12:06:57.633586 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 5.72183e-05 (* 1 = 5.72183e-05 loss)
I0316 12:06:57.633608 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0245105 (* 1 = -0.0245105 loss)
I0316 12:06:57.633615 55708 sgd_solver.cpp:112] Iteration 1700, lr = 0.001
I0316 12:07:05.567590 55708 solver.cpp:239] Iteration 1800 (12.6039 iter/s, 7.93404s/100 iters), loss = 0.741499
I0316 12:07:05.567646 55708 solver.cpp:258]     Train net output #0: loss = 0.770792 (* 1 = 0.770792 loss)
I0316 12:07:05.567669 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 5.42576e-05 (* 1 = 5.42576e-05 loss)
I0316 12:07:05.567677 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0293474 (* 1 = -0.0293474 loss)
I0316 12:07:05.567683 55708 sgd_solver.cpp:112] Iteration 1800, lr = 0.001
I0316 12:07:13.498370 55708 solver.cpp:239] Iteration 1900 (12.6091 iter/s, 7.93076s/100 iters), loss = 0.981241
I0316 12:07:13.498420 55708 solver.cpp:258]     Train net output #0: loss = 1.00779 (* 1 = 1.00779 loss)
I0316 12:07:13.498426 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 7.67946e-05 (* 1 = 7.67946e-05 loss)
I0316 12:07:13.498448 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0266226 (* 1 = -0.0266226 loss)
I0316 12:07:13.498453 55708 sgd_solver.cpp:112] Iteration 1900, lr = 0.001
I0316 12:07:21.350744 55708 solver.cpp:351] Iteration 2000, Testing net (#0)
I0316 12:07:24.036242 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:07:26.279124 55708 solver.cpp:418]     Test net output #0: loss = 0.769761 (* 1 = 0.769761 loss)
I0316 12:07:26.279158 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 7.14514e-05 (* 1 = 7.14514e-05 loss)
I0316 12:07:26.279165 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0300365 (* 1 = -0.0300365 loss)
I0316 12:07:26.279170 55708 solver.cpp:418]     Test net output #3: top-1 = 0.838594
I0316 12:07:26.279173 55708 solver.cpp:418]     Test net output #4: top-5 = 0.99125
I0316 12:07:26.358599 55708 solver.cpp:239] Iteration 2000 (7.7759 iter/s, 12.8603s/100 iters), loss = 0.567552
I0316 12:07:26.358636 55708 solver.cpp:258]     Train net output #0: loss = 0.598359 (* 1 = 0.598359 loss)
I0316 12:07:26.358644 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 7.97558e-05 (* 1 = 7.97558e-05 loss)
I0316 12:07:26.358650 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0308859 (* 1 = -0.0308859 loss)
I0316 12:07:26.358659 55708 sgd_solver.cpp:112] Iteration 2000, lr = 0.001
I0316 12:07:34.289142 55708 solver.cpp:239] Iteration 2100 (12.6095 iter/s, 7.93054s/100 iters), loss = 0.626341
I0316 12:07:34.289187 55708 solver.cpp:258]     Train net output #0: loss = 0.656669 (* 1 = 0.656669 loss)
I0316 12:07:34.289194 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 6.61454e-05 (* 1 = 6.61454e-05 loss)
I0316 12:07:34.289201 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.030394 (* 1 = -0.030394 loss)
I0316 12:07:34.289206 55708 sgd_solver.cpp:112] Iteration 2100, lr = 0.001
I0316 12:07:42.218665 55708 solver.cpp:239] Iteration 2200 (12.6111 iter/s, 7.92951s/100 iters), loss = 0.598296
I0316 12:07:42.218704 55708 solver.cpp:258]     Train net output #0: loss = 0.633918 (* 1 = 0.633918 loss)
I0316 12:07:42.218711 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 9.91774e-05 (* 1 = 9.91774e-05 loss)
I0316 12:07:42.218716 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0357205 (* 1 = -0.0357205 loss)
I0316 12:07:42.218722 55708 sgd_solver.cpp:112] Iteration 2200, lr = 0.001
I0316 12:07:50.147541 55708 solver.cpp:239] Iteration 2300 (12.6122 iter/s, 7.92886s/100 iters), loss = 0.484209
I0316 12:07:50.147588 55708 solver.cpp:258]     Train net output #0: loss = 0.520382 (* 1 = 0.520382 loss)
I0316 12:07:50.147594 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 9.2896e-05 (* 1 = 9.2896e-05 loss)
I0316 12:07:50.147600 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0362657 (* 1 = -0.0362657 loss)
I0316 12:07:50.147606 55708 sgd_solver.cpp:112] Iteration 2300, lr = 0.001
I0316 12:07:58.076351 55708 solver.cpp:239] Iteration 2400 (12.6122 iter/s, 7.9288s/100 iters), loss = 0.577705
I0316 12:07:58.076699 55708 solver.cpp:258]     Train net output #0: loss = 0.610894 (* 1 = 0.610894 loss)
I0316 12:07:58.076707 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 9.90098e-05 (* 1 = 9.90098e-05 loss)
I0316 12:07:58.076714 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.033288 (* 1 = -0.033288 loss)
I0316 12:07:58.076718 55708 sgd_solver.cpp:112] Iteration 2400, lr = 0.001
I0316 12:08:06.005862 55708 solver.cpp:239] Iteration 2500 (12.6116 iter/s, 7.92919s/100 iters), loss = 0.389016
I0316 12:08:06.005909 55708 solver.cpp:258]     Train net output #0: loss = 0.428212 (* 1 = 0.428212 loss)
I0316 12:08:06.005916 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000122674 (* 1 = 0.000122674 loss)
I0316 12:08:06.005937 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0393187 (* 1 = -0.0393187 loss)
I0316 12:08:06.005942 55708 sgd_solver.cpp:112] Iteration 2500, lr = 0.001
I0316 12:08:13.936282 55708 solver.cpp:239] Iteration 2600 (12.6097 iter/s, 7.93041s/100 iters), loss = 0.532928
I0316 12:08:13.936328 55708 solver.cpp:258]     Train net output #0: loss = 0.565215 (* 1 = 0.565215 loss)
I0316 12:08:13.936336 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 8.3584e-05 (* 1 = 8.3584e-05 loss)
I0316 12:08:13.936343 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.032371 (* 1 = -0.032371 loss)
I0316 12:08:13.936352 55708 sgd_solver.cpp:112] Iteration 2600, lr = 0.001
I0316 12:08:21.866642 55708 solver.cpp:239] Iteration 2700 (12.6098 iter/s, 7.93034s/100 iters), loss = 0.416055
I0316 12:08:21.866698 55708 solver.cpp:258]     Train net output #0: loss = 0.453955 (* 1 = 0.453955 loss)
I0316 12:08:21.866703 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000135337 (* 1 = 0.000135337 loss)
I0316 12:08:21.866710 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0380348 (* 1 = -0.0380348 loss)
I0316 12:08:21.866714 55708 sgd_solver.cpp:112] Iteration 2700, lr = 0.001
I0316 12:08:29.796818 55708 solver.cpp:239] Iteration 2800 (12.6101 iter/s, 7.93016s/100 iters), loss = 0.474414
I0316 12:08:29.797397 55708 solver.cpp:258]     Train net output #0: loss = 0.513457 (* 1 = 0.513457 loss)
I0316 12:08:29.797406 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000130242 (* 1 = 0.000130242 loss)
I0316 12:08:29.797412 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0391725 (* 1 = -0.0391725 loss)
I0316 12:08:29.797417 55708 sgd_solver.cpp:112] Iteration 2800, lr = 0.001
I0316 12:08:37.726972 55708 solver.cpp:239] Iteration 2900 (12.611 iter/s, 7.92962s/100 iters), loss = 0.487687
I0316 12:08:37.727012 55708 solver.cpp:258]     Train net output #0: loss = 0.525357 (* 1 = 0.525357 loss)
I0316 12:08:37.727018 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000132163 (* 1 = 0.000132163 loss)
I0316 12:08:37.727025 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0378021 (* 1 = -0.0378021 loss)
I0316 12:08:37.727044 55708 sgd_solver.cpp:112] Iteration 2900, lr = 0.001
I0316 12:08:45.579053 55708 solver.cpp:351] Iteration 3000, Testing net (#0)
I0316 12:08:50.502359 55708 solver.cpp:418]     Test net output #0: loss = 0.555906 (* 1 = 0.555906 loss)
I0316 12:08:50.502384 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000126614 (* 1 = 0.000126614 loss)
I0316 12:08:50.502389 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0394439 (* 1 = -0.0394439 loss)
I0316 12:08:50.502394 55708 solver.cpp:418]     Test net output #3: top-1 = 0.85125
I0316 12:08:50.502398 55708 solver.cpp:418]     Test net output #4: top-5 = 0.991719
I0316 12:08:50.580090 55708 solver.cpp:239] Iteration 3000 (7.78019 iter/s, 12.8531s/100 iters), loss = 0.416786
I0316 12:08:50.580116 55708 solver.cpp:258]     Train net output #0: loss = 0.457748 (* 1 = 0.457748 loss)
I0316 12:08:50.580123 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000130747 (* 1 = 0.000130747 loss)
I0316 12:08:50.580128 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0410928 (* 1 = -0.0410928 loss)
I0316 12:08:50.580134 55708 sgd_solver.cpp:112] Iteration 3000, lr = 0.001
I0316 12:08:58.512755 55708 solver.cpp:239] Iteration 3100 (12.6061 iter/s, 7.93268s/100 iters), loss = 0.389735
I0316 12:08:58.512797 55708 solver.cpp:258]     Train net output #0: loss = 0.431857 (* 1 = 0.431857 loss)
I0316 12:08:58.512804 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000122426 (* 1 = 0.000122426 loss)
I0316 12:08:58.512810 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0422444 (* 1 = -0.0422444 loss)
I0316 12:08:58.512815 55708 sgd_solver.cpp:112] Iteration 3100, lr = 0.001
I0316 12:09:00.103089 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:09:06.443058 55708 solver.cpp:239] Iteration 3200 (12.6099 iter/s, 7.93029s/100 iters), loss = 0.30513
I0316 12:09:06.443104 55708 solver.cpp:258]     Train net output #0: loss = 0.345708 (* 1 = 0.345708 loss)
I0316 12:09:06.443110 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000155582 (* 1 = 0.000155582 loss)
I0316 12:09:06.443116 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0407342 (* 1 = -0.0407342 loss)
I0316 12:09:06.443121 55708 sgd_solver.cpp:112] Iteration 3200, lr = 0.001
I0316 12:09:14.373245 55708 solver.cpp:239] Iteration 3300 (12.6101 iter/s, 7.93018s/100 iters), loss = 0.651363
I0316 12:09:14.373292 55708 solver.cpp:258]     Train net output #0: loss = 0.690159 (* 1 = 0.690159 loss)
I0316 12:09:14.373301 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00013906 (* 1 = 0.00013906 loss)
I0316 12:09:14.373308 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.038935 (* 1 = -0.038935 loss)
I0316 12:09:14.373314 55708 sgd_solver.cpp:112] Iteration 3300, lr = 0.001
I0316 12:09:22.304774 55708 solver.cpp:239] Iteration 3400 (12.6079 iter/s, 7.93151s/100 iters), loss = 0.234195
I0316 12:09:22.304821 55708 solver.cpp:258]     Train net output #0: loss = 0.2772 (* 1 = 0.2772 loss)
I0316 12:09:22.304828 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000135692 (* 1 = 0.000135692 loss)
I0316 12:09:22.304833 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0431406 (* 1 = -0.0431406 loss)
I0316 12:09:22.304838 55708 sgd_solver.cpp:112] Iteration 3400, lr = 0.001
I0316 12:09:30.234499 55708 solver.cpp:239] Iteration 3500 (12.6108 iter/s, 7.92971s/100 iters), loss = 0.408809
I0316 12:09:30.234889 55708 solver.cpp:258]     Train net output #0: loss = 0.451237 (* 1 = 0.451237 loss)
I0316 12:09:30.234899 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000178648 (* 1 = 0.000178648 loss)
I0316 12:09:30.234905 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0426062 (* 1 = -0.0426062 loss)
I0316 12:09:30.234910 55708 sgd_solver.cpp:112] Iteration 3500, lr = 0.001
I0316 12:09:38.165195 55708 solver.cpp:239] Iteration 3600 (12.6098 iter/s, 7.93034s/100 iters), loss = 0.239237
I0316 12:09:38.165235 55708 solver.cpp:258]     Train net output #0: loss = 0.285803 (* 1 = 0.285803 loss)
I0316 12:09:38.165243 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00012485 (* 1 = 0.00012485 loss)
I0316 12:09:38.165249 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0466902 (* 1 = -0.0466902 loss)
I0316 12:09:38.165254 55708 sgd_solver.cpp:112] Iteration 3600, lr = 0.001
I0316 12:09:46.095291 55708 solver.cpp:239] Iteration 3700 (12.6102 iter/s, 7.93009s/100 iters), loss = 0.351844
I0316 12:09:46.095338 55708 solver.cpp:258]     Train net output #0: loss = 0.394664 (* 1 = 0.394664 loss)
I0316 12:09:46.095345 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000156904 (* 1 = 0.000156904 loss)
I0316 12:09:46.095351 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0429771 (* 1 = -0.0429771 loss)
I0316 12:09:46.095356 55708 sgd_solver.cpp:112] Iteration 3700, lr = 0.001
I0316 12:09:54.026132 55708 solver.cpp:239] Iteration 3800 (12.609 iter/s, 7.93083s/100 iters), loss = 0.310741
I0316 12:09:54.026177 55708 solver.cpp:258]     Train net output #0: loss = 0.354434 (* 1 = 0.354434 loss)
I0316 12:09:54.026185 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000169088 (* 1 = 0.000169088 loss)
I0316 12:09:54.026190 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0438622 (* 1 = -0.0438622 loss)
I0316 12:09:54.026196 55708 sgd_solver.cpp:112] Iteration 3800, lr = 0.001
I0316 12:10:01.958300 55708 solver.cpp:239] Iteration 3900 (12.6069 iter/s, 7.93214s/100 iters), loss = 0.520612
I0316 12:10:01.958514 55708 solver.cpp:258]     Train net output #0: loss = 0.565861 (* 1 = 0.565861 loss)
I0316 12:10:01.958523 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000175833 (* 1 = 0.000175833 loss)
I0316 12:10:01.958528 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0454248 (* 1 = -0.0454248 loss)
I0316 12:10:01.958534 55708 sgd_solver.cpp:112] Iteration 3900, lr = 0.001
I0316 12:10:09.814761 55708 solver.cpp:351] Iteration 4000, Testing net (#0)
I0316 12:10:10.333768 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:10:14.743449 55708 solver.cpp:418]     Test net output #0: loss = 0.483345 (* 1 = 0.483345 loss)
I0316 12:10:14.743475 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.00016932 (* 1 = 0.00016932 loss)
I0316 12:10:14.743481 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0444113 (* 1 = -0.0444113 loss)
I0316 12:10:14.743486 55708 solver.cpp:418]     Test net output #3: top-1 = 0.856094
I0316 12:10:14.743490 55708 solver.cpp:418]     Test net output #4: top-5 = 0.993438
I0316 12:10:14.821210 55708 solver.cpp:239] Iteration 4000 (7.77438 iter/s, 12.8628s/100 iters), loss = 0.284976
I0316 12:10:14.821240 55708 solver.cpp:258]     Train net output #0: loss = 0.331243 (* 1 = 0.331243 loss)
I0316 12:10:14.821249 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00015291 (* 1 = 0.00015291 loss)
I0316 12:10:14.821257 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0464194 (* 1 = -0.0464194 loss)
I0316 12:10:14.821266 55708 sgd_solver.cpp:112] Iteration 4000, lr = 0.001
I0316 12:10:22.751412 55708 solver.cpp:239] Iteration 4100 (12.61 iter/s, 7.9302s/100 iters), loss = 0.118958
I0316 12:10:22.751461 55708 solver.cpp:258]     Train net output #0: loss = 0.167808 (* 1 = 0.167808 loss)
I0316 12:10:22.751467 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000190814 (* 1 = 0.000190814 loss)
I0316 12:10:22.751473 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0490408 (* 1 = -0.0490408 loss)
I0316 12:10:22.751478 55708 sgd_solver.cpp:112] Iteration 4100, lr = 0.001
I0316 12:10:30.680071 55708 solver.cpp:239] Iteration 4200 (12.6125 iter/s, 7.92865s/100 iters), loss = 0.24217
I0316 12:10:30.680111 55708 solver.cpp:258]     Train net output #0: loss = 0.288352 (* 1 = 0.288352 loss)
I0316 12:10:30.680119 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000189187 (* 1 = 0.000189187 loss)
I0316 12:10:30.680140 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0463714 (* 1 = -0.0463714 loss)
I0316 12:10:30.680145 55708 sgd_solver.cpp:112] Iteration 4200, lr = 0.001
I0316 12:10:38.609351 55708 solver.cpp:239] Iteration 4300 (12.6115 iter/s, 7.92927s/100 iters), loss = 0.295416
I0316 12:10:38.609723 55708 solver.cpp:258]     Train net output #0: loss = 0.339276 (* 1 = 0.339276 loss)
I0316 12:10:38.609732 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000138629 (* 1 = 0.000138629 loss)
I0316 12:10:38.609738 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.043998 (* 1 = -0.043998 loss)
I0316 12:10:38.609745 55708 sgd_solver.cpp:112] Iteration 4300, lr = 0.001
I0316 12:10:46.538965 55708 solver.cpp:239] Iteration 4400 (12.6115 iter/s, 7.92927s/100 iters), loss = 0.166065
I0316 12:10:46.539060 55708 solver.cpp:258]     Train net output #0: loss = 0.214077 (* 1 = 0.214077 loss)
I0316 12:10:46.539083 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000197918 (* 1 = 0.000197918 loss)
I0316 12:10:46.539100 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0482097 (* 1 = -0.0482097 loss)
I0316 12:10:46.539119 55708 sgd_solver.cpp:112] Iteration 4400, lr = 0.001
I0316 12:10:54.469882 55708 solver.cpp:239] Iteration 4500 (12.609 iter/s, 7.93086s/100 iters), loss = 0.270414
I0316 12:10:54.469923 55708 solver.cpp:258]     Train net output #0: loss = 0.313221 (* 1 = 0.313221 loss)
I0316 12:10:54.469930 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000162095 (* 1 = 0.000162095 loss)
I0316 12:10:54.469938 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0429695 (* 1 = -0.0429695 loss)
I0316 12:10:54.469942 55708 sgd_solver.cpp:112] Iteration 4500, lr = 0.001
I0316 12:11:02.401185 55708 solver.cpp:239] Iteration 4600 (12.6083 iter/s, 7.93129s/100 iters), loss = 0.358334
I0316 12:11:02.401233 55708 solver.cpp:258]     Train net output #0: loss = 0.402812 (* 1 = 0.402812 loss)
I0316 12:11:02.401242 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00014458 (* 1 = 0.00014458 loss)
I0316 12:11:02.401247 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0446228 (* 1 = -0.0446228 loss)
I0316 12:11:02.401252 55708 sgd_solver.cpp:112] Iteration 4600, lr = 0.001
I0316 12:11:08.984915 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:11:10.330358 55708 solver.cpp:239] Iteration 4700 (12.6117 iter/s, 7.92916s/100 iters), loss = 0.248761
I0316 12:11:10.330399 55708 solver.cpp:258]     Train net output #0: loss = 0.299781 (* 1 = 0.299781 loss)
I0316 12:11:10.330406 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000230911 (* 1 = 0.000230911 loss)
I0316 12:11:10.330412 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0512512 (* 1 = -0.0512512 loss)
I0316 12:11:10.330416 55708 sgd_solver.cpp:112] Iteration 4700, lr = 0.001
I0316 12:11:18.261613 55708 solver.cpp:239] Iteration 4800 (12.6084 iter/s, 7.93125s/100 iters), loss = 0.184759
I0316 12:11:18.261653 55708 solver.cpp:258]     Train net output #0: loss = 0.234748 (* 1 = 0.234748 loss)
I0316 12:11:18.261660 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000198388 (* 1 = 0.000198388 loss)
I0316 12:11:18.261682 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.050187 (* 1 = -0.050187 loss)
I0316 12:11:18.261688 55708 sgd_solver.cpp:112] Iteration 4800, lr = 0.001
I0316 12:11:26.191609 55708 solver.cpp:239] Iteration 4900 (12.6104 iter/s, 7.92998s/100 iters), loss = 0.170679
I0316 12:11:26.191654 55708 solver.cpp:258]     Train net output #0: loss = 0.217821 (* 1 = 0.217821 loss)
I0316 12:11:26.191661 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000172968 (* 1 = 0.000172968 loss)
I0316 12:11:26.191668 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0473143 (* 1 = -0.0473143 loss)
I0316 12:11:26.191673 55708 sgd_solver.cpp:112] Iteration 4900, lr = 0.001
I0316 12:11:34.044785 55708 solver.cpp:351] Iteration 5000, Testing net (#0)
I0316 12:11:37.345078 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:11:38.971083 55708 solver.cpp:418]     Test net output #0: loss = 0.457826 (* 1 = 0.457826 loss)
I0316 12:11:38.971113 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.00019097 (* 1 = 0.00019097 loss)
I0316 12:11:38.971119 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0482498 (* 1 = -0.0482498 loss)
I0316 12:11:38.971123 55708 solver.cpp:418]     Test net output #3: top-1 = 0.857031
I0316 12:11:38.971128 55708 solver.cpp:418]     Test net output #4: top-5 = 0.991406
I0316 12:11:39.048831 55708 solver.cpp:239] Iteration 5000 (7.77772 iter/s, 12.8572s/100 iters), loss = 0.25313
I0316 12:11:39.049115 55708 solver.cpp:258]     Train net output #0: loss = 0.303249 (* 1 = 0.303249 loss)
I0316 12:11:39.049124 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00019894 (* 1 = 0.00019894 loss)
I0316 12:11:39.049130 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0503174 (* 1 = -0.0503174 loss)
I0316 12:11:39.049137 55708 sgd_solver.cpp:112] Iteration 5000, lr = 0.001
I0316 12:11:46.980284 55708 solver.cpp:239] Iteration 5100 (12.6084 iter/s, 7.9312s/100 iters), loss = 0.119762
I0316 12:11:46.980331 55708 solver.cpp:258]     Train net output #0: loss = 0.170586 (* 1 = 0.170586 loss)
I0316 12:11:46.980340 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000228015 (* 1 = 0.000228015 loss)
I0316 12:11:46.980361 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0510519 (* 1 = -0.0510519 loss)
I0316 12:11:46.980370 55708 sgd_solver.cpp:112] Iteration 5100, lr = 0.001
I0316 12:11:54.910706 55708 solver.cpp:239] Iteration 5200 (12.6097 iter/s, 7.93041s/100 iters), loss = 0.11458
I0316 12:11:54.910748 55708 solver.cpp:258]     Train net output #0: loss = 0.166649 (* 1 = 0.166649 loss)
I0316 12:11:54.910755 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000186555 (* 1 = 0.000186555 loss)
I0316 12:11:54.910776 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0522553 (* 1 = -0.0522553 loss)
I0316 12:11:54.910781 55708 sgd_solver.cpp:112] Iteration 5200, lr = 0.001
I0316 12:12:02.840261 55708 solver.cpp:239] Iteration 5300 (12.6111 iter/s, 7.92954s/100 iters), loss = 0.204393
I0316 12:12:02.840307 55708 solver.cpp:258]     Train net output #0: loss = 0.251935 (* 1 = 0.251935 loss)
I0316 12:12:02.840314 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000207273 (* 1 = 0.000207273 loss)
I0316 12:12:02.840319 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0477493 (* 1 = -0.0477493 loss)
I0316 12:12:02.840325 55708 sgd_solver.cpp:112] Iteration 5300, lr = 0.001
I0316 12:12:10.770592 55708 solver.cpp:239] Iteration 5400 (12.6098 iter/s, 7.93032s/100 iters), loss = 0.341565
I0316 12:12:10.770959 55708 solver.cpp:258]     Train net output #0: loss = 0.393324 (* 1 = 0.393324 loss)
I0316 12:12:10.770968 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000239457 (* 1 = 0.000239457 loss)
I0316 12:12:10.770975 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0519989 (* 1 = -0.0519989 loss)
I0316 12:12:10.770980 55708 sgd_solver.cpp:112] Iteration 5400, lr = 0.001
I0316 12:12:18.702208 55708 solver.cpp:239] Iteration 5500 (12.6083 iter/s, 7.93128s/100 iters), loss = 0.359085
I0316 12:12:18.702252 55708 solver.cpp:258]     Train net output #0: loss = 0.405573 (* 1 = 0.405573 loss)
I0316 12:12:18.702260 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000216308 (* 1 = 0.000216308 loss)
I0316 12:12:18.702283 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0467033 (* 1 = -0.0467033 loss)
I0316 12:12:18.702287 55708 sgd_solver.cpp:112] Iteration 5500, lr = 0.001
I0316 12:12:26.635785 55708 solver.cpp:239] Iteration 5600 (12.6047 iter/s, 7.93356s/100 iters), loss = 0.20037
I0316 12:12:26.635833 55708 solver.cpp:258]     Train net output #0: loss = 0.249032 (* 1 = 0.249032 loss)
I0316 12:12:26.635841 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000202194 (* 1 = 0.000202194 loss)
I0316 12:12:26.635847 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0488643 (* 1 = -0.0488643 loss)
I0316 12:12:26.635851 55708 sgd_solver.cpp:112] Iteration 5600, lr = 0.001
I0316 12:12:34.565312 55708 solver.cpp:239] Iteration 5700 (12.6111 iter/s, 7.92951s/100 iters), loss = 0.516703
I0316 12:12:34.565356 55708 solver.cpp:258]     Train net output #0: loss = 0.56342 (* 1 = 0.56342 loss)
I0316 12:12:34.565363 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000205299 (* 1 = 0.000205299 loss)
I0316 12:12:34.565369 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0469226 (* 1 = -0.0469226 loss)
I0316 12:12:34.565374 55708 sgd_solver.cpp:112] Iteration 5700, lr = 0.001
I0316 12:12:42.495602 55708 solver.cpp:239] Iteration 5800 (12.6099 iter/s, 7.93027s/100 iters), loss = 0.215343
I0316 12:12:42.495929 55708 solver.cpp:258]     Train net output #0: loss = 0.265904 (* 1 = 0.265904 loss)
I0316 12:12:42.495936 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000214281 (* 1 = 0.000214281 loss)
I0316 12:12:42.495944 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0507753 (* 1 = -0.0507753 loss)
I0316 12:12:42.495949 55708 sgd_solver.cpp:112] Iteration 5800, lr = 0.001
I0316 12:12:50.425266 55708 solver.cpp:239] Iteration 5900 (12.6113 iter/s, 7.92937s/100 iters), loss = 0.143163
I0316 12:12:50.425309 55708 solver.cpp:258]     Train net output #0: loss = 0.191833 (* 1 = 0.191833 loss)
I0316 12:12:50.425318 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000184946 (* 1 = 0.000184946 loss)
I0316 12:12:50.425323 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0488544 (* 1 = -0.0488544 loss)
I0316 12:12:50.425328 55708 sgd_solver.cpp:112] Iteration 5900, lr = 0.001
I0316 12:12:58.276182 55708 solver.cpp:351] Iteration 6000, Testing net (#0)
I0316 12:13:03.208540 55708 solver.cpp:418]     Test net output #0: loss = 0.450443 (* 1 = 0.450443 loss)
I0316 12:13:03.208570 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000217256 (* 1 = 0.000217256 loss)
I0316 12:13:03.208575 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0519037 (* 1 = -0.0519037 loss)
I0316 12:13:03.208580 55708 solver.cpp:418]     Test net output #3: top-1 = 0.855156
I0316 12:13:03.208583 55708 solver.cpp:418]     Test net output #4: top-5 = 0.990781
I0316 12:13:03.286332 55708 solver.cpp:239] Iteration 6000 (7.77539 iter/s, 12.8611s/100 iters), loss = 0.173615
I0316 12:13:03.286365 55708 solver.cpp:258]     Train net output #0: loss = 0.227769 (* 1 = 0.227769 loss)
I0316 12:13:03.286371 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00019168 (* 1 = 0.00019168 loss)
I0316 12:13:03.286377 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0543466 (* 1 = -0.0543466 loss)
I0316 12:13:03.286384 55708 sgd_solver.cpp:112] Iteration 6000, lr = 0.001
I0316 12:13:11.215386 55708 solver.cpp:239] Iteration 6100 (12.6118 iter/s, 7.92905s/100 iters), loss = 0.207662
I0316 12:13:11.215436 55708 solver.cpp:258]     Train net output #0: loss = 0.259911 (* 1 = 0.259911 loss)
I0316 12:13:11.215445 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000190872 (* 1 = 0.000190872 loss)
I0316 12:13:11.215468 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0524399 (* 1 = -0.0524399 loss)
I0316 12:13:11.215474 55708 sgd_solver.cpp:112] Iteration 6100, lr = 0.001
I0316 12:13:19.144543 55708 solver.cpp:239] Iteration 6200 (12.6117 iter/s, 7.92914s/100 iters), loss = 0.238827
I0316 12:13:19.144901 55708 solver.cpp:258]     Train net output #0: loss = 0.294865 (* 1 = 0.294865 loss)
I0316 12:13:19.144908 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000237236 (* 1 = 0.000237236 loss)
I0316 12:13:19.144914 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.056275 (* 1 = -0.056275 loss)
I0316 12:13:19.144919 55708 sgd_solver.cpp:112] Iteration 6200, lr = 0.001
I0316 12:13:22.716446 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:13:27.077407 55708 solver.cpp:239] Iteration 6300 (12.6063 iter/s, 7.93255s/100 iters), loss = 0.114849
I0316 12:13:27.077455 55708 solver.cpp:258]     Train net output #0: loss = 0.166645 (* 1 = 0.166645 loss)
I0316 12:13:27.077462 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000173552 (* 1 = 0.000173552 loss)
I0316 12:13:27.077468 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0519694 (* 1 = -0.0519694 loss)
I0316 12:13:27.077473 55708 sgd_solver.cpp:112] Iteration 6300, lr = 0.001
I0316 12:13:35.006893 55708 solver.cpp:239] Iteration 6400 (12.6112 iter/s, 7.92947s/100 iters), loss = 0.446341
I0316 12:13:35.006932 55708 solver.cpp:258]     Train net output #0: loss = 0.501039 (* 1 = 0.501039 loss)
I0316 12:13:35.006939 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000161263 (* 1 = 0.000161263 loss)
I0316 12:13:35.006945 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0548599 (* 1 = -0.0548599 loss)
I0316 12:13:35.006950 55708 sgd_solver.cpp:112] Iteration 6400, lr = 0.001
I0316 12:13:42.939375 55708 solver.cpp:239] Iteration 6500 (12.6064 iter/s, 7.93247s/100 iters), loss = 0.0780744
I0316 12:13:42.939424 55708 solver.cpp:258]     Train net output #0: loss = 0.13116 (* 1 = 0.13116 loss)
I0316 12:13:42.939430 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000221217 (* 1 = 0.000221217 loss)
I0316 12:13:42.939435 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0533071 (* 1 = -0.0533071 loss)
I0316 12:13:42.939440 55708 sgd_solver.cpp:112] Iteration 6500, lr = 0.001
I0316 12:13:50.870239 55708 solver.cpp:239] Iteration 6600 (12.609 iter/s, 7.93085s/100 iters), loss = 0.144393
I0316 12:13:50.870627 55708 solver.cpp:258]     Train net output #0: loss = 0.197062 (* 1 = 0.197062 loss)
I0316 12:13:50.870635 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000194154 (* 1 = 0.000194154 loss)
I0316 12:13:50.870641 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0528628 (* 1 = -0.0528628 loss)
I0316 12:13:50.870647 55708 sgd_solver.cpp:112] Iteration 6600, lr = 0.001
I0316 12:13:58.803246 55708 solver.cpp:239] Iteration 6700 (12.6061 iter/s, 7.93266s/100 iters), loss = 0.0664647
I0316 12:13:58.803292 55708 solver.cpp:258]     Train net output #0: loss = 0.124726 (* 1 = 0.124726 loss)
I0316 12:13:58.803298 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000223414 (* 1 = 0.000223414 loss)
I0316 12:13:58.803321 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.058485 (* 1 = -0.058485 loss)
I0316 12:13:58.803326 55708 sgd_solver.cpp:112] Iteration 6700, lr = 0.001
I0316 12:14:06.733530 55708 solver.cpp:239] Iteration 6800 (12.6099 iter/s, 7.93027s/100 iters), loss = 0.0818402
I0316 12:14:06.733577 55708 solver.cpp:258]     Train net output #0: loss = 0.1328 (* 1 = 0.1328 loss)
I0316 12:14:06.733585 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000218548 (* 1 = 0.000218548 loss)
I0316 12:14:06.733590 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0511782 (* 1 = -0.0511782 loss)
I0316 12:14:06.733595 55708 sgd_solver.cpp:112] Iteration 6800, lr = 0.001
I0316 12:14:14.663357 55708 solver.cpp:239] Iteration 6900 (12.6106 iter/s, 7.92982s/100 iters), loss = 0.13168
I0316 12:14:14.663398 55708 solver.cpp:258]     Train net output #0: loss = 0.18906 (* 1 = 0.18906 loss)
I0316 12:14:14.663404 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000209123 (* 1 = 0.000209123 loss)
I0316 12:14:14.663426 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0575888 (* 1 = -0.0575888 loss)
I0316 12:14:14.663431 55708 sgd_solver.cpp:112] Iteration 6900, lr = 0.001
I0316 12:14:22.515558 55708 solver.cpp:351] Iteration 7000, Testing net (#0)
I0316 12:14:23.650719 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:14:27.442696 55708 solver.cpp:418]     Test net output #0: loss = 0.459167 (* 1 = 0.459167 loss)
I0316 12:14:27.442720 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000220015 (* 1 = 0.000220015 loss)
I0316 12:14:27.442726 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0534089 (* 1 = -0.0534089 loss)
I0316 12:14:27.442731 55708 solver.cpp:418]     Test net output #3: top-1 = 0.851875
I0316 12:14:27.442735 55708 solver.cpp:418]     Test net output #4: top-5 = 0.992188
I0316 12:14:27.520504 55708 solver.cpp:239] Iteration 7000 (7.77776 iter/s, 12.8572s/100 iters), loss = 0.0571094
I0316 12:14:27.520534 55708 solver.cpp:258]     Train net output #0: loss = 0.112142 (* 1 = 0.112142 loss)
I0316 12:14:27.520541 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000246069 (* 1 = 0.000246069 loss)
I0316 12:14:27.520547 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0552784 (* 1 = -0.0552784 loss)
I0316 12:14:27.520552 55708 sgd_solver.cpp:112] Iteration 7000, lr = 0.001
I0316 12:14:35.450841 55708 solver.cpp:239] Iteration 7100 (12.6098 iter/s, 7.93035s/100 iters), loss = 0.17315
I0316 12:14:35.450881 55708 solver.cpp:258]     Train net output #0: loss = 0.22487 (* 1 = 0.22487 loss)
I0316 12:14:35.450887 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00019906 (* 1 = 0.00019906 loss)
I0316 12:14:35.450893 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0519185 (* 1 = -0.0519185 loss)
I0316 12:14:35.450914 55708 sgd_solver.cpp:112] Iteration 7100, lr = 0.001
I0316 12:14:43.382126 55708 solver.cpp:239] Iteration 7200 (12.6083 iter/s, 7.93127s/100 iters), loss = 0.106868
I0316 12:14:43.382171 55708 solver.cpp:258]     Train net output #0: loss = 0.163057 (* 1 = 0.163057 loss)
I0316 12:14:43.382179 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000229732 (* 1 = 0.000229732 loss)
I0316 12:14:43.382201 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0564187 (* 1 = -0.0564187 loss)
I0316 12:14:43.382205 55708 sgd_solver.cpp:112] Iteration 7200, lr = 0.001
I0316 12:14:51.313957 55708 solver.cpp:239] Iteration 7300 (12.6074 iter/s, 7.93182s/100 iters), loss = 0.390044
I0316 12:14:51.313995 55708 solver.cpp:258]     Train net output #0: loss = 0.442119 (* 1 = 0.442119 loss)
I0316 12:14:51.314003 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00023947 (* 1 = 0.00023947 loss)
I0316 12:14:51.314008 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0523141 (* 1 = -0.0523141 loss)
I0316 12:14:51.314013 55708 sgd_solver.cpp:112] Iteration 7300, lr = 0.001
I0316 12:14:59.244369 55708 solver.cpp:239] Iteration 7400 (12.6097 iter/s, 7.93041s/100 iters), loss = 0.103589
I0316 12:14:59.244676 55708 solver.cpp:258]     Train net output #0: loss = 0.161179 (* 1 = 0.161179 loss)
I0316 12:14:59.244684 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000278308 (* 1 = 0.000278308 loss)
I0316 12:14:59.244690 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0578681 (* 1 = -0.0578681 loss)
I0316 12:14:59.244695 55708 sgd_solver.cpp:112] Iteration 7400, lr = 0.001
I0316 12:15:07.179570 55708 solver.cpp:239] Iteration 7500 (12.6025 iter/s, 7.93492s/100 iters), loss = 0.193074
I0316 12:15:07.179646 55708 solver.cpp:258]     Train net output #0: loss = 0.245483 (* 1 = 0.245483 loss)
I0316 12:15:07.179672 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000278297 (* 1 = 0.000278297 loss)
I0316 12:15:07.179682 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0526879 (* 1 = -0.0526879 loss)
I0316 12:15:07.179688 55708 sgd_solver.cpp:112] Iteration 7500, lr = 0.001
I0316 12:15:15.122287 55708 solver.cpp:239] Iteration 7600 (12.5902 iter/s, 7.94268s/100 iters), loss = 0.183031
I0316 12:15:15.122329 55708 solver.cpp:258]     Train net output #0: loss = 0.238092 (* 1 = 0.238092 loss)
I0316 12:15:15.122336 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000323262 (* 1 = 0.000323262 loss)
I0316 12:15:15.122359 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0553837 (* 1 = -0.0553837 loss)
I0316 12:15:15.122364 55708 sgd_solver.cpp:112] Iteration 7600, lr = 0.001
I0316 12:15:23.053288 55708 solver.cpp:239] Iteration 7700 (12.6088 iter/s, 7.93099s/100 iters), loss = 0.216546
I0316 12:15:23.053333 55708 solver.cpp:258]     Train net output #0: loss = 0.272169 (* 1 = 0.272169 loss)
I0316 12:15:23.053341 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000237318 (* 1 = 0.000237318 loss)
I0316 12:15:23.053347 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0558598 (* 1 = -0.0558598 loss)
I0316 12:15:23.053352 55708 sgd_solver.cpp:112] Iteration 7700, lr = 0.001
I0316 12:15:30.983017 55708 solver.cpp:239] Iteration 7800 (12.6108 iter/s, 7.92972s/100 iters), loss = 0.196681
I0316 12:15:30.983325 55708 solver.cpp:258]     Train net output #0: loss = 0.250204 (* 1 = 0.250204 loss)
I0316 12:15:30.983333 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000207921 (* 1 = 0.000207921 loss)
I0316 12:15:30.983340 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0537305 (* 1 = -0.0537305 loss)
I0316 12:15:30.983345 55708 sgd_solver.cpp:112] Iteration 7800, lr = 0.001
I0316 12:15:31.620051 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:15:38.913885 55708 solver.cpp:239] Iteration 7900 (12.6094 iter/s, 7.9306s/100 iters), loss = 0.0179224
I0316 12:15:38.913926 55708 solver.cpp:258]     Train net output #0: loss = 0.0793676 (* 1 = 0.0793676 loss)
I0316 12:15:38.913933 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000215421 (* 1 = 0.000215421 loss)
I0316 12:15:38.913955 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0616604 (* 1 = -0.0616604 loss)
I0316 12:15:38.913960 55708 sgd_solver.cpp:112] Iteration 7900, lr = 0.001
I0316 12:15:46.769574 55708 solver.cpp:351] Iteration 8000, Testing net (#0)
I0316 12:15:50.690626 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:15:51.701074 55708 solver.cpp:418]     Test net output #0: loss = 0.439264 (* 1 = 0.439264 loss)
I0316 12:15:51.701100 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000230013 (* 1 = 0.000230013 loss)
I0316 12:15:51.701107 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0558046 (* 1 = -0.0558046 loss)
I0316 12:15:51.701112 55708 solver.cpp:418]     Test net output #3: top-1 = 0.857656
I0316 12:15:51.701117 55708 solver.cpp:418]     Test net output #4: top-5 = 0.991094
I0316 12:15:51.778796 55708 solver.cpp:239] Iteration 8000 (7.77307 iter/s, 12.8649s/100 iters), loss = 0.0426254
I0316 12:15:51.778865 55708 solver.cpp:258]     Train net output #0: loss = 0.102629 (* 1 = 0.102629 loss)
I0316 12:15:51.778887 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000247967 (* 1 = 0.000247967 loss)
I0316 12:15:51.778906 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0602518 (* 1 = -0.0602518 loss)
I0316 12:15:51.778925 55708 sgd_solver.cpp:112] Iteration 8000, lr = 0.001
I0316 12:15:59.710024 55708 solver.cpp:239] Iteration 8100 (12.6084 iter/s, 7.9312s/100 iters), loss = 0.199498
I0316 12:15:59.710072 55708 solver.cpp:258]     Train net output #0: loss = 0.251607 (* 1 = 0.251607 loss)
I0316 12:15:59.710081 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00019583 (* 1 = 0.00019583 loss)
I0316 12:15:59.710089 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.052304 (* 1 = -0.052304 loss)
I0316 12:15:59.710095 55708 sgd_solver.cpp:112] Iteration 8100, lr = 0.001
I0316 12:16:07.642421 55708 solver.cpp:239] Iteration 8200 (12.6066 iter/s, 7.93238s/100 iters), loss = 0.0710861
I0316 12:16:07.642804 55708 solver.cpp:258]     Train net output #0: loss = 0.129261 (* 1 = 0.129261 loss)
I0316 12:16:07.642817 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000247 (* 1 = 0.000247 loss)
I0316 12:16:07.642828 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0584223 (* 1 = -0.0584223 loss)
I0316 12:16:07.642836 55708 sgd_solver.cpp:112] Iteration 8200, lr = 0.001
I0316 12:16:15.567441 55708 solver.cpp:239] Iteration 8300 (12.6188 iter/s, 7.92467s/100 iters), loss = 0.140755
I0316 12:16:15.567510 55708 solver.cpp:258]     Train net output #0: loss = 0.196977 (* 1 = 0.196977 loss)
I0316 12:16:15.567526 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000256732 (* 1 = 0.000256732 loss)
I0316 12:16:15.567541 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0564784 (* 1 = -0.0564784 loss)
I0316 12:16:15.567555 55708 sgd_solver.cpp:112] Iteration 8300, lr = 0.001
I0316 12:16:23.499944 55708 solver.cpp:239] Iteration 8400 (12.6064 iter/s, 7.93247s/100 iters), loss = 0.0366552
I0316 12:16:23.500000 55708 solver.cpp:258]     Train net output #0: loss = 0.0952527 (* 1 = 0.0952527 loss)
I0316 12:16:23.500008 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000245414 (* 1 = 0.000245414 loss)
I0316 12:16:23.500017 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0588427 (* 1 = -0.0588427 loss)
I0316 12:16:23.500023 55708 sgd_solver.cpp:112] Iteration 8400, lr = 0.001
I0316 12:16:31.430598 55708 solver.cpp:239] Iteration 8500 (12.6093 iter/s, 7.93064s/100 iters), loss = 0.171069
I0316 12:16:31.430641 55708 solver.cpp:258]     Train net output #0: loss = 0.227751 (* 1 = 0.227751 loss)
I0316 12:16:31.430649 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000296258 (* 1 = 0.000296258 loss)
I0316 12:16:31.430655 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.056978 (* 1 = -0.056978 loss)
I0316 12:16:31.430675 55708 sgd_solver.cpp:112] Iteration 8500, lr = 0.001
I0316 12:16:39.362053 55708 solver.cpp:239] Iteration 8600 (12.608 iter/s, 7.93145s/100 iters), loss = 0.252516
I0316 12:16:39.362401 55708 solver.cpp:258]     Train net output #0: loss = 0.30549 (* 1 = 0.30549 loss)
I0316 12:16:39.362409 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000265507 (* 1 = 0.000265507 loss)
I0316 12:16:39.362416 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0532393 (* 1 = -0.0532393 loss)
I0316 12:16:39.362421 55708 sgd_solver.cpp:112] Iteration 8600, lr = 0.001
I0316 12:16:47.293769 55708 solver.cpp:239] Iteration 8700 (12.6081 iter/s, 7.9314s/100 iters), loss = 0.0713679
I0316 12:16:47.293817 55708 solver.cpp:258]     Train net output #0: loss = 0.128231 (* 1 = 0.128231 loss)
I0316 12:16:47.293823 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000265597 (* 1 = 0.000265597 loss)
I0316 12:16:47.293828 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0571287 (* 1 = -0.0571287 loss)
I0316 12:16:47.293850 55708 sgd_solver.cpp:112] Iteration 8700, lr = 0.001
I0316 12:16:55.224658 55708 solver.cpp:239] Iteration 8800 (12.6089 iter/s, 7.93088s/100 iters), loss = 0.282147
I0316 12:16:55.224697 55708 solver.cpp:258]     Train net output #0: loss = 0.339434 (* 1 = 0.339434 loss)
I0316 12:16:55.224704 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000250225 (* 1 = 0.000250225 loss)
I0316 12:16:55.224710 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0575375 (* 1 = -0.0575375 loss)
I0316 12:16:55.224715 55708 sgd_solver.cpp:112] Iteration 8800, lr = 0.001
I0316 12:17:03.157429 55708 solver.cpp:239] Iteration 8900 (12.606 iter/s, 7.93275s/100 iters), loss = 0.0500622
I0316 12:17:03.157500 55708 solver.cpp:258]     Train net output #0: loss = 0.106327 (* 1 = 0.106327 loss)
I0316 12:17:03.157511 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000239447 (* 1 = 0.000239447 loss)
I0316 12:17:03.157517 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0565038 (* 1 = -0.0565038 loss)
I0316 12:17:03.157522 55708 sgd_solver.cpp:112] Iteration 8900, lr = 0.001
I0316 12:17:11.010524 55708 solver.cpp:351] Iteration 9000, Testing net (#0)
I0316 12:17:15.940007 55708 solver.cpp:418]     Test net output #0: loss = 0.451714 (* 1 = 0.451714 loss)
I0316 12:17:15.940034 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000243419 (* 1 = 0.000243419 loss)
I0316 12:17:15.940040 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.057848 (* 1 = -0.057848 loss)
I0316 12:17:15.940044 55708 solver.cpp:418]     Test net output #3: top-1 = 0.854219
I0316 12:17:15.940049 55708 solver.cpp:418]     Test net output #4: top-5 = 0.992969
I0316 12:17:16.017768 55708 solver.cpp:239] Iteration 9000 (7.77584 iter/s, 12.8603s/100 iters), loss = 0.0848205
I0316 12:17:16.017797 55708 solver.cpp:258]     Train net output #0: loss = 0.142375 (* 1 = 0.142375 loss)
I0316 12:17:16.017803 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000203701 (* 1 = 0.000203701 loss)
I0316 12:17:16.017809 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.057758 (* 1 = -0.057758 loss)
I0316 12:17:16.017832 55708 sgd_solver.cpp:112] Iteration 9000, lr = 0.001
I0316 12:17:23.948022 55708 solver.cpp:239] Iteration 9100 (12.6099 iter/s, 7.93025s/100 iters), loss = 0.0836646
I0316 12:17:23.948071 55708 solver.cpp:258]     Train net output #0: loss = 0.139678 (* 1 = 0.139678 loss)
I0316 12:17:23.948079 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000232671 (* 1 = 0.000232671 loss)
I0316 12:17:23.948086 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0562465 (* 1 = -0.0562465 loss)
I0316 12:17:23.948089 55708 sgd_solver.cpp:112] Iteration 9100, lr = 0.001
I0316 12:17:31.879431 55708 solver.cpp:239] Iteration 9200 (12.6081 iter/s, 7.9314s/100 iters), loss = 0.0815539
I0316 12:17:31.879474 55708 solver.cpp:258]     Train net output #0: loss = 0.137828 (* 1 = 0.137828 loss)
I0316 12:17:31.879482 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000252971 (* 1 = 0.000252971 loss)
I0316 12:17:31.879487 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0565267 (* 1 = -0.0565267 loss)
I0316 12:17:31.879508 55708 sgd_solver.cpp:112] Iteration 9200, lr = 0.001
I0316 12:17:39.808126 55708 solver.cpp:239] Iteration 9300 (12.6124 iter/s, 7.92869s/100 iters), loss = 0.0141489
I0316 12:17:39.808167 55708 solver.cpp:258]     Train net output #0: loss = 0.0773615 (* 1 = 0.0773615 loss)
I0316 12:17:39.808174 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000271387 (* 1 = 0.000271387 loss)
I0316 12:17:39.808197 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.063484 (* 1 = -0.063484 loss)
I0316 12:17:39.808202 55708 sgd_solver.cpp:112] Iteration 9300, lr = 0.001
I0316 12:17:45.361886 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:17:47.737866 55708 solver.cpp:239] Iteration 9400 (12.6108 iter/s, 7.92973s/100 iters), loss = 0.0769306
I0316 12:17:47.737908 55708 solver.cpp:258]     Train net output #0: loss = 0.140469 (* 1 = 0.140469 loss)
I0316 12:17:47.737915 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000269252 (* 1 = 0.000269252 loss)
I0316 12:17:47.737937 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0638074 (* 1 = -0.0638074 loss)
I0316 12:17:47.737942 55708 sgd_solver.cpp:112] Iteration 9400, lr = 0.001
I0316 12:17:55.666020 55708 solver.cpp:239] Iteration 9500 (12.6133 iter/s, 7.92815s/100 iters), loss = 0.0329929
I0316 12:17:55.666062 55708 solver.cpp:258]     Train net output #0: loss = 0.095166 (* 1 = 0.095166 loss)
I0316 12:17:55.666069 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000218533 (* 1 = 0.000218533 loss)
I0316 12:17:55.666074 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0623916 (* 1 = -0.0623916 loss)
I0316 12:17:55.666095 55708 sgd_solver.cpp:112] Iteration 9500, lr = 0.001
I0316 12:18:03.593206 55708 solver.cpp:239] Iteration 9600 (12.6148 iter/s, 7.92717s/100 iters), loss = 0.165085
I0316 12:18:03.593253 55708 solver.cpp:258]     Train net output #0: loss = 0.224411 (* 1 = 0.224411 loss)
I0316 12:18:03.593259 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000237935 (* 1 = 0.000237935 loss)
I0316 12:18:03.593266 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0595646 (* 1 = -0.0595646 loss)
I0316 12:18:03.593271 55708 sgd_solver.cpp:112] Iteration 9600, lr = 0.001
I0316 12:18:11.522791 55708 solver.cpp:239] Iteration 9700 (12.611 iter/s, 7.92957s/100 iters), loss = -0.0179105
I0316 12:18:11.522832 55708 solver.cpp:258]     Train net output #0: loss = 0.0472677 (* 1 = 0.0472677 loss)
I0316 12:18:11.522840 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000287683 (* 1 = 0.000287683 loss)
I0316 12:18:11.522845 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0654659 (* 1 = -0.0654659 loss)
I0316 12:18:11.522850 55708 sgd_solver.cpp:112] Iteration 9700, lr = 0.001
I0316 12:18:19.452275 55708 solver.cpp:239] Iteration 9800 (12.6112 iter/s, 7.92948s/100 iters), loss = 0.187953
I0316 12:18:19.452587 55708 solver.cpp:258]     Train net output #0: loss = 0.245864 (* 1 = 0.245864 loss)
I0316 12:18:19.452597 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000293974 (* 1 = 0.000293974 loss)
I0316 12:18:19.452603 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0582054 (* 1 = -0.0582054 loss)
I0316 12:18:19.452610 55708 sgd_solver.cpp:112] Iteration 9800, lr = 0.001
I0316 12:18:27.381903 55708 solver.cpp:239] Iteration 9900 (12.6114 iter/s, 7.92935s/100 iters), loss = 0.132277
I0316 12:18:27.381953 55708 solver.cpp:258]     Train net output #0: loss = 0.185036 (* 1 = 0.185036 loss)
I0316 12:18:27.381959 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000221364 (* 1 = 0.000221364 loss)
I0316 12:18:27.381965 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0529811 (* 1 = -0.0529811 loss)
I0316 12:18:27.381970 55708 sgd_solver.cpp:112] Iteration 9900, lr = 0.001
I0316 12:18:35.234005 55708 solver.cpp:351] Iteration 10000, Testing net (#0)
I0316 12:18:36.985132 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:18:40.162544 55708 solver.cpp:418]     Test net output #0: loss = 0.457167 (* 1 = 0.457167 loss)
I0316 12:18:40.162568 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000239371 (* 1 = 0.000239371 loss)
I0316 12:18:40.162575 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0583455 (* 1 = -0.0583455 loss)
I0316 12:18:40.162580 55708 solver.cpp:418]     Test net output #3: top-1 = 0.85375
I0316 12:18:40.162583 55708 solver.cpp:418]     Test net output #4: top-5 = 0.992344
I0316 12:18:40.240252 55708 solver.cpp:239] Iteration 10000 (7.77704 iter/s, 12.8584s/100 iters), loss = 0.160865
I0316 12:18:40.240280 55708 solver.cpp:258]     Train net output #0: loss = 0.220314 (* 1 = 0.220314 loss)
I0316 12:18:40.240288 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000221146 (* 1 = 0.000221146 loss)
I0316 12:18:40.240293 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.059671 (* 1 = -0.059671 loss)
I0316 12:18:40.240298 55708 sgd_solver.cpp:112] Iteration 10000, lr = 0.001
I0316 12:18:48.170400 55708 solver.cpp:239] Iteration 10100 (12.6101 iter/s, 7.93014s/100 iters), loss = 0.0680286
I0316 12:18:48.170444 55708 solver.cpp:258]     Train net output #0: loss = 0.129693 (* 1 = 0.129693 loss)
I0316 12:18:48.170450 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000231783 (* 1 = 0.000231783 loss)
I0316 12:18:48.170472 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0618962 (* 1 = -0.0618962 loss)
I0316 12:18:48.170477 55708 sgd_solver.cpp:112] Iteration 10100, lr = 0.001
I0316 12:18:56.099342 55708 solver.cpp:239] Iteration 10200 (12.612 iter/s, 7.92893s/100 iters), loss = 0.0306922
I0316 12:18:56.099718 55708 solver.cpp:258]     Train net output #0: loss = 0.0883017 (* 1 = 0.0883017 loss)
I0316 12:18:56.099727 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000248914 (* 1 = 0.000248914 loss)
I0316 12:18:56.099735 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0578585 (* 1 = -0.0578585 loss)
I0316 12:18:56.099740 55708 sgd_solver.cpp:112] Iteration 10200, lr = 0.001
I0316 12:19:04.029716 55708 solver.cpp:239] Iteration 10300 (12.6103 iter/s, 7.93003s/100 iters), loss = 0.0370021
I0316 12:19:04.029763 55708 solver.cpp:258]     Train net output #0: loss = 0.0960065 (* 1 = 0.0960065 loss)
I0316 12:19:04.029772 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000253153 (* 1 = 0.000253153 loss)
I0316 12:19:04.029776 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0592577 (* 1 = -0.0592577 loss)
I0316 12:19:04.029781 55708 sgd_solver.cpp:112] Iteration 10300, lr = 0.001
I0316 12:19:11.958990 55708 solver.cpp:239] Iteration 10400 (12.6115 iter/s, 7.92926s/100 iters), loss = 0.0666044
I0316 12:19:11.959033 55708 solver.cpp:258]     Train net output #0: loss = 0.124673 (* 1 = 0.124673 loss)
I0316 12:19:11.959041 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00018728 (* 1 = 0.00018728 loss)
I0316 12:19:11.959048 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0582556 (* 1 = -0.0582556 loss)
I0316 12:19:11.959051 55708 sgd_solver.cpp:112] Iteration 10400, lr = 0.001
I0316 12:19:19.887614 55708 solver.cpp:239] Iteration 10500 (12.6125 iter/s, 7.92861s/100 iters), loss = 0.179568
I0316 12:19:19.887657 55708 solver.cpp:258]     Train net output #0: loss = 0.235381 (* 1 = 0.235381 loss)
I0316 12:19:19.887665 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000229065 (* 1 = 0.000229065 loss)
I0316 12:19:19.887670 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0560423 (* 1 = -0.0560423 loss)
I0316 12:19:19.887676 55708 sgd_solver.cpp:112] Iteration 10500, lr = 0.001
I0316 12:19:27.820286 55708 solver.cpp:239] Iteration 10600 (12.6061 iter/s, 7.93265s/100 iters), loss = 0.237649
I0316 12:19:27.820713 55708 solver.cpp:258]     Train net output #0: loss = 0.297419 (* 1 = 0.297419 loss)
I0316 12:19:27.820721 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000275745 (* 1 = 0.000275745 loss)
I0316 12:19:27.820729 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0600459 (* 1 = -0.0600459 loss)
I0316 12:19:27.820734 55708 sgd_solver.cpp:112] Iteration 10600, lr = 0.001
I0316 12:19:35.754384 55708 solver.cpp:239] Iteration 10700 (12.6044 iter/s, 7.93371s/100 iters), loss = 0.202678
I0316 12:19:35.754423 55708 solver.cpp:258]     Train net output #0: loss = 0.260282 (* 1 = 0.260282 loss)
I0316 12:19:35.754431 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000274366 (* 1 = 0.000274366 loss)
I0316 12:19:35.754437 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0578789 (* 1 = -0.0578789 loss)
I0316 12:19:35.754442 55708 sgd_solver.cpp:112] Iteration 10700, lr = 0.001
I0316 12:19:43.685237 55708 solver.cpp:239] Iteration 10800 (12.609 iter/s, 7.93084s/100 iters), loss = 0.0723577
I0316 12:19:43.685285 55708 solver.cpp:258]     Train net output #0: loss = 0.131138 (* 1 = 0.131138 loss)
I0316 12:19:43.685292 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000223402 (* 1 = 0.000223402 loss)
I0316 12:19:43.685297 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0590038 (* 1 = -0.0590038 loss)
I0316 12:19:43.685302 55708 sgd_solver.cpp:112] Iteration 10800, lr = 0.001
I0316 12:19:51.614859 55708 solver.cpp:239] Iteration 10900 (12.611 iter/s, 7.92961s/100 iters), loss = 0.0631274
I0316 12:19:51.614899 55708 solver.cpp:258]     Train net output #0: loss = 0.119404 (* 1 = 0.119404 loss)
I0316 12:19:51.614907 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000191375 (* 1 = 0.000191375 loss)
I0316 12:19:51.614928 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0564682 (* 1 = -0.0564682 loss)
I0316 12:19:51.614933 55708 sgd_solver.cpp:112] Iteration 10900, lr = 0.001
I0316 12:19:54.232810 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:19:59.464622 55708 solver.cpp:351] Iteration 11000, Testing net (#0)
I0316 12:20:03.998989 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:20:04.392191 55708 solver.cpp:418]     Test net output #0: loss = 0.458682 (* 1 = 0.458682 loss)
I0316 12:20:04.392211 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000239223 (* 1 = 0.000239223 loss)
I0316 12:20:04.392216 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0596896 (* 1 = -0.0596896 loss)
I0316 12:20:04.392221 55708 solver.cpp:418]     Test net output #3: top-1 = 0.855156
I0316 12:20:04.392226 55708 solver.cpp:418]     Test net output #4: top-5 = 0.992344
I0316 12:20:04.469928 55708 solver.cpp:239] Iteration 11000 (7.77902 iter/s, 12.8551s/100 iters), loss = 0.103843
I0316 12:20:04.469954 55708 solver.cpp:258]     Train net output #0: loss = 0.16423 (* 1 = 0.16423 loss)
I0316 12:20:04.469961 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000275726 (* 1 = 0.000275726 loss)
I0316 12:20:04.469967 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0606627 (* 1 = -0.0606627 loss)
I0316 12:20:04.469976 55708 sgd_solver.cpp:112] Iteration 11000, lr = 0.001
I0316 12:20:12.397121 55708 solver.cpp:239] Iteration 11100 (12.6148 iter/s, 7.9272s/100 iters), loss = 0.150662
I0316 12:20:12.397163 55708 solver.cpp:258]     Train net output #0: loss = 0.212035 (* 1 = 0.212035 loss)
I0316 12:20:12.397171 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000222474 (* 1 = 0.000222474 loss)
I0316 12:20:12.397176 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0615961 (* 1 = -0.0615961 loss)
I0316 12:20:12.397181 55708 sgd_solver.cpp:112] Iteration 11100, lr = 0.001
I0316 12:20:20.325938 55708 solver.cpp:239] Iteration 11200 (12.6122 iter/s, 7.92881s/100 iters), loss = 0.0319208
I0316 12:20:20.325980 55708 solver.cpp:258]     Train net output #0: loss = 0.0953099 (* 1 = 0.0953099 loss)
I0316 12:20:20.325986 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000244953 (* 1 = 0.000244953 loss)
I0316 12:20:20.325992 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0636341 (* 1 = -0.0636341 loss)
I0316 12:20:20.325997 55708 sgd_solver.cpp:112] Iteration 11200, lr = 0.001
I0316 12:20:28.256377 55708 solver.cpp:239] Iteration 11300 (12.6097 iter/s, 7.93042s/100 iters), loss = 0.0641465
I0316 12:20:28.256439 55708 solver.cpp:258]     Train net output #0: loss = 0.120925 (* 1 = 0.120925 loss)
I0316 12:20:28.256446 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000256815 (* 1 = 0.000256815 loss)
I0316 12:20:28.256453 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0570354 (* 1 = -0.0570354 loss)
I0316 12:20:28.256458 55708 sgd_solver.cpp:112] Iteration 11300, lr = 0.001
I0316 12:20:36.186565 55708 solver.cpp:239] Iteration 11400 (12.6101 iter/s, 7.93016s/100 iters), loss = 0.0500567
I0316 12:20:36.186933 55708 solver.cpp:258]     Train net output #0: loss = 0.114134 (* 1 = 0.114134 loss)
I0316 12:20:36.186941 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000229702 (* 1 = 0.000229702 loss)
I0316 12:20:36.186949 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0643067 (* 1 = -0.0643067 loss)
I0316 12:20:36.186954 55708 sgd_solver.cpp:112] Iteration 11400, lr = 0.001
I0316 12:20:44.116297 55708 solver.cpp:239] Iteration 11500 (12.6113 iter/s, 7.92939s/100 iters), loss = 0.0725136
I0316 12:20:44.116346 55708 solver.cpp:258]     Train net output #0: loss = 0.134849 (* 1 = 0.134849 loss)
I0316 12:20:44.116354 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000270956 (* 1 = 0.000270956 loss)
I0316 12:20:44.116360 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0626068 (* 1 = -0.0626068 loss)
I0316 12:20:44.116369 55708 sgd_solver.cpp:112] Iteration 11500, lr = 0.001
I0316 12:20:52.045090 55708 solver.cpp:239] Iteration 11600 (12.6123 iter/s, 7.92878s/100 iters), loss = 0.191472
I0316 12:20:52.045131 55708 solver.cpp:258]     Train net output #0: loss = 0.250377 (* 1 = 0.250377 loss)
I0316 12:20:52.045138 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000286404 (* 1 = 0.000286404 loss)
I0316 12:20:52.045143 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0591914 (* 1 = -0.0591914 loss)
I0316 12:20:52.045148 55708 sgd_solver.cpp:112] Iteration 11600, lr = 0.001
I0316 12:20:59.975020 55708 solver.cpp:239] Iteration 11700 (12.6105 iter/s, 7.92992s/100 iters), loss = 0.00430136
I0316 12:20:59.975061 55708 solver.cpp:258]     Train net output #0: loss = 0.0707608 (* 1 = 0.0707608 loss)
I0316 12:20:59.975068 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000255657 (* 1 = 0.000255657 loss)
I0316 12:20:59.975090 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0667151 (* 1 = -0.0667151 loss)
I0316 12:20:59.975096 55708 sgd_solver.cpp:112] Iteration 11700, lr = 0.001
I0316 12:21:07.905125 55708 solver.cpp:239] Iteration 11800 (12.6102 iter/s, 7.9301s/100 iters), loss = 0.383989
I0316 12:21:07.905429 55708 solver.cpp:258]     Train net output #0: loss = 0.441911 (* 1 = 0.441911 loss)
I0316 12:21:07.905436 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000238431 (* 1 = 0.000238431 loss)
I0316 12:21:07.905443 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0581602 (* 1 = -0.0581602 loss)
I0316 12:21:07.905448 55708 sgd_solver.cpp:112] Iteration 11800, lr = 0.001
I0316 12:21:15.834771 55708 solver.cpp:239] Iteration 11900 (12.6113 iter/s, 7.9294s/100 iters), loss = 0.242544
I0316 12:21:15.834811 55708 solver.cpp:258]     Train net output #0: loss = 0.304666 (* 1 = 0.304666 loss)
I0316 12:21:15.834818 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000266123 (* 1 = 0.000266123 loss)
I0316 12:21:15.834841 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0623883 (* 1 = -0.0623883 loss)
I0316 12:21:15.834846 55708 sgd_solver.cpp:112] Iteration 11900, lr = 0.001
I0316 12:21:23.685408 55708 solver.cpp:351] Iteration 12000, Testing net (#0)
I0316 12:21:28.616669 55708 solver.cpp:418]     Test net output #0: loss = 0.449459 (* 1 = 0.449459 loss)
I0316 12:21:28.616695 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000250847 (* 1 = 0.000250847 loss)
I0316 12:21:28.616701 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0619345 (* 1 = -0.0619345 loss)
I0316 12:21:28.616705 55708 solver.cpp:418]     Test net output #3: top-1 = 0.85875
I0316 12:21:28.616710 55708 solver.cpp:418]     Test net output #4: top-5 = 0.991406
I0316 12:21:28.694386 55708 solver.cpp:239] Iteration 12000 (7.77625 iter/s, 12.8597s/100 iters), loss = 0.0332646
I0316 12:21:28.694411 55708 solver.cpp:258]     Train net output #0: loss = 0.0982873 (* 1 = 0.0982873 loss)
I0316 12:21:28.694418 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000236329 (* 1 = 0.000236329 loss)
I0316 12:21:28.694424 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0652591 (* 1 = -0.0652591 loss)
I0316 12:21:28.694430 55708 sgd_solver.cpp:112] Iteration 12000, lr = 0.001
I0316 12:21:36.624557 55708 solver.cpp:239] Iteration 12100 (12.61 iter/s, 7.9302s/100 iters), loss = 0.181478
I0316 12:21:36.624598 55708 solver.cpp:258]     Train net output #0: loss = 0.241122 (* 1 = 0.241122 loss)
I0316 12:21:36.624606 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000230811 (* 1 = 0.000230811 loss)
I0316 12:21:36.624612 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0598749 (* 1 = -0.0598749 loss)
I0316 12:21:36.624616 55708 sgd_solver.cpp:112] Iteration 12100, lr = 0.001
I0316 12:21:44.554661 55708 solver.cpp:239] Iteration 12200 (12.6102 iter/s, 7.93011s/100 iters), loss = 0.058917
I0316 12:21:44.555061 55708 solver.cpp:258]     Train net output #0: loss = 0.123476 (* 1 = 0.123476 loss)
I0316 12:21:44.555071 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000262709 (* 1 = 0.000262709 loss)
I0316 12:21:44.555078 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0648218 (* 1 = -0.0648218 loss)
I0316 12:21:44.555083 55708 sgd_solver.cpp:112] Iteration 12200, lr = 0.001
I0316 12:21:52.482300 55708 solver.cpp:239] Iteration 12300 (12.6146 iter/s, 7.9273s/100 iters), loss = 0.0478804
I0316 12:21:52.482342 55708 solver.cpp:258]     Train net output #0: loss = 0.110958 (* 1 = 0.110958 loss)
I0316 12:21:52.482348 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000289622 (* 1 = 0.000289622 loss)
I0316 12:21:52.482354 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0633677 (* 1 = -0.0633677 loss)
I0316 12:21:52.482359 55708 sgd_solver.cpp:112] Iteration 12300, lr = 0.001
I0316 12:22:00.409931 55708 solver.cpp:239] Iteration 12400 (12.6141 iter/s, 7.92764s/100 iters), loss = 0.144261
I0316 12:22:00.409970 55708 solver.cpp:258]     Train net output #0: loss = 0.203074 (* 1 = 0.203074 loss)
I0316 12:22:00.409977 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000220899 (* 1 = 0.000220899 loss)
I0316 12:22:00.410001 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0590336 (* 1 = -0.0590336 loss)
I0316 12:22:00.410005 55708 sgd_solver.cpp:112] Iteration 12400, lr = 0.001
I0316 12:22:07.946692 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:22:08.340461 55708 solver.cpp:239] Iteration 12500 (12.6095 iter/s, 7.93054s/100 iters), loss = 0.119504
I0316 12:22:08.340510 55708 solver.cpp:258]     Train net output #0: loss = 0.17852 (* 1 = 0.17852 loss)
I0316 12:22:08.340517 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000322609 (* 1 = 0.000322609 loss)
I0316 12:22:08.340523 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0593386 (* 1 = -0.0593386 loss)
I0316 12:22:08.340528 55708 sgd_solver.cpp:112] Iteration 12500, lr = 0.001
I0316 12:22:16.269222 55708 solver.cpp:239] Iteration 12600 (12.6123 iter/s, 7.92876s/100 iters), loss = 0.226437
I0316 12:22:16.269620 55708 solver.cpp:258]     Train net output #0: loss = 0.285159 (* 1 = 0.285159 loss)
I0316 12:22:16.269629 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000295484 (* 1 = 0.000295484 loss)
I0316 12:22:16.269635 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0590179 (* 1 = -0.0590179 loss)
I0316 12:22:16.269641 55708 sgd_solver.cpp:112] Iteration 12600, lr = 0.001
I0316 12:22:24.200778 55708 solver.cpp:239] Iteration 12700 (12.6084 iter/s, 7.93121s/100 iters), loss = 0.149686
I0316 12:22:24.200824 55708 solver.cpp:258]     Train net output #0: loss = 0.211864 (* 1 = 0.211864 loss)
I0316 12:22:24.200831 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000229957 (* 1 = 0.000229957 loss)
I0316 12:22:24.200837 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0624074 (* 1 = -0.0624074 loss)
I0316 12:22:24.200841 55708 sgd_solver.cpp:112] Iteration 12700, lr = 0.001
I0316 12:22:32.131125 55708 solver.cpp:239] Iteration 12800 (12.6098 iter/s, 7.93035s/100 iters), loss = 0.224986
I0316 12:22:32.131165 55708 solver.cpp:258]     Train net output #0: loss = 0.288786 (* 1 = 0.288786 loss)
I0316 12:22:32.131171 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000213281 (* 1 = 0.000213281 loss)
I0316 12:22:32.131193 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0640136 (* 1 = -0.0640136 loss)
I0316 12:22:32.131198 55708 sgd_solver.cpp:112] Iteration 12800, lr = 0.001
I0316 12:22:40.060005 55708 solver.cpp:239] Iteration 12900 (12.6121 iter/s, 7.92889s/100 iters), loss = 0.116449
I0316 12:22:40.060045 55708 solver.cpp:258]     Train net output #0: loss = 0.178866 (* 1 = 0.178866 loss)
I0316 12:22:40.060051 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000215658 (* 1 = 0.000215658 loss)
I0316 12:22:40.060073 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0626329 (* 1 = -0.0626329 loss)
I0316 12:22:40.060078 55708 sgd_solver.cpp:112] Iteration 12900, lr = 0.001
I0316 12:22:47.911931 55708 solver.cpp:351] Iteration 13000, Testing net (#0)
I0316 12:22:50.277408 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:22:52.844102 55708 solver.cpp:418]     Test net output #0: loss = 0.482363 (* 1 = 0.482363 loss)
I0316 12:22:52.844127 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000244387 (* 1 = 0.000244387 loss)
I0316 12:22:52.844134 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0616631 (* 1 = -0.0616631 loss)
I0316 12:22:52.844139 55708 solver.cpp:418]     Test net output #3: top-1 = 0.848125
I0316 12:22:52.844142 55708 solver.cpp:418]     Test net output #4: top-5 = 0.992188
I0316 12:22:52.922101 55708 solver.cpp:239] Iteration 13000 (7.77475 iter/s, 12.8622s/100 iters), loss = 0.0625305
I0316 12:22:52.922137 55708 solver.cpp:258]     Train net output #0: loss = 0.128276 (* 1 = 0.128276 loss)
I0316 12:22:52.922164 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000227616 (* 1 = 0.000227616 loss)
I0316 12:22:52.922174 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0659736 (* 1 = -0.0659736 loss)
I0316 12:22:52.922184 55708 sgd_solver.cpp:112] Iteration 13000, lr = 0.001
I0316 12:23:00.849797 55708 solver.cpp:239] Iteration 13100 (12.614 iter/s, 7.92771s/100 iters), loss = 0.0141806
I0316 12:23:00.849839 55708 solver.cpp:258]     Train net output #0: loss = 0.0808193 (* 1 = 0.0808193 loss)
I0316 12:23:00.849846 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000266719 (* 1 = 0.000266719 loss)
I0316 12:23:00.849851 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0669056 (* 1 = -0.0669056 loss)
I0316 12:23:00.849858 55708 sgd_solver.cpp:112] Iteration 13100, lr = 0.001
I0316 12:23:08.778697 55708 solver.cpp:239] Iteration 13200 (12.6121 iter/s, 7.9289s/100 iters), loss = 0.0991523
I0316 12:23:08.778743 55708 solver.cpp:258]     Train net output #0: loss = 0.163874 (* 1 = 0.163874 loss)
I0316 12:23:08.778750 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00027699 (* 1 = 0.00027699 loss)
I0316 12:23:08.778774 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0649985 (* 1 = -0.0649985 loss)
I0316 12:23:08.778777 55708 sgd_solver.cpp:112] Iteration 13200, lr = 0.001
I0316 12:23:16.707126 55708 solver.cpp:239] Iteration 13300 (12.6128 iter/s, 7.92844s/100 iters), loss = 0.0162113
I0316 12:23:16.707167 55708 solver.cpp:258]     Train net output #0: loss = 0.0818089 (* 1 = 0.0818089 loss)
I0316 12:23:16.707175 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000231148 (* 1 = 0.000231148 loss)
I0316 12:23:16.707180 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0658288 (* 1 = -0.0658288 loss)
I0316 12:23:16.707185 55708 sgd_solver.cpp:112] Iteration 13300, lr = 0.001
I0316 12:23:24.636516 55708 solver.cpp:239] Iteration 13400 (12.6113 iter/s, 7.92939s/100 iters), loss = 0.0497899
I0316 12:23:24.636904 55708 solver.cpp:258]     Train net output #0: loss = 0.11209 (* 1 = 0.11209 loss)
I0316 12:23:24.636914 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000269416 (* 1 = 0.000269416 loss)
I0316 12:23:24.636920 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0625696 (* 1 = -0.0625696 loss)
I0316 12:23:24.636925 55708 sgd_solver.cpp:112] Iteration 13400, lr = 0.001
I0316 12:23:32.566463 55708 solver.cpp:239] Iteration 13500 (12.611 iter/s, 7.92961s/100 iters), loss = 0.0212266
I0316 12:23:32.566505 55708 solver.cpp:258]     Train net output #0: loss = 0.0868609 (* 1 = 0.0868609 loss)
I0316 12:23:32.566512 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000247802 (* 1 = 0.000247802 loss)
I0316 12:23:32.566517 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0658821 (* 1 = -0.0658821 loss)
I0316 12:23:32.566524 55708 sgd_solver.cpp:112] Iteration 13500, lr = 0.001
I0316 12:23:40.495790 55708 solver.cpp:239] Iteration 13600 (12.6114 iter/s, 7.92934s/100 iters), loss = -0.017234
I0316 12:23:40.495832 55708 solver.cpp:258]     Train net output #0: loss = 0.0502178 (* 1 = 0.0502178 loss)
I0316 12:23:40.495839 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000327692 (* 1 = 0.000327692 loss)
I0316 12:23:40.495862 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0677796 (* 1 = -0.0677796 loss)
I0316 12:23:40.495867 55708 sgd_solver.cpp:112] Iteration 13600, lr = 0.001
I0316 12:23:48.426170 55708 solver.cpp:239] Iteration 13700 (12.6097 iter/s, 7.93038s/100 iters), loss = 0.0313032
I0316 12:23:48.426218 55708 solver.cpp:258]     Train net output #0: loss = 0.0960273 (* 1 = 0.0960273 loss)
I0316 12:23:48.426224 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000256432 (* 1 = 0.000256432 loss)
I0316 12:23:48.426230 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0649806 (* 1 = -0.0649806 loss)
I0316 12:23:48.426235 55708 sgd_solver.cpp:112] Iteration 13700, lr = 0.001
I0316 12:23:56.351207 55708 solver.cpp:239] Iteration 13800 (12.6182 iter/s, 7.92504s/100 iters), loss = 0.067991
I0316 12:23:56.351492 55708 solver.cpp:258]     Train net output #0: loss = 0.130682 (* 1 = 0.130682 loss)
I0316 12:23:56.351500 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000218526 (* 1 = 0.000218526 loss)
I0316 12:23:56.351506 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0629098 (* 1 = -0.0629098 loss)
I0316 12:23:56.351511 55708 sgd_solver.cpp:112] Iteration 13800, lr = 0.001
I0316 12:24:04.275413 55708 solver.cpp:239] Iteration 13900 (12.6199 iter/s, 7.92396s/100 iters), loss = 0.0871889
I0316 12:24:04.275460 55708 solver.cpp:258]     Train net output #0: loss = 0.151574 (* 1 = 0.151574 loss)
I0316 12:24:04.275467 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000278748 (* 1 = 0.000278748 loss)
I0316 12:24:04.275472 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0646637 (* 1 = -0.0646637 loss)
I0316 12:24:04.275478 55708 sgd_solver.cpp:112] Iteration 13900, lr = 0.001
I0316 12:24:12.125712 55708 solver.cpp:351] Iteration 14000, Testing net (#0)
I0316 12:24:17.054908 55708 solver.cpp:418]     Test net output #0: loss = 0.480802 (* 1 = 0.480802 loss)
I0316 12:24:17.054937 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000242214 (* 1 = 0.000242214 loss)
I0316 12:24:17.054945 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.063938 (* 1 = -0.063938 loss)
I0316 12:24:17.054949 55708 solver.cpp:418]     Test net output #3: top-1 = 0.847031
I0316 12:24:17.054970 55708 solver.cpp:418]     Test net output #4: top-5 = 0.992031
I0316 12:24:17.132743 55708 solver.cpp:239] Iteration 14000 (7.77764 iter/s, 12.8574s/100 iters), loss = 0.00773956
I0316 12:24:17.132772 55708 solver.cpp:258]     Train net output #0: loss = 0.0722314 (* 1 = 0.0722314 loss)
I0316 12:24:17.132779 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000300891 (* 1 = 0.000300891 loss)
I0316 12:24:17.132784 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0647928 (* 1 = -0.0647928 loss)
I0316 12:24:17.132791 55708 sgd_solver.cpp:112] Iteration 14000, lr = 0.001
I0316 12:24:21.734371 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:24:25.064059 55708 solver.cpp:239] Iteration 14100 (12.6082 iter/s, 7.93133s/100 iters), loss = -0.0159933
I0316 12:24:25.064110 55708 solver.cpp:258]     Train net output #0: loss = 0.0483266 (* 1 = 0.0483266 loss)
I0316 12:24:25.064118 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000264234 (* 1 = 0.000264234 loss)
I0316 12:24:25.064126 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0645842 (* 1 = -0.0645842 loss)
I0316 12:24:25.064129 55708 sgd_solver.cpp:112] Iteration 14100, lr = 0.001
I0316 12:24:32.994685 55708 solver.cpp:239] Iteration 14200 (12.6093 iter/s, 7.93063s/100 iters), loss = 0.111606
I0316 12:24:32.995088 55708 solver.cpp:258]     Train net output #0: loss = 0.173748 (* 1 = 0.173748 loss)
I0316 12:24:32.995098 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000266268 (* 1 = 0.000266268 loss)
I0316 12:24:32.995105 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0624077 (* 1 = -0.0624077 loss)
I0316 12:24:32.995108 55708 sgd_solver.cpp:112] Iteration 14200, lr = 0.001
I0316 12:24:40.924553 55708 solver.cpp:239] Iteration 14300 (12.6111 iter/s, 7.92952s/100 iters), loss = 0.0514044
I0316 12:24:40.924594 55708 solver.cpp:258]     Train net output #0: loss = 0.118237 (* 1 = 0.118237 loss)
I0316 12:24:40.924602 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000236829 (* 1 = 0.000236829 loss)
I0316 12:24:40.924607 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.06707 (* 1 = -0.06707 loss)
I0316 12:24:40.924612 55708 sgd_solver.cpp:112] Iteration 14300, lr = 0.001
I0316 12:24:48.854358 55708 solver.cpp:239] Iteration 14400 (12.6107 iter/s, 7.9298s/100 iters), loss = 0.144556
I0316 12:24:48.854410 55708 solver.cpp:258]     Train net output #0: loss = 0.2055 (* 1 = 0.2055 loss)
I0316 12:24:48.854418 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000276039 (* 1 = 0.000276039 loss)
I0316 12:24:48.854424 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0612202 (* 1 = -0.0612202 loss)
I0316 12:24:48.854430 55708 sgd_solver.cpp:112] Iteration 14400, lr = 0.001
I0316 12:24:56.784639 55708 solver.cpp:239] Iteration 14500 (12.6099 iter/s, 7.93028s/100 iters), loss = 0.01069
I0316 12:24:56.784679 55708 solver.cpp:258]     Train net output #0: loss = 0.0763788 (* 1 = 0.0763788 loss)
I0316 12:24:56.784687 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000232313 (* 1 = 0.000232313 loss)
I0316 12:24:56.784693 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0659212 (* 1 = -0.0659212 loss)
I0316 12:24:56.784698 55708 sgd_solver.cpp:112] Iteration 14500, lr = 0.001
I0316 12:25:04.715394 55708 solver.cpp:239] Iteration 14600 (12.6091 iter/s, 7.93076s/100 iters), loss = 0.0749952
I0316 12:25:04.715816 55708 solver.cpp:258]     Train net output #0: loss = 0.141983 (* 1 = 0.141983 loss)
I0316 12:25:04.715826 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000310688 (* 1 = 0.000310688 loss)
I0316 12:25:04.715832 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0672985 (* 1 = -0.0672985 loss)
I0316 12:25:04.715837 55708 sgd_solver.cpp:112] Iteration 14600, lr = 0.001
I0316 12:25:12.645195 55708 solver.cpp:239] Iteration 14700 (12.6112 iter/s, 7.92943s/100 iters), loss = 0.0705373
I0316 12:25:12.645239 55708 solver.cpp:258]     Train net output #0: loss = 0.136345 (* 1 = 0.136345 loss)
I0316 12:25:12.645246 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00022926 (* 1 = 0.00022926 loss)
I0316 12:25:12.645252 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0660366 (* 1 = -0.0660366 loss)
I0316 12:25:12.645257 55708 sgd_solver.cpp:112] Iteration 14700, lr = 0.001
I0316 12:25:20.572901 55708 solver.cpp:239] Iteration 14800 (12.614 iter/s, 7.92771s/100 iters), loss = 0.00874608
I0316 12:25:20.572942 55708 solver.cpp:258]     Train net output #0: loss = 0.0771823 (* 1 = 0.0771823 loss)
I0316 12:25:20.572949 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000296989 (* 1 = 0.000296989 loss)
I0316 12:25:20.572954 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0687332 (* 1 = -0.0687332 loss)
I0316 12:25:20.572960 55708 sgd_solver.cpp:112] Iteration 14800, lr = 0.001
I0316 12:25:28.500344 55708 solver.cpp:239] Iteration 14900 (12.6144 iter/s, 7.92744s/100 iters), loss = 0.051097
I0316 12:25:28.500394 55708 solver.cpp:258]     Train net output #0: loss = 0.114039 (* 1 = 0.114039 loss)
I0316 12:25:28.500401 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000200055 (* 1 = 0.000200055 loss)
I0316 12:25:28.500407 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.063142 (* 1 = -0.063142 loss)
I0316 12:25:28.500412 55708 sgd_solver.cpp:112] Iteration 14900, lr = 0.001
I0316 12:25:36.353178 55708 solver.cpp:351] Iteration 15000, Testing net (#0)
I0316 12:25:36.576138 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:25:41.282507 55708 solver.cpp:418]     Test net output #0: loss = 0.474172 (* 1 = 0.474172 loss)
I0316 12:25:41.282531 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000235144 (* 1 = 0.000235144 loss)
I0316 12:25:41.282537 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0640784 (* 1 = -0.0640784 loss)
I0316 12:25:41.282541 55708 solver.cpp:418]     Test net output #3: top-1 = 0.849688
I0316 12:25:41.282546 55708 solver.cpp:418]     Test net output #4: top-5 = 0.992813
I0316 12:25:41.360291 55708 solver.cpp:239] Iteration 15000 (7.77606 iter/s, 12.86s/100 iters), loss = 0.158484
I0316 12:25:41.360316 55708 solver.cpp:258]     Train net output #0: loss = 0.228762 (* 1 = 0.228762 loss)
I0316 12:25:41.360322 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000252599 (* 1 = 0.000252599 loss)
I0316 12:25:41.360328 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0705311 (* 1 = -0.0705311 loss)
I0316 12:25:41.360352 55708 sgd_solver.cpp:112] Iteration 15000, lr = 0.001
I0316 12:25:49.289253 55708 solver.cpp:239] Iteration 15100 (12.612 iter/s, 7.92898s/100 iters), loss = 0.0480649
I0316 12:25:49.289300 55708 solver.cpp:258]     Train net output #0: loss = 0.10944 (* 1 = 0.10944 loss)
I0316 12:25:49.289307 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000267321 (* 1 = 0.000267321 loss)
I0316 12:25:49.289314 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0616422 (* 1 = -0.0616422 loss)
I0316 12:25:49.289319 55708 sgd_solver.cpp:112] Iteration 15100, lr = 0.001
I0316 12:25:57.220517 55708 solver.cpp:239] Iteration 15200 (12.6083 iter/s, 7.93126s/100 iters), loss = 0.0473094
I0316 12:25:57.220561 55708 solver.cpp:258]     Train net output #0: loss = 0.114497 (* 1 = 0.114497 loss)
I0316 12:25:57.220568 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000299429 (* 1 = 0.000299429 loss)
I0316 12:25:57.220573 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0674871 (* 1 = -0.0674871 loss)
I0316 12:25:57.220578 55708 sgd_solver.cpp:112] Iteration 15200, lr = 0.001
I0316 12:26:05.149272 55708 solver.cpp:239] Iteration 15300 (12.6123 iter/s, 7.92875s/100 iters), loss = 0.0439934
I0316 12:26:05.149320 55708 solver.cpp:258]     Train net output #0: loss = 0.108504 (* 1 = 0.108504 loss)
I0316 12:26:05.149327 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000289198 (* 1 = 0.000289198 loss)
I0316 12:26:05.149333 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0647996 (* 1 = -0.0647996 loss)
I0316 12:26:05.149338 55708 sgd_solver.cpp:112] Iteration 15300, lr = 0.001
I0316 12:26:13.079478 55708 solver.cpp:239] Iteration 15400 (12.61 iter/s, 7.9302s/100 iters), loss = 0.100724
I0316 12:26:13.079855 55708 solver.cpp:258]     Train net output #0: loss = 0.164734 (* 1 = 0.164734 loss)
I0316 12:26:13.079864 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000258876 (* 1 = 0.000258876 loss)
I0316 12:26:13.079871 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0642689 (* 1 = -0.0642689 loss)
I0316 12:26:13.079876 55708 sgd_solver.cpp:112] Iteration 15400, lr = 0.001
I0316 12:26:21.009912 55708 solver.cpp:239] Iteration 15500 (12.6102 iter/s, 7.9301s/100 iters), loss = 0.0503401
I0316 12:26:21.009953 55708 solver.cpp:258]     Train net output #0: loss = 0.116401 (* 1 = 0.116401 loss)
I0316 12:26:21.009963 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00025997 (* 1 = 0.00025997 loss)
I0316 12:26:21.009968 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0663211 (* 1 = -0.0663211 loss)
I0316 12:26:21.009972 55708 sgd_solver.cpp:112] Iteration 15500, lr = 0.001
I0316 12:26:28.939774 55708 solver.cpp:239] Iteration 15600 (12.6106 iter/s, 7.92986s/100 iters), loss = 0.0185162
I0316 12:26:28.939821 55708 solver.cpp:258]     Train net output #0: loss = 0.0852638 (* 1 = 0.0852638 loss)
I0316 12:26:28.939827 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000181799 (* 1 = 0.000181799 loss)
I0316 12:26:28.939832 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0669294 (* 1 = -0.0669294 loss)
I0316 12:26:28.939837 55708 sgd_solver.cpp:112] Iteration 15600, lr = 0.001
I0316 12:26:30.528821 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:26:36.868422 55708 solver.cpp:239] Iteration 15700 (12.6125 iter/s, 7.92864s/100 iters), loss = 0.0233862
I0316 12:26:36.868467 55708 solver.cpp:258]     Train net output #0: loss = 0.0920367 (* 1 = 0.0920367 loss)
I0316 12:26:36.868474 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000280435 (* 1 = 0.000280435 loss)
I0316 12:26:36.868480 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.068931 (* 1 = -0.068931 loss)
I0316 12:26:36.868485 55708 sgd_solver.cpp:112] Iteration 15700, lr = 0.001
I0316 12:26:44.798878 55708 solver.cpp:239] Iteration 15800 (12.6096 iter/s, 7.93044s/100 iters), loss = 0.109993
I0316 12:26:44.799260 55708 solver.cpp:258]     Train net output #0: loss = 0.175861 (* 1 = 0.175861 loss)
I0316 12:26:44.799270 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000223519 (* 1 = 0.000223519 loss)
I0316 12:26:44.799276 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0660909 (* 1 = -0.0660909 loss)
I0316 12:26:44.799281 55708 sgd_solver.cpp:112] Iteration 15800, lr = 0.001
I0316 12:26:52.729418 55708 solver.cpp:239] Iteration 15900 (12.61 iter/s, 7.9302s/100 iters), loss = -0.0118534
I0316 12:26:52.729473 55708 solver.cpp:258]     Train net output #0: loss = 0.0580299 (* 1 = 0.0580299 loss)
I0316 12:26:52.729482 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000325138 (* 1 = 0.000325138 loss)
I0316 12:26:52.729490 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0702085 (* 1 = -0.0702085 loss)
I0316 12:26:52.729497 55708 sgd_solver.cpp:112] Iteration 15900, lr = 0.001
I0316 12:27:00.580921 55708 solver.cpp:351] Iteration 16000, Testing net (#0)
I0316 12:27:03.564568 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:27:05.509354 55708 solver.cpp:418]     Test net output #0: loss = 0.488244 (* 1 = 0.488244 loss)
I0316 12:27:05.509380 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000251459 (* 1 = 0.000251459 loss)
I0316 12:27:05.509387 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0645316 (* 1 = -0.0645316 loss)
I0316 12:27:05.509392 55708 solver.cpp:418]     Test net output #3: top-1 = 0.852031
I0316 12:27:05.509395 55708 solver.cpp:418]     Test net output #4: top-5 = 0.992656
I0316 12:27:05.587153 55708 solver.cpp:239] Iteration 16000 (7.7774 iter/s, 12.8578s/100 iters), loss = 0.0101856
I0316 12:27:05.587181 55708 solver.cpp:258]     Train net output #0: loss = 0.0744424 (* 1 = 0.0744424 loss)
I0316 12:27:05.587188 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000252877 (* 1 = 0.000252877 loss)
I0316 12:27:05.587193 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0645097 (* 1 = -0.0645097 loss)
I0316 12:27:05.587214 55708 sgd_solver.cpp:112] Iteration 16000, lr = 0.001
I0316 12:27:13.515630 55708 solver.cpp:239] Iteration 16100 (12.6127 iter/s, 7.92849s/100 iters), loss = -0.0467039
I0316 12:27:13.515671 55708 solver.cpp:258]     Train net output #0: loss = 0.0233174 (* 1 = 0.0233174 loss)
I0316 12:27:13.515677 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000252823 (* 1 = 0.000252823 loss)
I0316 12:27:13.515682 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.070274 (* 1 = -0.070274 loss)
I0316 12:27:13.515704 55708 sgd_solver.cpp:112] Iteration 16100, lr = 0.001
I0316 12:27:21.446897 55708 solver.cpp:239] Iteration 16200 (12.6083 iter/s, 7.93127s/100 iters), loss = 0.0297204
I0316 12:27:21.447206 55708 solver.cpp:258]     Train net output #0: loss = 0.0935434 (* 1 = 0.0935434 loss)
I0316 12:27:21.447214 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000226638 (* 1 = 0.000226638 loss)
I0316 12:27:21.447221 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0640496 (* 1 = -0.0640496 loss)
I0316 12:27:21.447225 55708 sgd_solver.cpp:112] Iteration 16200, lr = 0.001
I0316 12:27:29.376456 55708 solver.cpp:239] Iteration 16300 (12.6115 iter/s, 7.92928s/100 iters), loss = 0.0354362
I0316 12:27:29.376503 55708 solver.cpp:258]     Train net output #0: loss = 0.101218 (* 1 = 0.101218 loss)
I0316 12:27:29.376510 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000273517 (* 1 = 0.000273517 loss)
I0316 12:27:29.376516 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0660555 (* 1 = -0.0660555 loss)
I0316 12:27:29.376520 55708 sgd_solver.cpp:112] Iteration 16300, lr = 0.001
I0316 12:27:37.306635 55708 solver.cpp:239] Iteration 16400 (12.6101 iter/s, 7.93017s/100 iters), loss = 0.0297035
I0316 12:27:37.306680 55708 solver.cpp:258]     Train net output #0: loss = 0.0991767 (* 1 = 0.0991767 loss)
I0316 12:27:37.306687 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00029668 (* 1 = 0.00029668 loss)
I0316 12:27:37.306694 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0697698 (* 1 = -0.0697698 loss)
I0316 12:27:37.306697 55708 sgd_solver.cpp:112] Iteration 16400, lr = 0.001
I0316 12:27:45.234907 55708 solver.cpp:239] Iteration 16500 (12.6131 iter/s, 7.92826s/100 iters), loss = 0.0459003
I0316 12:27:45.234953 55708 solver.cpp:258]     Train net output #0: loss = 0.114458 (* 1 = 0.114458 loss)
I0316 12:27:45.234961 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000221906 (* 1 = 0.000221906 loss)
I0316 12:27:45.234966 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0687794 (* 1 = -0.0687794 loss)
I0316 12:27:45.234972 55708 sgd_solver.cpp:112] Iteration 16500, lr = 0.001
I0316 12:27:53.162453 55708 solver.cpp:239] Iteration 16600 (12.6142 iter/s, 7.92754s/100 iters), loss = -0.00941054
I0316 12:27:53.162839 55708 solver.cpp:258]     Train net output #0: loss = 0.0635294 (* 1 = 0.0635294 loss)
I0316 12:27:53.162847 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000265992 (* 1 = 0.000265992 loss)
I0316 12:27:53.162854 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0732059 (* 1 = -0.0732059 loss)
I0316 12:27:53.162859 55708 sgd_solver.cpp:112] Iteration 16600, lr = 0.001
I0316 12:28:01.092806 55708 solver.cpp:239] Iteration 16700 (12.6103 iter/s, 7.93001s/100 iters), loss = 0.0611213
I0316 12:28:01.092845 55708 solver.cpp:258]     Train net output #0: loss = 0.12805 (* 1 = 0.12805 loss)
I0316 12:28:01.092854 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000278879 (* 1 = 0.000278879 loss)
I0316 12:28:01.092859 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0672074 (* 1 = -0.0672074 loss)
I0316 12:28:01.092864 55708 sgd_solver.cpp:112] Iteration 16700, lr = 0.001
I0316 12:28:09.021505 55708 solver.cpp:239] Iteration 16800 (12.6124 iter/s, 7.92869s/100 iters), loss = -0.0177156
I0316 12:28:09.021553 55708 solver.cpp:258]     Train net output #0: loss = 0.0487939 (* 1 = 0.0487939 loss)
I0316 12:28:09.021560 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000240349 (* 1 = 0.000240349 loss)
I0316 12:28:09.021565 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0667497 (* 1 = -0.0667497 loss)
I0316 12:28:09.021570 55708 sgd_solver.cpp:112] Iteration 16800, lr = 0.001
I0316 12:28:16.952164 55708 solver.cpp:239] Iteration 16900 (12.6093 iter/s, 7.93065s/100 iters), loss = 0.0244934
I0316 12:28:16.952208 55708 solver.cpp:258]     Train net output #0: loss = 0.0948717 (* 1 = 0.0948717 loss)
I0316 12:28:16.952215 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000364021 (* 1 = 0.000364021 loss)
I0316 12:28:16.952221 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0707423 (* 1 = -0.0707423 loss)
I0316 12:28:16.952226 55708 sgd_solver.cpp:112] Iteration 16900, lr = 0.001
I0316 12:28:24.805939 55708 solver.cpp:351] Iteration 17000, Testing net (#0)
I0316 12:28:29.735273 55708 solver.cpp:418]     Test net output #0: loss = 0.49144 (* 1 = 0.49144 loss)
I0316 12:28:29.735299 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000248927 (* 1 = 0.000248927 loss)
I0316 12:28:29.735306 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0658882 (* 1 = -0.0658882 loss)
I0316 12:28:29.735311 55708 solver.cpp:418]     Test net output #3: top-1 = 0.85125
I0316 12:28:29.735314 55708 solver.cpp:418]     Test net output #4: top-5 = 0.989844
I0316 12:28:29.813004 55708 solver.cpp:239] Iteration 17000 (7.77552 iter/s, 12.8609s/100 iters), loss = 0.00647971
I0316 12:28:29.813035 55708 solver.cpp:258]     Train net output #0: loss = 0.0729506 (* 1 = 0.0729506 loss)
I0316 12:28:29.813040 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000250441 (* 1 = 0.000250441 loss)
I0316 12:28:29.813045 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0667213 (* 1 = -0.0667213 loss)
I0316 12:28:29.813051 55708 sgd_solver.cpp:112] Iteration 17000, lr = 0.001
I0316 12:28:37.744693 55708 solver.cpp:239] Iteration 17100 (12.6076 iter/s, 7.9317s/100 iters), loss = 0.0469982
I0316 12:28:37.744735 55708 solver.cpp:258]     Train net output #0: loss = 0.111001 (* 1 = 0.111001 loss)
I0316 12:28:37.744741 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000219415 (* 1 = 0.000219415 loss)
I0316 12:28:37.744747 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0642222 (* 1 = -0.0642222 loss)
I0316 12:28:37.744753 55708 sgd_solver.cpp:112] Iteration 17100, lr = 0.001
I0316 12:28:44.329952 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:28:45.675994 55708 solver.cpp:239] Iteration 17200 (12.6083 iter/s, 7.9313s/100 iters), loss = 0.100819
I0316 12:28:45.676039 55708 solver.cpp:258]     Train net output #0: loss = 0.170956 (* 1 = 0.170956 loss)
I0316 12:28:45.676046 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000396666 (* 1 = 0.000396666 loss)
I0316 12:28:45.676069 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0705335 (* 1 = -0.0705335 loss)
I0316 12:28:45.676074 55708 sgd_solver.cpp:112] Iteration 17200, lr = 0.001
I0316 12:28:53.606369 55708 solver.cpp:239] Iteration 17300 (12.6097 iter/s, 7.93037s/100 iters), loss = 0.0260371
I0316 12:28:53.606410 55708 solver.cpp:258]     Train net output #0: loss = 0.0959178 (* 1 = 0.0959178 loss)
I0316 12:28:53.606416 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000258183 (* 1 = 0.000258183 loss)
I0316 12:28:53.606422 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0701388 (* 1 = -0.0701388 loss)
I0316 12:28:53.606426 55708 sgd_solver.cpp:112] Iteration 17300, lr = 0.001
I0316 12:29:01.531519 55708 solver.cpp:239] Iteration 17400 (12.6181 iter/s, 7.92515s/100 iters), loss = -0.0165549
I0316 12:29:01.531911 55708 solver.cpp:258]     Train net output #0: loss = 0.0518057 (* 1 = 0.0518057 loss)
I0316 12:29:01.531920 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000270468 (* 1 = 0.000270468 loss)
I0316 12:29:01.531926 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.068631 (* 1 = -0.068631 loss)
I0316 12:29:01.531932 55708 sgd_solver.cpp:112] Iteration 17400, lr = 0.001
I0316 12:29:09.460839 55708 solver.cpp:239] Iteration 17500 (12.612 iter/s, 7.92897s/100 iters), loss = 0.00434779
I0316 12:29:09.460889 55708 solver.cpp:258]     Train net output #0: loss = 0.0760955 (* 1 = 0.0760955 loss)
I0316 12:29:09.460896 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000358352 (* 1 = 0.000358352 loss)
I0316 12:29:09.460903 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.072106 (* 1 = -0.072106 loss)
I0316 12:29:09.460907 55708 sgd_solver.cpp:112] Iteration 17500, lr = 0.001
I0316 12:29:17.390319 55708 solver.cpp:239] Iteration 17600 (12.6112 iter/s, 7.92948s/100 iters), loss = -0.0486067
I0316 12:29:17.390362 55708 solver.cpp:258]     Train net output #0: loss = 0.0207314 (* 1 = 0.0207314 loss)
I0316 12:29:17.390370 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000305028 (* 1 = 0.000305028 loss)
I0316 12:29:17.390376 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.069643 (* 1 = -0.069643 loss)
I0316 12:29:17.390381 55708 sgd_solver.cpp:112] Iteration 17600, lr = 0.001
I0316 12:29:25.317821 55708 solver.cpp:239] Iteration 17700 (12.6143 iter/s, 7.92749s/100 iters), loss = 0.12221
I0316 12:29:25.317883 55708 solver.cpp:258]     Train net output #0: loss = 0.187472 (* 1 = 0.187472 loss)
I0316 12:29:25.317893 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000246587 (* 1 = 0.000246587 loss)
I0316 12:29:25.317901 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0655081 (* 1 = -0.0655081 loss)
I0316 12:29:25.317914 55708 sgd_solver.cpp:112] Iteration 17700, lr = 0.001
I0316 12:29:33.245991 55708 solver.cpp:239] Iteration 17800 (12.6133 iter/s, 7.92816s/100 iters), loss = 0.18375
I0316 12:29:33.246381 55708 solver.cpp:258]     Train net output #0: loss = 0.251461 (* 1 = 0.251461 loss)
I0316 12:29:33.246392 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000272833 (* 1 = 0.000272833 loss)
I0316 12:29:33.246397 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0679832 (* 1 = -0.0679832 loss)
I0316 12:29:33.246403 55708 sgd_solver.cpp:112] Iteration 17800, lr = 0.001
I0316 12:29:41.177757 55708 solver.cpp:239] Iteration 17900 (12.6081 iter/s, 7.93143s/100 iters), loss = -0.00328103
I0316 12:29:41.177798 55708 solver.cpp:258]     Train net output #0: loss = 0.0656998 (* 1 = 0.0656998 loss)
I0316 12:29:41.177805 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000329183 (* 1 = 0.000329183 loss)
I0316 12:29:41.177811 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0693098 (* 1 = -0.0693098 loss)
I0316 12:29:41.177816 55708 sgd_solver.cpp:112] Iteration 17900, lr = 0.001
I0316 12:29:49.032778 55708 solver.cpp:351] Iteration 18000, Testing net (#0)
I0316 12:29:49.871454 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:29:53.960953 55708 solver.cpp:418]     Test net output #0: loss = 0.470608 (* 1 = 0.470608 loss)
I0316 12:29:53.960980 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000247266 (* 1 = 0.000247266 loss)
I0316 12:29:53.960986 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0660398 (* 1 = -0.0660398 loss)
I0316 12:29:53.960990 55708 solver.cpp:418]     Test net output #3: top-1 = 0.855469
I0316 12:29:53.960995 55708 solver.cpp:418]     Test net output #4: top-5 = 0.992344
I0316 12:29:54.038740 55708 solver.cpp:239] Iteration 18000 (7.77543 iter/s, 12.861s/100 iters), loss = 0.0550373
I0316 12:29:54.038770 55708 solver.cpp:258]     Train net output #0: loss = 0.122987 (* 1 = 0.122987 loss)
I0316 12:29:54.038777 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000301868 (* 1 = 0.000301868 loss)
I0316 12:29:54.038800 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0682517 (* 1 = -0.0682517 loss)
I0316 12:29:54.038805 55708 sgd_solver.cpp:112] Iteration 18000, lr = 0.001
I0316 12:30:01.966280 55708 solver.cpp:239] Iteration 18100 (12.6142 iter/s, 7.92756s/100 iters), loss = -0.00156684
I0316 12:30:01.966323 55708 solver.cpp:258]     Train net output #0: loss = 0.0664121 (* 1 = 0.0664121 loss)
I0316 12:30:01.966331 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00025498 (* 1 = 0.00025498 loss)
I0316 12:30:01.966336 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0682337 (* 1 = -0.0682337 loss)
I0316 12:30:01.966341 55708 sgd_solver.cpp:112] Iteration 18100, lr = 0.001
I0316 12:30:09.897755 55708 solver.cpp:239] Iteration 18200 (12.608 iter/s, 7.93147s/100 iters), loss = 0.167163
I0316 12:30:09.898077 55708 solver.cpp:258]     Train net output #0: loss = 0.23251 (* 1 = 0.23251 loss)
I0316 12:30:09.898085 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000281852 (* 1 = 0.000281852 loss)
I0316 12:30:09.898092 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0656284 (* 1 = -0.0656284 loss)
I0316 12:30:09.898097 55708 sgd_solver.cpp:112] Iteration 18200, lr = 0.001
I0316 12:30:17.828344 55708 solver.cpp:239] Iteration 18300 (12.6098 iter/s, 7.93032s/100 iters), loss = -0.0337394
I0316 12:30:17.828392 55708 solver.cpp:258]     Train net output #0: loss = 0.0366942 (* 1 = 0.0366942 loss)
I0316 12:30:17.828414 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000287225 (* 1 = 0.000287225 loss)
I0316 12:30:17.828420 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0707206 (* 1 = -0.0707206 loss)
I0316 12:30:17.828426 55708 sgd_solver.cpp:112] Iteration 18300, lr = 0.001
I0316 12:30:25.758630 55708 solver.cpp:239] Iteration 18400 (12.6099 iter/s, 7.93028s/100 iters), loss = -0.0456024
I0316 12:30:25.758678 55708 solver.cpp:258]     Train net output #0: loss = 0.0251332 (* 1 = 0.0251332 loss)
I0316 12:30:25.758685 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000194214 (* 1 = 0.000194214 loss)
I0316 12:30:25.758708 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0709295 (* 1 = -0.0709295 loss)
I0316 12:30:25.758713 55708 sgd_solver.cpp:112] Iteration 18400, lr = 0.001
I0316 12:30:33.692230 55708 solver.cpp:239] Iteration 18500 (12.6046 iter/s, 7.9336s/100 iters), loss = -0.00831423
I0316 12:30:33.692271 55708 solver.cpp:258]     Train net output #0: loss = 0.0610192 (* 1 = 0.0610192 loss)
I0316 12:30:33.692279 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000220849 (* 1 = 0.000220849 loss)
I0316 12:30:33.692284 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.069554 (* 1 = -0.069554 loss)
I0316 12:30:33.692289 55708 sgd_solver.cpp:112] Iteration 18500, lr = 0.001
I0316 12:30:41.623797 55708 solver.cpp:239] Iteration 18600 (12.6078 iter/s, 7.93157s/100 iters), loss = 0.102734
I0316 12:30:41.624208 55708 solver.cpp:258]     Train net output #0: loss = 0.171133 (* 1 = 0.171133 loss)
I0316 12:30:41.624217 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000155641 (* 1 = 0.000155641 loss)
I0316 12:30:41.624223 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0685549 (* 1 = -0.0685549 loss)
I0316 12:30:41.624228 55708 sgd_solver.cpp:112] Iteration 18600, lr = 0.001
I0316 12:30:49.552944 55708 solver.cpp:239] Iteration 18700 (12.6123 iter/s, 7.92877s/100 iters), loss = 0.118378
I0316 12:30:49.552995 55708 solver.cpp:258]     Train net output #0: loss = 0.185901 (* 1 = 0.185901 loss)
I0316 12:30:49.553004 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000270303 (* 1 = 0.000270303 loss)
I0316 12:30:49.553009 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0677935 (* 1 = -0.0677935 loss)
I0316 12:30:49.553015 55708 sgd_solver.cpp:112] Iteration 18700, lr = 0.001
I0316 12:30:53.124771 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:30:57.483778 55708 solver.cpp:239] Iteration 18800 (12.609 iter/s, 7.93083s/100 iters), loss = -0.0209085
I0316 12:30:57.483820 55708 solver.cpp:258]     Train net output #0: loss = 0.0473219 (* 1 = 0.0473219 loss)
I0316 12:30:57.483829 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000256322 (* 1 = 0.000256322 loss)
I0316 12:30:57.483834 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0684865 (* 1 = -0.0684865 loss)
I0316 12:30:57.483839 55708 sgd_solver.cpp:112] Iteration 18800, lr = 0.001
I0316 12:31:05.414389 55708 solver.cpp:239] Iteration 18900 (12.6094 iter/s, 7.93061s/100 iters), loss = 0.10695
I0316 12:31:05.414436 55708 solver.cpp:258]     Train net output #0: loss = 0.176786 (* 1 = 0.176786 loss)
I0316 12:31:05.414443 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000211513 (* 1 = 0.000211513 loss)
I0316 12:31:05.414449 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0700478 (* 1 = -0.0700478 loss)
I0316 12:31:05.414453 55708 sgd_solver.cpp:112] Iteration 18900, lr = 0.001
I0316 12:31:13.266379 55708 solver.cpp:351] Iteration 19000, Testing net (#0)
I0316 12:31:16.870204 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:31:18.199542 55708 solver.cpp:418]     Test net output #0: loss = 0.503193 (* 1 = 0.503193 loss)
I0316 12:31:18.199570 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000256191 (* 1 = 0.000256191 loss)
I0316 12:31:18.199577 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0670712 (* 1 = -0.0670712 loss)
I0316 12:31:18.199581 55708 solver.cpp:418]     Test net output #3: top-1 = 0.849844
I0316 12:31:18.199585 55708 solver.cpp:418]     Test net output #4: top-5 = 0.992656
I0316 12:31:18.277308 55708 solver.cpp:239] Iteration 19000 (7.77426 iter/s, 12.863s/100 iters), loss = 0.0502908
I0316 12:31:18.277338 55708 solver.cpp:258]     Train net output #0: loss = 0.118472 (* 1 = 0.118472 loss)
I0316 12:31:18.277344 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000214821 (* 1 = 0.000214821 loss)
I0316 12:31:18.277350 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.068396 (* 1 = -0.068396 loss)
I0316 12:31:18.277356 55708 sgd_solver.cpp:112] Iteration 19000, lr = 0.001
I0316 12:31:26.208201 55708 solver.cpp:239] Iteration 19100 (12.6089 iter/s, 7.9309s/100 iters), loss = 0.0311846
I0316 12:31:26.208247 55708 solver.cpp:258]     Train net output #0: loss = 0.0977596 (* 1 = 0.0977596 loss)
I0316 12:31:26.208254 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000242997 (* 1 = 0.000242997 loss)
I0316 12:31:26.208261 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0668178 (* 1 = -0.0668178 loss)
I0316 12:31:26.208266 55708 sgd_solver.cpp:112] Iteration 19100, lr = 0.001
I0316 12:31:34.137171 55708 solver.cpp:239] Iteration 19200 (12.612 iter/s, 7.92897s/100 iters), loss = -0.00178417
I0316 12:31:34.137212 55708 solver.cpp:258]     Train net output #0: loss = 0.0689189 (* 1 = 0.0689189 loss)
I0316 12:31:34.137219 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000266554 (* 1 = 0.000266554 loss)
I0316 12:31:34.137226 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0709694 (* 1 = -0.0709694 loss)
I0316 12:31:34.137231 55708 sgd_solver.cpp:112] Iteration 19200, lr = 0.001
I0316 12:31:42.066846 55708 solver.cpp:239] Iteration 19300 (12.6109 iter/s, 7.92968s/100 iters), loss = -0.0265769
I0316 12:31:42.066888 55708 solver.cpp:258]     Train net output #0: loss = 0.0404811 (* 1 = 0.0404811 loss)
I0316 12:31:42.066896 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000338203 (* 1 = 0.000338203 loss)
I0316 12:31:42.066901 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0673961 (* 1 = -0.0673961 loss)
I0316 12:31:42.066906 55708 sgd_solver.cpp:112] Iteration 19300, lr = 0.001
I0316 12:31:49.997824 55708 solver.cpp:239] Iteration 19400 (12.6088 iter/s, 7.93097s/100 iters), loss = -0.0430677
I0316 12:31:49.998227 55708 solver.cpp:258]     Train net output #0: loss = 0.0304149 (* 1 = 0.0304149 loss)
I0316 12:31:49.998235 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.0003293 (* 1 = 0.0003293 loss)
I0316 12:31:49.998241 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0738117 (* 1 = -0.0738117 loss)
I0316 12:31:49.998246 55708 sgd_solver.cpp:112] Iteration 19400, lr = 0.001
I0316 12:31:57.938064 55708 solver.cpp:239] Iteration 19500 (12.5946 iter/s, 7.93988s/100 iters), loss = -0.0250002
I0316 12:31:57.938107 55708 solver.cpp:258]     Train net output #0: loss = 0.0497663 (* 1 = 0.0497663 loss)
I0316 12:31:57.938114 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000273489 (* 1 = 0.000273489 loss)
I0316 12:31:57.938119 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0750399 (* 1 = -0.0750399 loss)
I0316 12:31:57.938125 55708 sgd_solver.cpp:112] Iteration 19500, lr = 0.001
I0316 12:32:05.869379 55708 solver.cpp:239] Iteration 19600 (12.6083 iter/s, 7.93131s/100 iters), loss = -0.00194475
I0316 12:32:05.869426 55708 solver.cpp:258]     Train net output #0: loss = 0.0648719 (* 1 = 0.0648719 loss)
I0316 12:32:05.869432 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00028029 (* 1 = 0.00028029 loss)
I0316 12:32:05.869438 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0670969 (* 1 = -0.0670969 loss)
I0316 12:32:05.869443 55708 sgd_solver.cpp:112] Iteration 19600, lr = 0.001
I0316 12:32:13.796778 55708 solver.cpp:239] Iteration 19700 (12.6145 iter/s, 7.92738s/100 iters), loss = 0.0255018
I0316 12:32:13.796850 55708 solver.cpp:258]     Train net output #0: loss = 0.0957883 (* 1 = 0.0957883 loss)
I0316 12:32:13.796859 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000285292 (* 1 = 0.000285292 loss)
I0316 12:32:13.796864 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0705718 (* 1 = -0.0705718 loss)
I0316 12:32:13.796869 55708 sgd_solver.cpp:112] Iteration 19700, lr = 0.001
I0316 12:32:21.728471 55708 solver.cpp:239] Iteration 19800 (12.6077 iter/s, 7.93167s/100 iters), loss = 0.00266456
I0316 12:32:21.728871 55708 solver.cpp:258]     Train net output #0: loss = 0.0693412 (* 1 = 0.0693412 loss)
I0316 12:32:21.728880 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000247178 (* 1 = 0.000247178 loss)
I0316 12:32:21.728886 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0669238 (* 1 = -0.0669238 loss)
I0316 12:32:21.728891 55708 sgd_solver.cpp:112] Iteration 19800, lr = 0.001
I0316 12:32:29.658907 55708 solver.cpp:239] Iteration 19900 (12.6102 iter/s, 7.93008s/100 iters), loss = 0.0739106
I0316 12:32:29.658955 55708 solver.cpp:258]     Train net output #0: loss = 0.144971 (* 1 = 0.144971 loss)
I0316 12:32:29.658962 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000261424 (* 1 = 0.000261424 loss)
I0316 12:32:29.658968 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0713216 (* 1 = -0.0713216 loss)
I0316 12:32:29.658974 55708 sgd_solver.cpp:112] Iteration 19900, lr = 0.001
I0316 12:32:37.510229 55708 solver.cpp:351] Iteration 20000, Testing net (#0)
I0316 12:32:42.443497 55708 solver.cpp:418]     Test net output #0: loss = 0.495065 (* 1 = 0.495065 loss)
I0316 12:32:42.443523 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000258871 (* 1 = 0.000258871 loss)
I0316 12:32:42.443531 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0688068 (* 1 = -0.0688068 loss)
I0316 12:32:42.443534 55708 solver.cpp:418]     Test net output #3: top-1 = 0.8525
I0316 12:32:42.443538 55708 solver.cpp:418]     Test net output #4: top-5 = 0.992344
I0316 12:32:42.521214 55708 solver.cpp:239] Iteration 20000 (7.77464 iter/s, 12.8623s/100 iters), loss = 0.191802
I0316 12:32:42.521245 55708 solver.cpp:258]     Train net output #0: loss = 0.258631 (* 1 = 0.258631 loss)
I0316 12:32:42.521251 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00023057 (* 1 = 0.00023057 loss)
I0316 12:32:42.521256 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0670589 (* 1 = -0.0670589 loss)
I0316 12:32:42.521263 55708 sgd_solver.cpp:112] Iteration 20000, lr = 0.001
I0316 12:32:50.452311 55708 solver.cpp:239] Iteration 20100 (12.6086 iter/s, 7.9311s/100 iters), loss = -0.00520413
I0316 12:32:50.452358 55708 solver.cpp:258]     Train net output #0: loss = 0.0651268 (* 1 = 0.0651268 loss)
I0316 12:32:50.452368 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000322844 (* 1 = 0.000322844 loss)
I0316 12:32:50.452389 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0706538 (* 1 = -0.0706538 loss)
I0316 12:32:50.452395 55708 sgd_solver.cpp:112] Iteration 20100, lr = 0.001
I0316 12:32:58.381942 55708 solver.cpp:239] Iteration 20200 (12.6109 iter/s, 7.92962s/100 iters), loss = 0.199255
I0316 12:32:58.382278 55708 solver.cpp:258]     Train net output #0: loss = 0.268311 (* 1 = 0.268311 loss)
I0316 12:32:58.382287 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000249126 (* 1 = 0.000249126 loss)
I0316 12:32:58.382293 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0693046 (* 1 = -0.0693046 loss)
I0316 12:32:58.382298 55708 sgd_solver.cpp:112] Iteration 20200, lr = 0.001
I0316 12:33:06.314253 55708 solver.cpp:239] Iteration 20300 (12.6071 iter/s, 7.93201s/100 iters), loss = 0.00141993
I0316 12:33:06.314303 55708 solver.cpp:258]     Train net output #0: loss = 0.0706677 (* 1 = 0.0706677 loss)
I0316 12:33:06.314311 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000290833 (* 1 = 0.000290833 loss)
I0316 12:33:06.314332 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0695386 (* 1 = -0.0695386 loss)
I0316 12:33:06.314338 55708 sgd_solver.cpp:112] Iteration 20300, lr = 0.001
I0316 12:33:06.951710 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:33:14.244637 55708 solver.cpp:239] Iteration 20400 (12.6097 iter/s, 7.93037s/100 iters), loss = -0.00725865
I0316 12:33:14.244679 55708 solver.cpp:258]     Train net output #0: loss = 0.0661902 (* 1 = 0.0661902 loss)
I0316 12:33:14.244686 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000264942 (* 1 = 0.000264942 loss)
I0316 12:33:14.244693 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0737139 (* 1 = -0.0737139 loss)
I0316 12:33:14.244696 55708 sgd_solver.cpp:112] Iteration 20400, lr = 0.001
I0316 12:33:22.171773 55708 solver.cpp:239] Iteration 20500 (12.6149 iter/s, 7.92713s/100 iters), loss = -0.0501493
I0316 12:33:22.171815 55708 solver.cpp:258]     Train net output #0: loss = 0.0239685 (* 1 = 0.0239685 loss)
I0316 12:33:22.171823 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000269653 (* 1 = 0.000269653 loss)
I0316 12:33:22.171828 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0743875 (* 1 = -0.0743875 loss)
I0316 12:33:22.171833 55708 sgd_solver.cpp:112] Iteration 20500, lr = 0.001
I0316 12:33:30.101631 55708 solver.cpp:239] Iteration 20600 (12.6106 iter/s, 7.92985s/100 iters), loss = 0.274933
I0316 12:33:30.102020 55708 solver.cpp:258]     Train net output #0: loss = 0.340525 (* 1 = 0.340525 loss)
I0316 12:33:30.102028 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000234231 (* 1 = 0.000234231 loss)
I0316 12:33:30.102035 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0658259 (* 1 = -0.0658259 loss)
I0316 12:33:30.102041 55708 sgd_solver.cpp:112] Iteration 20600, lr = 0.001
I0316 12:33:38.035492 55708 solver.cpp:239] Iteration 20700 (12.6048 iter/s, 7.93351s/100 iters), loss = 0.12258
I0316 12:33:38.035534 55708 solver.cpp:258]     Train net output #0: loss = 0.194567 (* 1 = 0.194567 loss)
I0316 12:33:38.035553 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000236899 (* 1 = 0.000236899 loss)
I0316 12:33:38.035559 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0722245 (* 1 = -0.0722245 loss)
I0316 12:33:38.035564 55708 sgd_solver.cpp:112] Iteration 20700, lr = 0.001
I0316 12:33:45.967308 55708 solver.cpp:239] Iteration 20800 (12.6075 iter/s, 7.93181s/100 iters), loss = -0.0302387
I0316 12:33:45.967357 55708 solver.cpp:258]     Train net output #0: loss = 0.0402802 (* 1 = 0.0402802 loss)
I0316 12:33:45.967363 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00029751 (* 1 = 0.00029751 loss)
I0316 12:33:45.967386 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0708164 (* 1 = -0.0708164 loss)
I0316 12:33:45.967391 55708 sgd_solver.cpp:112] Iteration 20800, lr = 0.001
I0316 12:33:53.898666 55708 solver.cpp:239] Iteration 20900 (12.6082 iter/s, 7.93135s/100 iters), loss = -0.00711438
I0316 12:33:53.898708 55708 solver.cpp:258]     Train net output #0: loss = 0.0637527 (* 1 = 0.0637527 loss)
I0316 12:33:53.898715 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000246937 (* 1 = 0.000246937 loss)
I0316 12:33:53.898721 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.071114 (* 1 = -0.071114 loss)
I0316 12:33:53.898727 55708 sgd_solver.cpp:112] Iteration 20900, lr = 0.001
I0316 12:34:01.750520 55708 solver.cpp:351] Iteration 21000, Testing net (#0)
I0316 12:34:03.206061 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:34:06.679090 55708 solver.cpp:418]     Test net output #0: loss = 0.475689 (* 1 = 0.475689 loss)
I0316 12:34:06.679117 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000265903 (* 1 = 0.000265903 loss)
I0316 12:34:06.679122 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0690917 (* 1 = -0.0690917 loss)
I0316 12:34:06.679126 55708 solver.cpp:418]     Test net output #3: top-1 = 0.854844
I0316 12:34:06.679131 55708 solver.cpp:418]     Test net output #4: top-5 = 0.993125
I0316 12:34:06.756868 55708 solver.cpp:239] Iteration 21000 (7.77712 iter/s, 12.8582s/100 iters), loss = 0.00770058
I0316 12:34:06.756897 55708 solver.cpp:258]     Train net output #0: loss = 0.0762077 (* 1 = 0.0762077 loss)
I0316 12:34:06.756904 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000289219 (* 1 = 0.000289219 loss)
I0316 12:34:06.756909 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0687963 (* 1 = -0.0687963 loss)
I0316 12:34:06.756918 55708 sgd_solver.cpp:112] Iteration 21000, lr = 0.001
I0316 12:34:14.687423 55708 solver.cpp:239] Iteration 21100 (12.6094 iter/s, 7.93056s/100 iters), loss = 0.0668071
I0316 12:34:14.687465 55708 solver.cpp:258]     Train net output #0: loss = 0.131852 (* 1 = 0.131852 loss)
I0316 12:34:14.687472 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000257805 (* 1 = 0.000257805 loss)
I0316 12:34:14.687494 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0653026 (* 1 = -0.0653026 loss)
I0316 12:34:14.687500 55708 sgd_solver.cpp:112] Iteration 21100, lr = 0.001
I0316 12:34:22.620309 55708 solver.cpp:239] Iteration 21200 (12.6058 iter/s, 7.93288s/100 iters), loss = -0.0465305
I0316 12:34:22.620352 55708 solver.cpp:258]     Train net output #0: loss = 0.0265024 (* 1 = 0.0265024 loss)
I0316 12:34:22.620359 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000333949 (* 1 = 0.000333949 loss)
I0316 12:34:22.620368 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0733668 (* 1 = -0.0733668 loss)
I0316 12:34:22.620373 55708 sgd_solver.cpp:112] Iteration 21200, lr = 0.001
I0316 12:34:30.551301 55708 solver.cpp:239] Iteration 21300 (12.6088 iter/s, 7.93098s/100 iters), loss = 0.0315533
I0316 12:34:30.551349 55708 solver.cpp:258]     Train net output #0: loss = 0.0990485 (* 1 = 0.0990485 loss)
I0316 12:34:30.551355 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000223716 (* 1 = 0.000223716 loss)
I0316 12:34:30.551362 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0677188 (* 1 = -0.0677188 loss)
I0316 12:34:30.551365 55708 sgd_solver.cpp:112] Iteration 21300, lr = 0.001
I0316 12:34:38.481400 55708 solver.cpp:239] Iteration 21400 (12.6102 iter/s, 7.93009s/100 iters), loss = 0.0326231
I0316 12:34:38.481753 55708 solver.cpp:258]     Train net output #0: loss = 0.0997535 (* 1 = 0.0997535 loss)
I0316 12:34:38.481762 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000251059 (* 1 = 0.000251059 loss)
I0316 12:34:38.481768 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0673814 (* 1 = -0.0673814 loss)
I0316 12:34:38.481773 55708 sgd_solver.cpp:112] Iteration 21400, lr = 0.001
I0316 12:34:46.411342 55708 solver.cpp:239] Iteration 21500 (12.6109 iter/s, 7.92962s/100 iters), loss = -0.0375617
I0316 12:34:46.411389 55708 solver.cpp:258]     Train net output #0: loss = 0.0327256 (* 1 = 0.0327256 loss)
I0316 12:34:46.411396 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000265657 (* 1 = 0.000265657 loss)
I0316 12:34:46.411402 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0705529 (* 1 = -0.0705529 loss)
I0316 12:34:46.411407 55708 sgd_solver.cpp:112] Iteration 21500, lr = 0.001
I0316 12:34:54.342618 55708 solver.cpp:239] Iteration 21600 (12.6083 iter/s, 7.93127s/100 iters), loss = -0.00993674
I0316 12:34:54.342661 55708 solver.cpp:258]     Train net output #0: loss = 0.0602048 (* 1 = 0.0602048 loss)
I0316 12:34:54.342669 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00026836 (* 1 = 0.00026836 loss)
I0316 12:34:54.342690 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0704099 (* 1 = -0.0704099 loss)
I0316 12:34:54.342695 55708 sgd_solver.cpp:112] Iteration 21600, lr = 0.001
I0316 12:35:02.273795 55708 solver.cpp:239] Iteration 21700 (12.6085 iter/s, 7.93118s/100 iters), loss = -0.0289465
I0316 12:35:02.273840 55708 solver.cpp:258]     Train net output #0: loss = 0.0380729 (* 1 = 0.0380729 loss)
I0316 12:35:02.273847 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000270696 (* 1 = 0.000270696 loss)
I0316 12:35:02.273869 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0672901 (* 1 = -0.0672901 loss)
I0316 12:35:02.273874 55708 sgd_solver.cpp:112] Iteration 21700, lr = 0.001
I0316 12:35:10.205086 55708 solver.cpp:239] Iteration 21800 (12.6083 iter/s, 7.93128s/100 iters), loss = 0.00640572
I0316 12:35:10.205531 55708 solver.cpp:258]     Train net output #0: loss = 0.0772549 (* 1 = 0.0772549 loss)
I0316 12:35:10.205543 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000304877 (* 1 = 0.000304877 loss)
I0316 12:35:10.205556 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.071154 (* 1 = -0.071154 loss)
I0316 12:35:10.205566 55708 sgd_solver.cpp:112] Iteration 21800, lr = 0.001
I0316 12:35:15.757596 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:35:18.133771 55708 solver.cpp:239] Iteration 21900 (12.6131 iter/s, 7.92829s/100 iters), loss = -0.0475559
I0316 12:35:18.133814 55708 solver.cpp:258]     Train net output #0: loss = 0.0278102 (* 1 = 0.0278102 loss)
I0316 12:35:18.133824 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000308721 (* 1 = 0.000308721 loss)
I0316 12:35:18.133832 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0756747 (* 1 = -0.0756747 loss)
I0316 12:35:18.133838 55708 sgd_solver.cpp:112] Iteration 21900, lr = 0.001
I0316 12:35:25.985550 55708 solver.cpp:351] Iteration 22000, Testing net (#0)
I0316 12:35:30.199888 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:35:30.912716 55708 solver.cpp:418]     Test net output #0: loss = 0.525935 (* 1 = 0.525935 loss)
I0316 12:35:30.912739 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000252022 (* 1 = 0.000252022 loss)
I0316 12:35:30.912748 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0683573 (* 1 = -0.0683573 loss)
I0316 12:35:30.912755 55708 solver.cpp:418]     Test net output #3: top-1 = 0.845469
I0316 12:35:30.912760 55708 solver.cpp:418]     Test net output #4: top-5 = 0.991406
I0316 12:35:30.990437 55708 solver.cpp:239] Iteration 22000 (7.77804 iter/s, 12.8567s/100 iters), loss = -0.0531341
I0316 12:35:30.990463 55708 solver.cpp:258]     Train net output #0: loss = 0.0201633 (* 1 = 0.0201633 loss)
I0316 12:35:30.990473 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000266736 (* 1 = 0.000266736 loss)
I0316 12:35:30.990481 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0735641 (* 1 = -0.0735641 loss)
I0316 12:35:30.990489 55708 sgd_solver.cpp:112] Iteration 22000, lr = 0.001
I0316 12:35:38.922394 55708 solver.cpp:239] Iteration 22100 (12.6072 iter/s, 7.93197s/100 iters), loss = 0.00963842
I0316 12:35:38.922438 55708 solver.cpp:258]     Train net output #0: loss = 0.0802303 (* 1 = 0.0802303 loss)
I0316 12:35:38.922446 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000249155 (* 1 = 0.000249155 loss)
I0316 12:35:38.922466 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.070841 (* 1 = -0.070841 loss)
I0316 12:35:38.922472 55708 sgd_solver.cpp:112] Iteration 22100, lr = 0.001
I0316 12:35:46.848345 55708 solver.cpp:239] Iteration 22200 (12.6168 iter/s, 7.92594s/100 iters), loss = -0.0562981
I0316 12:35:46.848701 55708 solver.cpp:258]     Train net output #0: loss = 0.0209628 (* 1 = 0.0209628 loss)
I0316 12:35:46.848709 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000272185 (* 1 = 0.000272185 loss)
I0316 12:35:46.848716 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0775332 (* 1 = -0.0775332 loss)
I0316 12:35:46.848722 55708 sgd_solver.cpp:112] Iteration 22200, lr = 0.001
I0316 12:35:54.777096 55708 solver.cpp:239] Iteration 22300 (12.6128 iter/s, 7.92844s/100 iters), loss = 0.234574
I0316 12:35:54.777139 55708 solver.cpp:258]     Train net output #0: loss = 0.307166 (* 1 = 0.307166 loss)
I0316 12:35:54.777148 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000249103 (* 1 = 0.000249103 loss)
I0316 12:35:54.777154 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0728405 (* 1 = -0.0728405 loss)
I0316 12:35:54.777161 55708 sgd_solver.cpp:112] Iteration 22300, lr = 0.001
I0316 12:36:02.706972 55708 solver.cpp:239] Iteration 22400 (12.6105 iter/s, 7.92988s/100 iters), loss = -0.0084725
I0316 12:36:02.707012 55708 solver.cpp:258]     Train net output #0: loss = 0.0628035 (* 1 = 0.0628035 loss)
I0316 12:36:02.707020 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000306692 (* 1 = 0.000306692 loss)
I0316 12:36:02.707026 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0715827 (* 1 = -0.0715827 loss)
I0316 12:36:02.707046 55708 sgd_solver.cpp:112] Iteration 22400, lr = 0.001
I0316 12:36:10.636816 55708 solver.cpp:239] Iteration 22500 (12.6106 iter/s, 7.92984s/100 iters), loss = -0.0225488
I0316 12:36:10.636865 55708 solver.cpp:258]     Train net output #0: loss = 0.050689 (* 1 = 0.050689 loss)
I0316 12:36:10.636873 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000349705 (* 1 = 0.000349705 loss)
I0316 12:36:10.636878 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0735875 (* 1 = -0.0735875 loss)
I0316 12:36:10.636883 55708 sgd_solver.cpp:112] Iteration 22500, lr = 0.001
I0316 12:36:18.567235 55708 solver.cpp:239] Iteration 22600 (12.6097 iter/s, 7.93041s/100 iters), loss = -0.011434
I0316 12:36:18.567674 55708 solver.cpp:258]     Train net output #0: loss = 0.0626699 (* 1 = 0.0626699 loss)
I0316 12:36:18.567683 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000196524 (* 1 = 0.000196524 loss)
I0316 12:36:18.567689 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0743004 (* 1 = -0.0743004 loss)
I0316 12:36:18.567698 55708 sgd_solver.cpp:112] Iteration 22600, lr = 0.001
I0316 12:36:26.501212 55708 solver.cpp:239] Iteration 22700 (12.6047 iter/s, 7.93358s/100 iters), loss = -0.0193513
I0316 12:36:26.501267 55708 solver.cpp:258]     Train net output #0: loss = 0.0522005 (* 1 = 0.0522005 loss)
I0316 12:36:26.501274 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000232997 (* 1 = 0.000232997 loss)
I0316 12:36:26.501282 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0717848 (* 1 = -0.0717848 loss)
I0316 12:36:26.501286 55708 sgd_solver.cpp:112] Iteration 22700, lr = 0.001
I0316 12:36:34.431401 55708 solver.cpp:239] Iteration 22800 (12.6101 iter/s, 7.93018s/100 iters), loss = -0.0127432
I0316 12:36:34.431439 55708 solver.cpp:258]     Train net output #0: loss = 0.0589972 (* 1 = 0.0589972 loss)
I0316 12:36:34.431447 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000303005 (* 1 = 0.000303005 loss)
I0316 12:36:34.431452 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0720435 (* 1 = -0.0720435 loss)
I0316 12:36:34.431473 55708 sgd_solver.cpp:112] Iteration 22800, lr = 0.001
I0316 12:36:42.361694 55708 solver.cpp:239] Iteration 22900 (12.6099 iter/s, 7.9303s/100 iters), loss = 0.10603
I0316 12:36:42.361737 55708 solver.cpp:258]     Train net output #0: loss = 0.173424 (* 1 = 0.173424 loss)
I0316 12:36:42.361743 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000283615 (* 1 = 0.000283615 loss)
I0316 12:36:42.361765 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0676785 (* 1 = -0.0676785 loss)
I0316 12:36:42.361770 55708 sgd_solver.cpp:112] Iteration 22900, lr = 0.001
I0316 12:36:50.214927 55708 solver.cpp:351] Iteration 23000, Testing net (#0)
I0316 12:36:55.145043 55708 solver.cpp:418]     Test net output #0: loss = 0.485636 (* 1 = 0.485636 loss)
I0316 12:36:55.145069 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000263367 (* 1 = 0.000263367 loss)
I0316 12:36:55.145076 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.070177 (* 1 = -0.070177 loss)
I0316 12:36:55.145081 55708 solver.cpp:418]     Test net output #3: top-1 = 0.857344
I0316 12:36:55.145085 55708 solver.cpp:418]     Test net output #4: top-5 = 0.991562
I0316 12:36:55.222818 55708 solver.cpp:239] Iteration 23000 (7.77534 iter/s, 12.8612s/100 iters), loss = 0.0405688
I0316 12:36:55.222848 55708 solver.cpp:258]     Train net output #0: loss = 0.109431 (* 1 = 0.109431 loss)
I0316 12:36:55.222855 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000308491 (* 1 = 0.000308491 loss)
I0316 12:36:55.222860 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0691711 (* 1 = -0.0691711 loss)
I0316 12:36:55.222867 55708 sgd_solver.cpp:112] Iteration 23000, lr = 0.001
I0316 12:37:03.153769 55708 solver.cpp:239] Iteration 23100 (12.6088 iter/s, 7.93096s/100 iters), loss = 0.0611877
I0316 12:37:03.153812 55708 solver.cpp:258]     Train net output #0: loss = 0.131695 (* 1 = 0.131695 loss)
I0316 12:37:03.153820 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000306321 (* 1 = 0.000306321 loss)
I0316 12:37:03.153825 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0708135 (* 1 = -0.0708135 loss)
I0316 12:37:03.153846 55708 sgd_solver.cpp:112] Iteration 23100, lr = 0.001
I0316 12:37:11.084949 55708 solver.cpp:239] Iteration 23200 (12.6085 iter/s, 7.93118s/100 iters), loss = 0.0722838
I0316 12:37:11.084997 55708 solver.cpp:258]     Train net output #0: loss = 0.143739 (* 1 = 0.143739 loss)
I0316 12:37:11.085004 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000300238 (* 1 = 0.000300238 loss)
I0316 12:37:11.085009 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0717554 (* 1 = -0.0717554 loss)
I0316 12:37:11.085016 55708 sgd_solver.cpp:112] Iteration 23200, lr = 0.001
I0316 12:37:19.016337 55708 solver.cpp:239] Iteration 23300 (12.6081 iter/s, 7.93139s/100 iters), loss = 0.0356553
I0316 12:37:19.016381 55708 solver.cpp:258]     Train net output #0: loss = 0.103913 (* 1 = 0.103913 loss)
I0316 12:37:19.016404 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000249397 (* 1 = 0.000249397 loss)
I0316 12:37:19.016410 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0685072 (* 1 = -0.0685072 loss)
I0316 12:37:19.016415 55708 sgd_solver.cpp:112] Iteration 23300, lr = 0.001
I0316 12:37:26.946877 55708 solver.cpp:239] Iteration 23400 (12.6095 iter/s, 7.93053s/100 iters), loss = 0.0396297
I0316 12:37:26.947400 55708 solver.cpp:258]     Train net output #0: loss = 0.104686 (* 1 = 0.104686 loss)
I0316 12:37:26.947409 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000183969 (* 1 = 0.000183969 loss)
I0316 12:37:26.947415 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.06524 (* 1 = -0.06524 loss)
I0316 12:37:26.947422 55708 sgd_solver.cpp:112] Iteration 23400, lr = 0.001
I0316 12:37:29.567065 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:37:34.877442 55708 solver.cpp:239] Iteration 23500 (12.6102 iter/s, 7.93009s/100 iters), loss = 0.00306088
I0316 12:37:34.877485 55708 solver.cpp:258]     Train net output #0: loss = 0.0725564 (* 1 = 0.0725564 loss)
I0316 12:37:34.877491 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000213955 (* 1 = 0.000213955 loss)
I0316 12:37:34.877496 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0697095 (* 1 = -0.0697095 loss)
I0316 12:37:34.877502 55708 sgd_solver.cpp:112] Iteration 23500, lr = 0.001
I0316 12:37:42.809195 55708 solver.cpp:239] Iteration 23600 (12.6075 iter/s, 7.93176s/100 iters), loss = -0.00258015
I0316 12:37:42.809235 55708 solver.cpp:258]     Train net output #0: loss = 0.0677309 (* 1 = 0.0677309 loss)
I0316 12:37:42.809242 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000322665 (* 1 = 0.000322665 loss)
I0316 12:37:42.809249 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0706337 (* 1 = -0.0706337 loss)
I0316 12:37:42.809254 55708 sgd_solver.cpp:112] Iteration 23600, lr = 0.001
I0316 12:37:50.742333 55708 solver.cpp:239] Iteration 23700 (12.6054 iter/s, 7.93314s/100 iters), loss = -0.0458517
I0316 12:37:50.742383 55708 solver.cpp:258]     Train net output #0: loss = 0.0300152 (* 1 = 0.0300152 loss)
I0316 12:37:50.742391 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000270615 (* 1 = 0.000270615 loss)
I0316 12:37:50.742396 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0761375 (* 1 = -0.0761375 loss)
I0316 12:37:50.742401 55708 sgd_solver.cpp:112] Iteration 23700, lr = 0.001
I0316 12:37:58.673966 55708 solver.cpp:239] Iteration 23800 (12.6078 iter/s, 7.93163s/100 iters), loss = -0.0169194
I0316 12:37:58.674347 55708 solver.cpp:258]     Train net output #0: loss = 0.0547599 (* 1 = 0.0547599 loss)
I0316 12:37:58.674356 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000317407 (* 1 = 0.000317407 loss)
I0316 12:37:58.674362 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0719968 (* 1 = -0.0719968 loss)
I0316 12:37:58.674366 55708 sgd_solver.cpp:112] Iteration 23800, lr = 0.001
I0316 12:38:06.603824 55708 solver.cpp:239] Iteration 23900 (12.6111 iter/s, 7.92952s/100 iters), loss = 0.0758908
I0316 12:38:06.603871 55708 solver.cpp:258]     Train net output #0: loss = 0.147155 (* 1 = 0.147155 loss)
I0316 12:38:06.603878 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000249294 (* 1 = 0.000249294 loss)
I0316 12:38:06.603899 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0715133 (* 1 = -0.0715133 loss)
I0316 12:38:06.603905 55708 sgd_solver.cpp:112] Iteration 23900, lr = 0.001
I0316 12:38:14.455749 55708 solver.cpp:351] Iteration 24000, Testing net (#0)
I0316 12:38:16.532984 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:38:19.403002 55708 solver.cpp:418]     Test net output #0: loss = 0.506701 (* 1 = 0.506701 loss)
I0316 12:38:19.403030 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000242356 (* 1 = 0.000242356 loss)
I0316 12:38:19.403036 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0699373 (* 1 = -0.0699373 loss)
I0316 12:38:19.403041 55708 solver.cpp:418]     Test net output #3: top-1 = 0.849688
I0316 12:38:19.403045 55708 solver.cpp:418]     Test net output #4: top-5 = 0.99125
I0316 12:38:19.480890 55708 solver.cpp:239] Iteration 24000 (7.76572 iter/s, 12.8771s/100 iters), loss = -0.0328819
I0316 12:38:19.480921 55708 solver.cpp:258]     Train net output #0: loss = 0.0413337 (* 1 = 0.0413337 loss)
I0316 12:38:19.480927 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000234191 (* 1 = 0.000234191 loss)
I0316 12:38:19.480933 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0744498 (* 1 = -0.0744498 loss)
I0316 12:38:19.480942 55708 sgd_solver.cpp:112] Iteration 24000, lr = 0.001
I0316 12:38:27.432344 55708 solver.cpp:239] Iteration 24100 (12.5763 iter/s, 7.95146s/100 iters), loss = 0.0551642
I0316 12:38:27.432415 55708 solver.cpp:258]     Train net output #0: loss = 0.126761 (* 1 = 0.126761 loss)
I0316 12:38:27.432422 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000293337 (* 1 = 0.000293337 loss)
I0316 12:38:27.432430 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0718904 (* 1 = -0.0718904 loss)
I0316 12:38:27.432435 55708 sgd_solver.cpp:112] Iteration 24100, lr = 0.001
I0316 12:38:35.384021 55708 solver.cpp:239] Iteration 24200 (12.576 iter/s, 7.95165s/100 iters), loss = -0.0603043
I0316 12:38:35.384356 55708 solver.cpp:258]     Train net output #0: loss = 0.0143005 (* 1 = 0.0143005 loss)
I0316 12:38:35.384369 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000319614 (* 1 = 0.000319614 loss)
I0316 12:38:35.384377 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0749244 (* 1 = -0.0749244 loss)
I0316 12:38:35.384382 55708 sgd_solver.cpp:112] Iteration 24200, lr = 0.001
I0316 12:38:43.336517 55708 solver.cpp:239] Iteration 24300 (12.5751 iter/s, 7.95221s/100 iters), loss = 0.0347542
I0316 12:38:43.336566 55708 solver.cpp:258]     Train net output #0: loss = 0.10545 (* 1 = 0.10545 loss)
I0316 12:38:43.336575 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000229583 (* 1 = 0.000229583 loss)
I0316 12:38:43.336581 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0709257 (* 1 = -0.0709257 loss)
I0316 12:38:43.336586 55708 sgd_solver.cpp:112] Iteration 24300, lr = 0.001
I0316 12:38:51.295676 55708 solver.cpp:239] Iteration 24400 (12.5642 iter/s, 7.95914s/100 iters), loss = 0.0491637
I0316 12:38:51.295724 55708 solver.cpp:258]     Train net output #0: loss = 0.123477 (* 1 = 0.123477 loss)
I0316 12:38:51.295732 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000287191 (* 1 = 0.000287191 loss)
I0316 12:38:51.295755 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0746005 (* 1 = -0.0746005 loss)
I0316 12:38:51.295761 55708 sgd_solver.cpp:112] Iteration 24400, lr = 0.001
I0316 12:38:59.245550 55708 solver.cpp:239] Iteration 24500 (12.5788 iter/s, 7.94986s/100 iters), loss = -0.0543851
I0316 12:38:59.245644 55708 solver.cpp:258]     Train net output #0: loss = 0.0230207 (* 1 = 0.0230207 loss)
I0316 12:38:59.245671 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000274088 (* 1 = 0.000274088 loss)
I0316 12:38:59.245692 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.07768 (* 1 = -0.07768 loss)
I0316 12:38:59.245710 55708 sgd_solver.cpp:112] Iteration 24500, lr = 0.001
I0316 12:39:07.194564 55708 solver.cpp:239] Iteration 24600 (12.5803 iter/s, 7.94896s/100 iters), loss = 0.06462
I0316 12:39:07.194913 55708 solver.cpp:258]     Train net output #0: loss = 0.141233 (* 1 = 0.141233 loss)
I0316 12:39:07.194931 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00023334 (* 1 = 0.00023334 loss)
I0316 12:39:07.194944 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0768464 (* 1 = -0.0768464 loss)
I0316 12:39:07.194954 55708 sgd_solver.cpp:112] Iteration 24600, lr = 0.001
I0316 12:39:15.145696 55708 solver.cpp:239] Iteration 24700 (12.5773 iter/s, 7.95083s/100 iters), loss = -0.0367035
I0316 12:39:15.145746 55708 solver.cpp:258]     Train net output #0: loss = 0.0376558 (* 1 = 0.0376558 loss)
I0316 12:39:15.145757 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000310863 (* 1 = 0.000310863 loss)
I0316 12:39:15.145766 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0746703 (* 1 = -0.0746703 loss)
I0316 12:39:15.145790 55708 sgd_solver.cpp:112] Iteration 24700, lr = 0.001
I0316 12:39:23.078557 55708 solver.cpp:239] Iteration 24800 (12.6058 iter/s, 7.93286s/100 iters), loss = -0.0595488
I0316 12:39:23.078598 55708 solver.cpp:258]     Train net output #0: loss = 0.0135103 (* 1 = 0.0135103 loss)
I0316 12:39:23.078604 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000297885 (* 1 = 0.000297885 loss)
I0316 12:39:23.078625 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0733571 (* 1 = -0.0733571 loss)
I0316 12:39:23.078631 55708 sgd_solver.cpp:112] Iteration 24800, lr = 0.001
I0316 12:39:31.009632 55708 solver.cpp:239] Iteration 24900 (12.6086 iter/s, 7.93107s/100 iters), loss = -0.03817
I0316 12:39:31.009681 55708 solver.cpp:258]     Train net output #0: loss = 0.030471 (* 1 = 0.030471 loss)
I0316 12:39:31.009688 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000228608 (* 1 = 0.000228608 loss)
I0316 12:39:31.009694 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0688697 (* 1 = -0.0688697 loss)
I0316 12:39:31.009699 55708 sgd_solver.cpp:112] Iteration 24900, lr = 0.001
I0316 12:39:38.547397 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:39:38.863190 55708 solver.cpp:351] Iteration 25000, Testing net (#0)
I0316 12:39:43.695693 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:39:43.793090 55708 solver.cpp:418]     Test net output #0: loss = 0.507241 (* 1 = 0.507241 loss)
I0316 12:39:43.793109 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000241189 (* 1 = 0.000241189 loss)
I0316 12:39:43.793115 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0712095 (* 1 = -0.0712095 loss)
I0316 12:39:43.793120 55708 solver.cpp:418]     Test net output #3: top-1 = 0.852813
I0316 12:39:43.793124 55708 solver.cpp:418]     Test net output #4: top-5 = 0.990156
I0316 12:39:43.870874 55708 solver.cpp:239] Iteration 25000 (7.77528 iter/s, 12.8613s/100 iters), loss = 0.0590238
I0316 12:39:43.870901 55708 solver.cpp:258]     Train net output #0: loss = 0.131064 (* 1 = 0.131064 loss)
I0316 12:39:43.870908 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000236485 (* 1 = 0.000236485 loss)
I0316 12:39:43.870913 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0722766 (* 1 = -0.0722766 loss)
I0316 12:39:43.870919 55708 sgd_solver.cpp:112] Iteration 25000, lr = 0.0001
I0316 12:39:51.804085 55708 solver.cpp:239] Iteration 25100 (12.6052 iter/s, 7.93322s/100 iters), loss = 0.189255
I0316 12:39:51.804132 55708 solver.cpp:258]     Train net output #0: loss = 0.263174 (* 1 = 0.263174 loss)
I0316 12:39:51.804138 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000321594 (* 1 = 0.000321594 loss)
I0316 12:39:51.804160 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.074241 (* 1 = -0.074241 loss)
I0316 12:39:51.804165 55708 sgd_solver.cpp:112] Iteration 25100, lr = 0.0001
I0316 12:39:59.734110 55708 solver.cpp:239] Iteration 25200 (12.6103 iter/s, 7.93002s/100 iters), loss = 0.0595337
I0316 12:39:59.734150 55708 solver.cpp:258]     Train net output #0: loss = 0.134429 (* 1 = 0.134429 loss)
I0316 12:39:59.734158 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000214536 (* 1 = 0.000214536 loss)
I0316 12:39:59.734163 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0751101 (* 1 = -0.0751101 loss)
I0316 12:39:59.734184 55708 sgd_solver.cpp:112] Iteration 25200, lr = 0.0001
I0316 12:40:07.663784 55708 solver.cpp:239] Iteration 25300 (12.6109 iter/s, 7.92966s/100 iters), loss = 0.054169
I0316 12:40:07.663830 55708 solver.cpp:258]     Train net output #0: loss = 0.127259 (* 1 = 0.127259 loss)
I0316 12:40:07.663836 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000243694 (* 1 = 0.000243694 loss)
I0316 12:40:07.663859 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0733341 (* 1 = -0.0733341 loss)
I0316 12:40:07.663864 55708 sgd_solver.cpp:112] Iteration 25300, lr = 0.0001
I0316 12:40:15.592618 55708 solver.cpp:239] Iteration 25400 (12.6122 iter/s, 7.92883s/100 iters), loss = 0.0127231
I0316 12:40:15.592952 55708 solver.cpp:258]     Train net output #0: loss = 0.0828449 (* 1 = 0.0828449 loss)
I0316 12:40:15.592960 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000173051 (* 1 = 0.000173051 loss)
I0316 12:40:15.592967 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0702949 (* 1 = -0.0702949 loss)
I0316 12:40:15.592972 55708 sgd_solver.cpp:112] Iteration 25400, lr = 0.0001
I0316 12:40:23.522264 55708 solver.cpp:239] Iteration 25500 (12.6114 iter/s, 7.92935s/100 iters), loss = -0.00265683
I0316 12:40:23.522315 55708 solver.cpp:258]     Train net output #0: loss = 0.0733081 (* 1 = 0.0733081 loss)
I0316 12:40:23.522321 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000298282 (* 1 = 0.000298282 loss)
I0316 12:40:23.522343 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0762632 (* 1 = -0.0762632 loss)
I0316 12:40:23.522349 55708 sgd_solver.cpp:112] Iteration 25500, lr = 0.0001
I0316 12:40:31.461309 55708 solver.cpp:239] Iteration 25600 (12.596 iter/s, 7.93903s/100 iters), loss = -0.0309794
I0316 12:40:31.461359 55708 solver.cpp:258]     Train net output #0: loss = 0.0430112 (* 1 = 0.0430112 loss)
I0316 12:40:31.461366 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00022393 (* 1 = 0.00022393 loss)
I0316 12:40:31.461371 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0742145 (* 1 = -0.0742145 loss)
I0316 12:40:31.461378 55708 sgd_solver.cpp:112] Iteration 25600, lr = 0.0001
I0316 12:40:39.394634 55708 solver.cpp:239] Iteration 25700 (12.6051 iter/s, 7.93332s/100 iters), loss = -0.0428729
I0316 12:40:39.394676 55708 solver.cpp:258]     Train net output #0: loss = 0.0331298 (* 1 = 0.0331298 loss)
I0316 12:40:39.394683 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000255537 (* 1 = 0.000255537 loss)
I0316 12:40:39.394706 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0762583 (* 1 = -0.0762583 loss)
I0316 12:40:39.394711 55708 sgd_solver.cpp:112] Iteration 25700, lr = 0.0001
I0316 12:40:47.325394 55708 solver.cpp:239] Iteration 25800 (12.6092 iter/s, 7.93075s/100 iters), loss = 0.0876099
I0316 12:40:47.325793 55708 solver.cpp:258]     Train net output #0: loss = 0.160308 (* 1 = 0.160308 loss)
I0316 12:40:47.325803 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000298834 (* 1 = 0.000298834 loss)
I0316 12:40:47.325809 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0729972 (* 1 = -0.0729972 loss)
I0316 12:40:47.325814 55708 sgd_solver.cpp:112] Iteration 25800, lr = 0.0001
I0316 12:40:55.257601 55708 solver.cpp:239] Iteration 25900 (12.6074 iter/s, 7.93185s/100 iters), loss = -0.0503849
I0316 12:40:55.257642 55708 solver.cpp:258]     Train net output #0: loss = 0.0256096 (* 1 = 0.0256096 loss)
I0316 12:40:55.257649 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000312545 (* 1 = 0.000312545 loss)
I0316 12:40:55.257670 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0763071 (* 1 = -0.0763071 loss)
I0316 12:40:55.257675 55708 sgd_solver.cpp:112] Iteration 25900, lr = 0.0001
I0316 12:41:03.110409 55708 solver.cpp:351] Iteration 26000, Testing net (#0)
I0316 12:41:08.041366 55708 solver.cpp:418]     Test net output #0: loss = 0.461542 (* 1 = 0.461542 loss)
I0316 12:41:08.041395 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000258665 (* 1 = 0.000258665 loss)
I0316 12:41:08.041401 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0725687 (* 1 = -0.0725687 loss)
I0316 12:41:08.041407 55708 solver.cpp:418]     Test net output #3: top-1 = 0.864688
I0316 12:41:08.041411 55708 solver.cpp:418]     Test net output #4: top-5 = 0.9925
I0316 12:41:08.119213 55708 solver.cpp:239] Iteration 26000 (7.77505 iter/s, 12.8616s/100 iters), loss = -0.0244012
I0316 12:41:08.119241 55708 solver.cpp:258]     Train net output #0: loss = 0.0496582 (* 1 = 0.0496582 loss)
I0316 12:41:08.119248 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000229664 (* 1 = 0.000229664 loss)
I0316 12:41:08.119254 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.074289 (* 1 = -0.074289 loss)
I0316 12:41:08.119277 55708 sgd_solver.cpp:112] Iteration 26000, lr = 0.0001
I0316 12:41:16.047564 55708 solver.cpp:239] Iteration 26100 (12.6129 iter/s, 7.92836s/100 iters), loss = -0.041777
I0316 12:41:16.047606 55708 solver.cpp:258]     Train net output #0: loss = 0.0345716 (* 1 = 0.0345716 loss)
I0316 12:41:16.047613 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000338781 (* 1 = 0.000338781 loss)
I0316 12:41:16.047619 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0766874 (* 1 = -0.0766874 loss)
I0316 12:41:16.047624 55708 sgd_solver.cpp:112] Iteration 26100, lr = 0.0001
I0316 12:41:23.977474 55708 solver.cpp:239] Iteration 26200 (12.6105 iter/s, 7.92991s/100 iters), loss = -0.0106936
I0316 12:41:23.977816 55708 solver.cpp:258]     Train net output #0: loss = 0.0669565 (* 1 = 0.0669565 loss)
I0316 12:41:23.977824 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000377109 (* 1 = 0.000377109 loss)
I0316 12:41:23.977830 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0780272 (* 1 = -0.0780272 loss)
I0316 12:41:23.977836 55708 sgd_solver.cpp:112] Iteration 26200, lr = 0.0001
I0316 12:41:31.908226 55708 solver.cpp:239] Iteration 26300 (12.6096 iter/s, 7.93044s/100 iters), loss = 0.00714862
I0316 12:41:31.908269 55708 solver.cpp:258]     Train net output #0: loss = 0.083893 (* 1 = 0.083893 loss)
I0316 12:41:31.908277 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000221471 (* 1 = 0.000221471 loss)
I0316 12:41:31.908299 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0769658 (* 1 = -0.0769658 loss)
I0316 12:41:31.908304 55708 sgd_solver.cpp:112] Iteration 26300, lr = 0.0001
I0316 12:41:39.838320 55708 solver.cpp:239] Iteration 26400 (12.6102 iter/s, 7.93009s/100 iters), loss = 0.0212933
I0316 12:41:39.838372 55708 solver.cpp:258]     Train net output #0: loss = 0.0988025 (* 1 = 0.0988025 loss)
I0316 12:41:39.838380 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000226382 (* 1 = 0.000226382 loss)
I0316 12:41:39.838403 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0777357 (* 1 = -0.0777357 loss)
I0316 12:41:39.838409 55708 sgd_solver.cpp:112] Iteration 26400, lr = 0.0001
I0316 12:41:47.769670 55708 solver.cpp:239] Iteration 26500 (12.6082 iter/s, 7.93134s/100 iters), loss = -0.0353418
I0316 12:41:47.769718 55708 solver.cpp:258]     Train net output #0: loss = 0.0402062 (* 1 = 0.0402062 loss)
I0316 12:41:47.769724 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000276832 (* 1 = 0.000276832 loss)
I0316 12:41:47.769730 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0758249 (* 1 = -0.0758249 loss)
I0316 12:41:47.769734 55708 sgd_solver.cpp:112] Iteration 26500, lr = 0.0001
I0316 12:41:52.371179 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:41:55.699025 55708 solver.cpp:239] Iteration 26600 (12.6114 iter/s, 7.92935s/100 iters), loss = -0.011572
I0316 12:41:55.699326 55708 solver.cpp:258]     Train net output #0: loss = 0.0672874 (* 1 = 0.0672874 loss)
I0316 12:41:55.699333 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00029847 (* 1 = 0.00029847 loss)
I0316 12:41:55.699340 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0791579 (* 1 = -0.0791579 loss)
I0316 12:41:55.699345 55708 sgd_solver.cpp:112] Iteration 26600, lr = 0.0001
I0316 12:42:03.627442 55708 solver.cpp:239] Iteration 26700 (12.6133 iter/s, 7.92816s/100 iters), loss = 0.0564904
I0316 12:42:03.627483 55708 solver.cpp:258]     Train net output #0: loss = 0.123489 (* 1 = 0.123489 loss)
I0316 12:42:03.627491 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000256022 (* 1 = 0.000256022 loss)
I0316 12:42:03.627512 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0672551 (* 1 = -0.0672551 loss)
I0316 12:42:03.627517 55708 sgd_solver.cpp:112] Iteration 26700, lr = 0.0001
I0316 12:42:11.557335 55708 solver.cpp:239] Iteration 26800 (12.6105 iter/s, 7.92988s/100 iters), loss = 0.0260395
I0316 12:42:11.557382 55708 solver.cpp:258]     Train net output #0: loss = 0.100572 (* 1 = 0.100572 loss)
I0316 12:42:11.557389 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000249116 (* 1 = 0.000249116 loss)
I0316 12:42:11.557395 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0747816 (* 1 = -0.0747816 loss)
I0316 12:42:11.557400 55708 sgd_solver.cpp:112] Iteration 26800, lr = 0.0001
I0316 12:42:19.487426 55708 solver.cpp:239] Iteration 26900 (12.6102 iter/s, 7.93008s/100 iters), loss = 0.0565041
I0316 12:42:19.487475 55708 solver.cpp:258]     Train net output #0: loss = 0.125403 (* 1 = 0.125403 loss)
I0316 12:42:19.487483 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000285314 (* 1 = 0.000285314 loss)
I0316 12:42:19.487504 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.069184 (* 1 = -0.069184 loss)
I0316 12:42:19.487511 55708 sgd_solver.cpp:112] Iteration 26900, lr = 0.0001
I0316 12:42:27.348455 55708 solver.cpp:351] Iteration 27000, Testing net (#0)
I0316 12:42:30.048746 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:42:32.299548 55708 solver.cpp:418]     Test net output #0: loss = 0.454637 (* 1 = 0.454637 loss)
I0316 12:42:32.299574 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000256564 (* 1 = 0.000256564 loss)
I0316 12:42:32.299580 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.072403 (* 1 = -0.072403 loss)
I0316 12:42:32.299585 55708 solver.cpp:418]     Test net output #3: top-1 = 0.864531
I0316 12:42:32.299589 55708 solver.cpp:418]     Test net output #4: top-5 = 0.992813
I0316 12:42:32.377523 55708 solver.cpp:239] Iteration 27000 (7.75788 iter/s, 12.8901s/100 iters), loss = -0.0739449
I0316 12:42:32.377559 55708 solver.cpp:258]     Train net output #0: loss = 0.00639232 (* 1 = 0.00639232 loss)
I0316 12:42:32.377566 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000249741 (* 1 = 0.000249741 loss)
I0316 12:42:32.377589 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.080587 (* 1 = -0.080587 loss)
I0316 12:42:32.377597 55708 sgd_solver.cpp:112] Iteration 27000, lr = 0.0001
I0316 12:42:40.336014 55708 solver.cpp:239] Iteration 27100 (12.5652 iter/s, 7.95849s/100 iters), loss = -0.0512599
I0316 12:42:40.336066 55708 solver.cpp:258]     Train net output #0: loss = 0.028243 (* 1 = 0.028243 loss)
I0316 12:42:40.336074 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00033354 (* 1 = 0.00033354 loss)
I0316 12:42:40.336082 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0798365 (* 1 = -0.0798365 loss)
I0316 12:42:40.336091 55708 sgd_solver.cpp:112] Iteration 27100, lr = 0.0001
I0316 12:42:48.292892 55708 solver.cpp:239] Iteration 27200 (12.5678 iter/s, 7.95686s/100 iters), loss = -0.0044373
I0316 12:42:48.292956 55708 solver.cpp:258]     Train net output #0: loss = 0.069294 (* 1 = 0.069294 loss)
I0316 12:42:48.292965 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000268293 (* 1 = 0.000268293 loss)
I0316 12:42:48.292973 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0739997 (* 1 = -0.0739997 loss)
I0316 12:42:48.292979 55708 sgd_solver.cpp:112] Iteration 27200, lr = 0.0001
I0316 12:42:56.242234 55708 solver.cpp:239] Iteration 27300 (12.5797 iter/s, 7.94932s/100 iters), loss = -0.0632214
I0316 12:42:56.242281 55708 solver.cpp:258]     Train net output #0: loss = 0.0144344 (* 1 = 0.0144344 loss)
I0316 12:42:56.242290 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000324436 (* 1 = 0.000324436 loss)
I0316 12:42:56.242295 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0779803 (* 1 = -0.0779803 loss)
I0316 12:42:56.242300 55708 sgd_solver.cpp:112] Iteration 27300, lr = 0.0001
I0316 12:43:04.189800 55708 solver.cpp:239] Iteration 27400 (12.5825 iter/s, 7.94756s/100 iters), loss = -0.0627434
I0316 12:43:04.190079 55708 solver.cpp:258]     Train net output #0: loss = 0.0130545 (* 1 = 0.0130545 loss)
I0316 12:43:04.190088 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000288556 (* 1 = 0.000288556 loss)
I0316 12:43:04.190094 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0760865 (* 1 = -0.0760865 loss)
I0316 12:43:04.190101 55708 sgd_solver.cpp:112] Iteration 27400, lr = 0.0001
I0316 12:43:12.137821 55708 solver.cpp:239] Iteration 27500 (12.5821 iter/s, 7.94778s/100 iters), loss = -0.0479255
I0316 12:43:12.137872 55708 solver.cpp:258]     Train net output #0: loss = 0.0303191 (* 1 = 0.0303191 loss)
I0316 12:43:12.137879 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000291076 (* 1 = 0.000291076 loss)
I0316 12:43:12.137887 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0785358 (* 1 = -0.0785358 loss)
I0316 12:43:12.137892 55708 sgd_solver.cpp:112] Iteration 27500, lr = 0.0001
I0316 12:43:20.086033 55708 solver.cpp:239] Iteration 27600 (12.5815 iter/s, 7.9482s/100 iters), loss = -0.0447457
I0316 12:43:20.086083 55708 solver.cpp:258]     Train net output #0: loss = 0.0258654 (* 1 = 0.0258654 loss)
I0316 12:43:20.086092 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000187321 (* 1 = 0.000187321 loss)
I0316 12:43:20.086098 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0707985 (* 1 = -0.0707985 loss)
I0316 12:43:20.086103 55708 sgd_solver.cpp:112] Iteration 27600, lr = 0.0001
I0316 12:43:28.034529 55708 solver.cpp:239] Iteration 27700 (12.581 iter/s, 7.94848s/100 iters), loss = -0.0454102
I0316 12:43:28.034581 55708 solver.cpp:258]     Train net output #0: loss = 0.0298364 (* 1 = 0.0298364 loss)
I0316 12:43:28.034590 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000348577 (* 1 = 0.000348577 loss)
I0316 12:43:28.034595 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0755952 (* 1 = -0.0755952 loss)
I0316 12:43:28.034600 55708 sgd_solver.cpp:112] Iteration 27700, lr = 0.0001
I0316 12:43:35.986604 55708 solver.cpp:239] Iteration 27800 (12.5753 iter/s, 7.95207s/100 iters), loss = -0.0522597
I0316 12:43:35.986936 55708 solver.cpp:258]     Train net output #0: loss = 0.0246561 (* 1 = 0.0246561 loss)
I0316 12:43:35.986945 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000261647 (* 1 = 0.000261647 loss)
I0316 12:43:35.986951 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0771775 (* 1 = -0.0771775 loss)
I0316 12:43:35.986958 55708 sgd_solver.cpp:112] Iteration 27800, lr = 0.0001
I0316 12:43:43.946812 55708 solver.cpp:239] Iteration 27900 (12.5629 iter/s, 7.95993s/100 iters), loss = -0.0521041
I0316 12:43:43.946861 55708 solver.cpp:258]     Train net output #0: loss = 0.0197075 (* 1 = 0.0197075 loss)
I0316 12:43:43.946869 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000262487 (* 1 = 0.000262487 loss)
I0316 12:43:43.946877 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0720741 (* 1 = -0.0720741 loss)
I0316 12:43:43.946882 55708 sgd_solver.cpp:112] Iteration 27900, lr = 0.0001
I0316 12:43:51.835376 55708 solver.cpp:351] Iteration 28000, Testing net (#0)
I0316 12:43:56.797320 55708 solver.cpp:418]     Test net output #0: loss = 0.463567 (* 1 = 0.463567 loss)
I0316 12:43:56.797348 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000262789 (* 1 = 0.000262789 loss)
I0316 12:43:56.797355 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0731447 (* 1 = -0.0731447 loss)
I0316 12:43:56.797360 55708 solver.cpp:418]     Test net output #3: top-1 = 0.863281
I0316 12:43:56.797364 55708 solver.cpp:418]     Test net output #4: top-5 = 0.992188
I0316 12:43:56.875159 55708 solver.cpp:239] Iteration 28000 (7.73492 iter/s, 12.9284s/100 iters), loss = 0.0218087
I0316 12:43:56.875195 55708 solver.cpp:258]     Train net output #0: loss = 0.0959505 (* 1 = 0.0959505 loss)
I0316 12:43:56.875201 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000301298 (* 1 = 0.000301298 loss)
I0316 12:43:56.875207 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0744431 (* 1 = -0.0744431 loss)
I0316 12:43:56.875214 55708 sgd_solver.cpp:112] Iteration 28000, lr = 0.0001
I0316 12:44:04.836539 55708 solver.cpp:239] Iteration 28100 (12.5606 iter/s, 7.96138s/100 iters), loss = -0.0593685
I0316 12:44:04.836596 55708 solver.cpp:258]     Train net output #0: loss = 0.015536 (* 1 = 0.015536 loss)
I0316 12:44:04.836604 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000226811 (* 1 = 0.000226811 loss)
I0316 12:44:04.836611 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0751314 (* 1 = -0.0751314 loss)
I0316 12:44:04.836618 55708 sgd_solver.cpp:112] Iteration 28100, lr = 0.0001
I0316 12:44:06.431144 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:44:12.799957 55708 solver.cpp:239] Iteration 28200 (12.5574 iter/s, 7.9634s/100 iters), loss = -0.0599723
I0316 12:44:12.800057 55708 solver.cpp:258]     Train net output #0: loss = 0.0152917 (* 1 = 0.0152917 loss)
I0316 12:44:12.800081 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000329811 (* 1 = 0.000329811 loss)
I0316 12:44:12.800103 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0755939 (* 1 = -0.0755939 loss)
I0316 12:44:12.800117 55708 sgd_solver.cpp:112] Iteration 28200, lr = 0.0001
I0316 12:44:20.759301 55708 solver.cpp:239] Iteration 28300 (12.5639 iter/s, 7.95929s/100 iters), loss = -0.0522122
I0316 12:44:20.759356 55708 solver.cpp:258]     Train net output #0: loss = 0.0247987 (* 1 = 0.0247987 loss)
I0316 12:44:20.759368 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00028582 (* 1 = 0.00028582 loss)
I0316 12:44:20.759378 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0772969 (* 1 = -0.0772969 loss)
I0316 12:44:20.759388 55708 sgd_solver.cpp:112] Iteration 28300, lr = 0.0001
I0316 12:44:28.727218 55708 solver.cpp:239] Iteration 28400 (12.5504 iter/s, 7.9679s/100 iters), loss = -0.0555471
I0316 12:44:28.727277 55708 solver.cpp:258]     Train net output #0: loss = 0.0183263 (* 1 = 0.0183263 loss)
I0316 12:44:28.727288 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000347432 (* 1 = 0.000347432 loss)
I0316 12:44:28.727299 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0742209 (* 1 = -0.0742209 loss)
I0316 12:44:28.727308 55708 sgd_solver.cpp:112] Iteration 28400, lr = 0.0001
I0316 12:44:36.720991 55708 solver.cpp:239] Iteration 28500 (12.5098 iter/s, 7.99376s/100 iters), loss = -0.0578371
I0316 12:44:36.721285 55708 solver.cpp:258]     Train net output #0: loss = 0.0174387 (* 1 = 0.0174387 loss)
I0316 12:44:36.721299 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000294554 (* 1 = 0.000294554 loss)
I0316 12:44:36.721311 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0755704 (* 1 = -0.0755704 loss)
I0316 12:44:36.721320 55708 sgd_solver.cpp:112] Iteration 28500, lr = 0.0001
I0316 12:44:44.690042 55708 solver.cpp:239] Iteration 28600 (12.5489 iter/s, 7.9688s/100 iters), loss = -0.0733939
I0316 12:44:44.690099 55708 solver.cpp:258]     Train net output #0: loss = 0.00873551 (* 1 = 0.00873551 loss)
I0316 12:44:44.690109 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.0002621 (* 1 = 0.0002621 loss)
I0316 12:44:44.690120 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0823916 (* 1 = -0.0823916 loss)
I0316 12:44:44.690129 55708 sgd_solver.cpp:112] Iteration 28600, lr = 0.0001
I0316 12:44:52.667352 55708 solver.cpp:239] Iteration 28700 (12.5356 iter/s, 7.97729s/100 iters), loss = -0.0132428
I0316 12:44:52.667416 55708 solver.cpp:258]     Train net output #0: loss = 0.0640186 (* 1 = 0.0640186 loss)
I0316 12:44:52.667428 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000258336 (* 1 = 0.000258336 loss)
I0316 12:44:52.667439 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0775197 (* 1 = -0.0775197 loss)
I0316 12:44:52.667454 55708 sgd_solver.cpp:112] Iteration 28700, lr = 0.0001
I0316 12:45:00.617468 55708 solver.cpp:239] Iteration 28800 (12.5785 iter/s, 7.9501s/100 iters), loss = -0.0497627
I0316 12:45:00.617514 55708 solver.cpp:258]     Train net output #0: loss = 0.0263627 (* 1 = 0.0263627 loss)
I0316 12:45:00.617522 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000280808 (* 1 = 0.000280808 loss)
I0316 12:45:00.617527 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0764063 (* 1 = -0.0764063 loss)
I0316 12:45:00.617532 55708 sgd_solver.cpp:112] Iteration 28800, lr = 0.0001
I0316 12:45:08.561408 55708 solver.cpp:239] Iteration 28900 (12.5882 iter/s, 7.94393s/100 iters), loss = -0.0650324
I0316 12:45:08.561771 55708 solver.cpp:258]     Train net output #0: loss = 0.0132685 (* 1 = 0.0132685 loss)
I0316 12:45:08.561781 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000283018 (* 1 = 0.000283018 loss)
I0316 12:45:08.561787 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0785839 (* 1 = -0.0785839 loss)
I0316 12:45:08.561792 55708 sgd_solver.cpp:112] Iteration 28900, lr = 0.0001
I0316 12:45:16.427423 55708 solver.cpp:351] Iteration 29000, Testing net (#0)
I0316 12:45:16.947623 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:45:21.376227 55708 solver.cpp:418]     Test net output #0: loss = 0.44902 (* 1 = 0.44902 loss)
I0316 12:45:21.376253 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000264952 (* 1 = 0.000264952 loss)
I0316 12:45:21.376260 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0732102 (* 1 = -0.0732102 loss)
I0316 12:45:21.376264 55708 solver.cpp:418]     Test net output #3: top-1 = 0.867031
I0316 12:45:21.376268 55708 solver.cpp:418]     Test net output #4: top-5 = 0.993594
I0316 12:45:21.453948 55708 solver.cpp:239] Iteration 29000 (7.75659 iter/s, 12.8923s/100 iters), loss = -0.0407629
I0316 12:45:21.453979 55708 solver.cpp:258]     Train net output #0: loss = 0.0377084 (* 1 = 0.0377084 loss)
I0316 12:45:21.453986 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000275289 (* 1 = 0.000275289 loss)
I0316 12:45:21.453992 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0787467 (* 1 = -0.0787467 loss)
I0316 12:45:21.453997 55708 sgd_solver.cpp:112] Iteration 29000, lr = 0.0001
I0316 12:45:29.399410 55708 solver.cpp:239] Iteration 29100 (12.5858 iter/s, 7.94546s/100 iters), loss = -0.061859
I0316 12:45:29.399456 55708 solver.cpp:258]     Train net output #0: loss = 0.0158122 (* 1 = 0.0158122 loss)
I0316 12:45:29.399463 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000332197 (* 1 = 0.000332197 loss)
I0316 12:45:29.399485 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0780035 (* 1 = -0.0780035 loss)
I0316 12:45:29.399489 55708 sgd_solver.cpp:112] Iteration 29100, lr = 0.0001
I0316 12:45:37.343281 55708 solver.cpp:239] Iteration 29200 (12.5883 iter/s, 7.94387s/100 iters), loss = -0.0586658
I0316 12:45:37.343322 55708 solver.cpp:258]     Train net output #0: loss = 0.0202049 (* 1 = 0.0202049 loss)
I0316 12:45:37.343329 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00030063 (* 1 = 0.00030063 loss)
I0316 12:45:37.343334 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0791714 (* 1 = -0.0791714 loss)
I0316 12:45:37.343341 55708 sgd_solver.cpp:112] Iteration 29200, lr = 0.0001
I0316 12:45:45.275225 55708 solver.cpp:239] Iteration 29300 (12.6073 iter/s, 7.93194s/100 iters), loss = -0.0353838
I0316 12:45:45.275543 55708 solver.cpp:258]     Train net output #0: loss = 0.0383325 (* 1 = 0.0383325 loss)
I0316 12:45:45.275552 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000224874 (* 1 = 0.000224874 loss)
I0316 12:45:45.275558 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0739413 (* 1 = -0.0739413 loss)
I0316 12:45:45.275564 55708 sgd_solver.cpp:112] Iteration 29300, lr = 0.0001
I0316 12:45:53.202741 55708 solver.cpp:239] Iteration 29400 (12.6147 iter/s, 7.92725s/100 iters), loss = -0.068
I0316 12:45:53.202802 55708 solver.cpp:258]     Train net output #0: loss = 0.012476 (* 1 = 0.012476 loss)
I0316 12:45:53.202831 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000349626 (* 1 = 0.000349626 loss)
I0316 12:45:53.202839 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0808258 (* 1 = -0.0808258 loss)
I0316 12:45:53.202847 55708 sgd_solver.cpp:112] Iteration 29400, lr = 0.0001
I0316 12:46:01.134861 55708 solver.cpp:239] Iteration 29500 (12.607 iter/s, 7.93211s/100 iters), loss = -0.0577612
I0316 12:46:01.134905 55708 solver.cpp:258]     Train net output #0: loss = 0.0188321 (* 1 = 0.0188321 loss)
I0316 12:46:01.134912 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000251129 (* 1 = 0.000251129 loss)
I0316 12:46:01.134933 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0768445 (* 1 = -0.0768445 loss)
I0316 12:46:01.134938 55708 sgd_solver.cpp:112] Iteration 29500, lr = 0.0001
I0316 12:46:09.066449 55708 solver.cpp:239] Iteration 29600 (12.6078 iter/s, 7.93158s/100 iters), loss = -0.02621
I0316 12:46:09.066495 55708 solver.cpp:258]     Train net output #0: loss = 0.0509281 (* 1 = 0.0509281 loss)
I0316 12:46:09.066502 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000249469 (* 1 = 0.000249469 loss)
I0316 12:46:09.066524 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0773876 (* 1 = -0.0773876 loss)
I0316 12:46:09.066529 55708 sgd_solver.cpp:112] Iteration 29600, lr = 0.0001
I0316 12:46:15.650182 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:46:17.003101 55708 solver.cpp:239] Iteration 29700 (12.5998 iter/s, 7.93664s/100 iters), loss = -0.0206262
I0316 12:46:17.003149 55708 solver.cpp:258]     Train net output #0: loss = 0.0550616 (* 1 = 0.0550616 loss)
I0316 12:46:17.003156 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00030703 (* 1 = 0.00030703 loss)
I0316 12:46:17.003162 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0759949 (* 1 = -0.0759949 loss)
I0316 12:46:17.003168 55708 sgd_solver.cpp:112] Iteration 29700, lr = 0.0001
I0316 12:46:24.936358 55708 solver.cpp:239] Iteration 29800 (12.6052 iter/s, 7.93325s/100 iters), loss = -0.0452673
I0316 12:46:24.936429 55708 solver.cpp:258]     Train net output #0: loss = 0.031591 (* 1 = 0.031591 loss)
I0316 12:46:24.936436 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000302188 (* 1 = 0.000302188 loss)
I0316 12:46:24.936442 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0771606 (* 1 = -0.0771606 loss)
I0316 12:46:24.936447 55708 sgd_solver.cpp:112] Iteration 29800, lr = 0.0001
I0316 12:46:32.862488 55708 solver.cpp:239] Iteration 29900 (12.6165 iter/s, 7.9261s/100 iters), loss = -0.0573446
I0316 12:46:32.862530 55708 solver.cpp:258]     Train net output #0: loss = 0.0194049 (* 1 = 0.0194049 loss)
I0316 12:46:32.862537 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000287931 (* 1 = 0.000287931 loss)
I0316 12:46:32.862543 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0770375 (* 1 = -0.0770375 loss)
I0316 12:46:32.862550 55708 sgd_solver.cpp:112] Iteration 29900, lr = 0.0001
I0316 12:46:40.714540 55708 solver.cpp:351] Iteration 30000, Testing net (#0)
I0316 12:46:44.019630 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:46:45.644017 55708 solver.cpp:418]     Test net output #0: loss = 0.437859 (* 1 = 0.437859 loss)
I0316 12:46:45.644049 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000263493 (* 1 = 0.000263493 loss)
I0316 12:46:45.644057 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0731863 (* 1 = -0.0731863 loss)
I0316 12:46:45.644060 55708 solver.cpp:418]     Test net output #3: top-1 = 0.871094
I0316 12:46:45.644064 55708 solver.cpp:418]     Test net output #4: top-5 = 0.993594
I0316 12:46:45.721742 55708 solver.cpp:239] Iteration 30000 (7.77648 iter/s, 12.8593s/100 iters), loss = -0.0371963
I0316 12:46:45.722064 55708 solver.cpp:258]     Train net output #0: loss = 0.0376061 (* 1 = 0.0376061 loss)
I0316 12:46:45.722070 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000259823 (* 1 = 0.000259823 loss)
I0316 12:46:45.722076 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0750623 (* 1 = -0.0750623 loss)
I0316 12:46:45.722087 55708 sgd_solver.cpp:112] Iteration 30000, lr = 0.0001
I0316 12:46:53.658864 55708 solver.cpp:239] Iteration 30100 (12.5995 iter/s, 7.93684s/100 iters), loss = -0.0679289
I0316 12:46:53.658970 55708 solver.cpp:258]     Train net output #0: loss = 0.00926779 (* 1 = 0.00926779 loss)
I0316 12:46:53.659005 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000278371 (* 1 = 0.000278371 loss)
I0316 12:46:53.659030 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0774752 (* 1 = -0.0774752 loss)
I0316 12:46:53.659051 55708 sgd_solver.cpp:112] Iteration 30100, lr = 0.0001
I0316 12:47:01.592598 55708 solver.cpp:239] Iteration 30200 (12.6045 iter/s, 7.93367s/100 iters), loss = -0.0663207
I0316 12:47:01.592648 55708 solver.cpp:258]     Train net output #0: loss = 0.0132617 (* 1 = 0.0132617 loss)
I0316 12:47:01.592658 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000339935 (* 1 = 0.000339935 loss)
I0316 12:47:01.592666 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0799224 (* 1 = -0.0799224 loss)
I0316 12:47:01.592674 55708 sgd_solver.cpp:112] Iteration 30200, lr = 0.0001
I0316 12:47:09.530859 55708 solver.cpp:239] Iteration 30300 (12.5972 iter/s, 7.93825s/100 iters), loss = -0.0512441
I0316 12:47:09.530912 55708 solver.cpp:258]     Train net output #0: loss = 0.0242616 (* 1 = 0.0242616 loss)
I0316 12:47:09.530922 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000210917 (* 1 = 0.000210917 loss)
I0316 12:47:09.530930 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0757166 (* 1 = -0.0757166 loss)
I0316 12:47:09.530936 55708 sgd_solver.cpp:112] Iteration 30300, lr = 0.0001
I0316 12:47:17.473197 55708 solver.cpp:239] Iteration 30400 (12.5908 iter/s, 7.94233s/100 iters), loss = -0.0713676
I0316 12:47:17.473556 55708 solver.cpp:258]     Train net output #0: loss = 0.0092727 (* 1 = 0.0092727 loss)
I0316 12:47:17.473567 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000368377 (* 1 = 0.000368377 loss)
I0316 12:47:17.473575 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0810088 (* 1 = -0.0810088 loss)
I0316 12:47:17.473583 55708 sgd_solver.cpp:112] Iteration 30400, lr = 0.0001
I0316 12:47:25.417300 55708 solver.cpp:239] Iteration 30500 (12.5885 iter/s, 7.94378s/100 iters), loss = -0.0536991
I0316 12:47:25.417352 55708 solver.cpp:258]     Train net output #0: loss = 0.0220655 (* 1 = 0.0220655 loss)
I0316 12:47:25.417361 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000343478 (* 1 = 0.000343478 loss)
I0316 12:47:25.417371 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0761081 (* 1 = -0.0761081 loss)
I0316 12:47:25.417376 55708 sgd_solver.cpp:112] Iteration 30500, lr = 0.0001
I0316 12:47:33.361042 55708 solver.cpp:239] Iteration 30600 (12.5885 iter/s, 7.94373s/100 iters), loss = -0.0602088
I0316 12:47:33.361088 55708 solver.cpp:258]     Train net output #0: loss = 0.0182445 (* 1 = 0.0182445 loss)
I0316 12:47:33.361097 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000312676 (* 1 = 0.000312676 loss)
I0316 12:47:33.361105 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0787661 (* 1 = -0.0787661 loss)
I0316 12:47:33.361111 55708 sgd_solver.cpp:112] Iteration 30600, lr = 0.0001
I0316 12:47:41.303395 55708 solver.cpp:239] Iteration 30700 (12.5907 iter/s, 7.94235s/100 iters), loss = -0.0493396
I0316 12:47:41.303440 55708 solver.cpp:258]     Train net output #0: loss = 0.0255071 (* 1 = 0.0255071 loss)
I0316 12:47:41.303449 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000247387 (* 1 = 0.000247387 loss)
I0316 12:47:41.303457 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0750942 (* 1 = -0.0750942 loss)
I0316 12:47:41.303463 55708 sgd_solver.cpp:112] Iteration 30700, lr = 0.0001
I0316 12:47:49.247678 55708 solver.cpp:239] Iteration 30800 (12.5877 iter/s, 7.94427s/100 iters), loss = -0.0657797
I0316 12:47:49.247970 55708 solver.cpp:258]     Train net output #0: loss = 0.0117029 (* 1 = 0.0117029 loss)
I0316 12:47:49.247982 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000238489 (* 1 = 0.000238489 loss)
I0316 12:47:49.247989 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0777212 (* 1 = -0.0777212 loss)
I0316 12:47:49.247998 55708 sgd_solver.cpp:112] Iteration 30800, lr = 0.0001
I0316 12:47:57.190244 55708 solver.cpp:239] Iteration 30900 (12.5908 iter/s, 7.94232s/100 iters), loss = -0.046216
I0316 12:47:57.190291 55708 solver.cpp:258]     Train net output #0: loss = 0.0305925 (* 1 = 0.0305925 loss)
I0316 12:47:57.190300 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000243705 (* 1 = 0.000243705 loss)
I0316 12:47:57.190310 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0770523 (* 1 = -0.0770523 loss)
I0316 12:47:57.190316 55708 sgd_solver.cpp:112] Iteration 30900, lr = 0.0001
I0316 12:48:05.056289 55708 solver.cpp:351] Iteration 31000, Testing net (#0)
I0316 12:48:10.003238 55708 solver.cpp:418]     Test net output #0: loss = 0.462407 (* 1 = 0.462407 loss)
I0316 12:48:10.003268 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000268629 (* 1 = 0.000268629 loss)
I0316 12:48:10.003276 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0737446 (* 1 = -0.0737446 loss)
I0316 12:48:10.003283 55708 solver.cpp:418]     Test net output #3: top-1 = 0.864219
I0316 12:48:10.003288 55708 solver.cpp:418]     Test net output #4: top-5 = 0.992344
I0316 12:48:10.081284 55708 solver.cpp:239] Iteration 31000 (7.75731 iter/s, 12.8911s/100 iters), loss = -0.0713063
I0316 12:48:10.081327 55708 solver.cpp:258]     Train net output #0: loss = 0.00994138 (* 1 = 0.00994138 loss)
I0316 12:48:10.081337 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000278289 (* 1 = 0.000278289 loss)
I0316 12:48:10.081347 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0815261 (* 1 = -0.0815261 loss)
I0316 12:48:10.081393 55708 sgd_solver.cpp:112] Iteration 31000, lr = 0.0001
I0316 12:48:18.028090 55708 solver.cpp:239] Iteration 31100 (12.5837 iter/s, 7.94681s/100 iters), loss = -0.0533718
I0316 12:48:18.028132 55708 solver.cpp:258]     Train net output #0: loss = 0.0231376 (* 1 = 0.0231376 loss)
I0316 12:48:18.028139 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000185057 (* 1 = 0.000185057 loss)
I0316 12:48:18.028162 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0766945 (* 1 = -0.0766945 loss)
I0316 12:48:18.028167 55708 sgd_solver.cpp:112] Iteration 31100, lr = 0.0001
I0316 12:48:25.971583 55708 solver.cpp:239] Iteration 31200 (12.5889 iter/s, 7.94348s/100 iters), loss = -0.0422131
I0316 12:48:25.971905 55708 solver.cpp:258]     Train net output #0: loss = 0.0339383 (* 1 = 0.0339383 loss)
I0316 12:48:25.971915 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000271707 (* 1 = 0.000271707 loss)
I0316 12:48:25.971920 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0764233 (* 1 = -0.0764233 loss)
I0316 12:48:25.971925 55708 sgd_solver.cpp:112] Iteration 31200, lr = 0.0001
I0316 12:48:29.551169 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:48:33.916208 55708 solver.cpp:239] Iteration 31300 (12.5876 iter/s, 7.94434s/100 iters), loss = -0.0668515
I0316 12:48:33.916265 55708 solver.cpp:258]     Train net output #0: loss = 0.00997174 (* 1 = 0.00997174 loss)
I0316 12:48:33.916275 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00029898 (* 1 = 0.00029898 loss)
I0316 12:48:33.916285 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0771223 (* 1 = -0.0771223 loss)
I0316 12:48:33.916292 55708 sgd_solver.cpp:112] Iteration 31300, lr = 0.0001
I0316 12:48:41.862169 55708 solver.cpp:239] Iteration 31400 (12.585 iter/s, 7.94594s/100 iters), loss = -0.0579149
I0316 12:48:41.862210 55708 solver.cpp:258]     Train net output #0: loss = 0.0207564 (* 1 = 0.0207564 loss)
I0316 12:48:41.862217 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00026093 (* 1 = 0.00026093 loss)
I0316 12:48:41.862239 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0789324 (* 1 = -0.0789324 loss)
I0316 12:48:41.862244 55708 sgd_solver.cpp:112] Iteration 31400, lr = 0.0001
I0316 12:48:49.805932 55708 solver.cpp:239] Iteration 31500 (12.5885 iter/s, 7.94375s/100 iters), loss = -0.0529274
I0316 12:48:49.805980 55708 solver.cpp:258]     Train net output #0: loss = 0.0216506 (* 1 = 0.0216506 loss)
I0316 12:48:49.805989 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000204225 (* 1 = 0.000204225 loss)
I0316 12:48:49.805994 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0747822 (* 1 = -0.0747822 loss)
I0316 12:48:49.805999 55708 sgd_solver.cpp:112] Iteration 31500, lr = 0.0001
I0316 12:48:57.753468 55708 solver.cpp:239] Iteration 31600 (12.5825 iter/s, 7.94753s/100 iters), loss = -0.00385284
I0316 12:48:57.753827 55708 solver.cpp:258]     Train net output #0: loss = 0.0685901 (* 1 = 0.0685901 loss)
I0316 12:48:57.753835 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00023923 (* 1 = 0.00023923 loss)
I0316 12:48:57.753841 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0726822 (* 1 = -0.0726822 loss)
I0316 12:48:57.753846 55708 sgd_solver.cpp:112] Iteration 31600, lr = 0.0001
I0316 12:49:05.700582 55708 solver.cpp:239] Iteration 31700 (12.5837 iter/s, 7.94679s/100 iters), loss = -0.0727394
I0316 12:49:05.700639 55708 solver.cpp:258]     Train net output #0: loss = 0.00833077 (* 1 = 0.00833077 loss)
I0316 12:49:05.700647 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000295961 (* 1 = 0.000295961 loss)
I0316 12:49:05.700654 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0813662 (* 1 = -0.0813662 loss)
I0316 12:49:05.700661 55708 sgd_solver.cpp:112] Iteration 31700, lr = 0.0001
I0316 12:49:13.644448 55708 solver.cpp:239] Iteration 31800 (12.5884 iter/s, 7.94385s/100 iters), loss = -0.0461567
I0316 12:49:13.644495 55708 solver.cpp:258]     Train net output #0: loss = 0.0261476 (* 1 = 0.0261476 loss)
I0316 12:49:13.644501 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000305736 (* 1 = 0.000305736 loss)
I0316 12:49:13.644508 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0726101 (* 1 = -0.0726101 loss)
I0316 12:49:13.644513 55708 sgd_solver.cpp:112] Iteration 31800, lr = 0.0001
I0316 12:49:21.589459 55708 solver.cpp:239] Iteration 31900 (12.5865 iter/s, 7.945s/100 iters), loss = -0.0723288
I0316 12:49:21.589499 55708 solver.cpp:258]     Train net output #0: loss = 0.00667031 (* 1 = 0.00667031 loss)
I0316 12:49:21.589506 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000307771 (* 1 = 0.000307771 loss)
I0316 12:49:21.589512 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.079307 (* 1 = -0.079307 loss)
I0316 12:49:21.589517 55708 sgd_solver.cpp:112] Iteration 31900, lr = 0.0001
I0316 12:49:29.457000 55708 solver.cpp:351] Iteration 32000, Testing net (#0)
I0316 12:49:30.595324 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:49:34.399293 55708 solver.cpp:418]     Test net output #0: loss = 0.465078 (* 1 = 0.465078 loss)
I0316 12:49:34.399319 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000266785 (* 1 = 0.000266785 loss)
I0316 12:49:34.399325 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0734854 (* 1 = -0.0734854 loss)
I0316 12:49:34.399330 55708 solver.cpp:418]     Test net output #3: top-1 = 0.861719
I0316 12:49:34.399334 55708 solver.cpp:418]     Test net output #4: top-5 = 0.993281
I0316 12:49:34.477262 55708 solver.cpp:239] Iteration 32000 (7.75925 iter/s, 12.8878s/100 iters), loss = -0.0655001
I0316 12:49:34.477289 55708 solver.cpp:258]     Train net output #0: loss = 0.0151828 (* 1 = 0.0151828 loss)
I0316 12:49:34.477296 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00026167 (* 1 = 0.00026167 loss)
I0316 12:49:34.477303 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0809446 (* 1 = -0.0809446 loss)
I0316 12:49:34.477308 55708 sgd_solver.cpp:112] Iteration 32000, lr = 0.0001
I0316 12:49:42.421514 55708 solver.cpp:239] Iteration 32100 (12.5877 iter/s, 7.94426s/100 iters), loss = -0.038652
I0316 12:49:42.421561 55708 solver.cpp:258]     Train net output #0: loss = 0.0345607 (* 1 = 0.0345607 loss)
I0316 12:49:42.421568 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000271262 (* 1 = 0.000271262 loss)
I0316 12:49:42.421574 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.073484 (* 1 = -0.073484 loss)
I0316 12:49:42.421579 55708 sgd_solver.cpp:112] Iteration 32100, lr = 0.0001
I0316 12:49:50.367950 55708 solver.cpp:239] Iteration 32200 (12.5843 iter/s, 7.94642s/100 iters), loss = -0.034679
I0316 12:49:50.368000 55708 solver.cpp:258]     Train net output #0: loss = 0.0406768 (* 1 = 0.0406768 loss)
I0316 12:49:50.368007 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000277635 (* 1 = 0.000277635 loss)
I0316 12:49:50.368012 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0756335 (* 1 = -0.0756335 loss)
I0316 12:49:50.368024 55708 sgd_solver.cpp:112] Iteration 32200, lr = 0.0001
I0316 12:49:58.314329 55708 solver.cpp:239] Iteration 32300 (12.5844 iter/s, 7.94637s/100 iters), loss = -0.0272893
I0316 12:49:58.314376 55708 solver.cpp:258]     Train net output #0: loss = 0.0464969 (* 1 = 0.0464969 loss)
I0316 12:49:58.314383 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000329008 (* 1 = 0.000329008 loss)
I0316 12:49:58.314389 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0741153 (* 1 = -0.0741153 loss)
I0316 12:49:58.314394 55708 sgd_solver.cpp:112] Iteration 32300, lr = 0.0001
I0316 12:50:06.261673 55708 solver.cpp:239] Iteration 32400 (12.5829 iter/s, 7.94732s/100 iters), loss = -0.0473459
I0316 12:50:06.262006 55708 solver.cpp:258]     Train net output #0: loss = 0.0294028 (* 1 = 0.0294028 loss)
I0316 12:50:06.262015 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000271455 (* 1 = 0.000271455 loss)
I0316 12:50:06.262022 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0770202 (* 1 = -0.0770202 loss)
I0316 12:50:06.262027 55708 sgd_solver.cpp:112] Iteration 32400, lr = 0.0001
I0316 12:50:14.212605 55708 solver.cpp:239] Iteration 32500 (12.5776 iter/s, 7.95064s/100 iters), loss = -0.0435855
I0316 12:50:14.212657 55708 solver.cpp:258]     Train net output #0: loss = 0.0297099 (* 1 = 0.0297099 loss)
I0316 12:50:14.212666 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000284361 (* 1 = 0.000284361 loss)
I0316 12:50:14.212671 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0735798 (* 1 = -0.0735798 loss)
I0316 12:50:14.212677 55708 sgd_solver.cpp:112] Iteration 32500, lr = 0.0001
I0316 12:50:22.159155 55708 solver.cpp:239] Iteration 32600 (12.5841 iter/s, 7.94653s/100 iters), loss = -0.0581688
I0316 12:50:22.159205 55708 solver.cpp:258]     Train net output #0: loss = 0.0171411 (* 1 = 0.0171411 loss)
I0316 12:50:22.159214 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000395558 (* 1 = 0.000395558 loss)
I0316 12:50:22.159219 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0757055 (* 1 = -0.0757055 loss)
I0316 12:50:22.159226 55708 sgd_solver.cpp:112] Iteration 32600, lr = 0.0001
I0316 12:50:30.104382 55708 solver.cpp:239] Iteration 32700 (12.5862 iter/s, 7.94521s/100 iters), loss = -0.0585203
I0316 12:50:30.104430 55708 solver.cpp:258]     Train net output #0: loss = 0.015548 (* 1 = 0.015548 loss)
I0316 12:50:30.104436 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000307553 (* 1 = 0.000307553 loss)
I0316 12:50:30.104444 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.074376 (* 1 = -0.074376 loss)
I0316 12:50:30.104449 55708 sgd_solver.cpp:112] Iteration 32700, lr = 0.0001
I0316 12:50:38.049540 55708 solver.cpp:239] Iteration 32800 (12.5863 iter/s, 7.94515s/100 iters), loss = -0.031902
I0316 12:50:38.049870 55708 solver.cpp:258]     Train net output #0: loss = 0.0411649 (* 1 = 0.0411649 loss)
I0316 12:50:38.049878 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000240783 (* 1 = 0.000240783 loss)
I0316 12:50:38.049885 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0733077 (* 1 = -0.0733077 loss)
I0316 12:50:38.049890 55708 sgd_solver.cpp:112] Iteration 32800, lr = 0.0001
I0316 12:50:38.687078 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:50:45.995074 55708 solver.cpp:239] Iteration 32900 (12.5862 iter/s, 7.94524s/100 iters), loss = -0.0604838
I0316 12:50:45.995117 55708 solver.cpp:258]     Train net output #0: loss = 0.0187571 (* 1 = 0.0187571 loss)
I0316 12:50:45.995124 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000217072 (* 1 = 0.000217072 loss)
I0316 12:50:45.995146 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0794581 (* 1 = -0.0794581 loss)
I0316 12:50:45.995152 55708 sgd_solver.cpp:112] Iteration 32900, lr = 0.0001
I0316 12:50:53.861130 55708 solver.cpp:351] Iteration 33000, Testing net (#0)
I0316 12:50:57.793056 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:50:58.804503 55708 solver.cpp:418]     Test net output #0: loss = 0.432671 (* 1 = 0.432671 loss)
I0316 12:50:58.804531 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000265105 (* 1 = 0.000265105 loss)
I0316 12:50:58.804538 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0736354 (* 1 = -0.0736354 loss)
I0316 12:50:58.804543 55708 solver.cpp:418]     Test net output #3: top-1 = 0.872187
I0316 12:50:58.804545 55708 solver.cpp:418]     Test net output #4: top-5 = 0.993281
I0316 12:50:58.882223 55708 solver.cpp:239] Iteration 33000 (7.75965 iter/s, 12.8872s/100 iters), loss = -0.0564202
I0316 12:50:58.882254 55708 solver.cpp:258]     Train net output #0: loss = 0.0203011 (* 1 = 0.0203011 loss)
I0316 12:50:58.882261 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000263187 (* 1 = 0.000263187 loss)
I0316 12:50:58.882266 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0769846 (* 1 = -0.0769846 loss)
I0316 12:50:58.882289 55708 sgd_solver.cpp:112] Iteration 33000, lr = 0.0001
I0316 12:51:06.835525 55708 solver.cpp:239] Iteration 33100 (12.5734 iter/s, 7.95329s/100 iters), loss = 0.0144108
I0316 12:51:06.835597 55708 solver.cpp:258]     Train net output #0: loss = 0.0870548 (* 1 = 0.0870548 loss)
I0316 12:51:06.835609 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000271438 (* 1 = 0.000271438 loss)
I0316 12:51:06.835621 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0729155 (* 1 = -0.0729155 loss)
I0316 12:51:06.835633 55708 sgd_solver.cpp:112] Iteration 33100, lr = 0.0001
I0316 12:51:14.809424 55708 solver.cpp:239] Iteration 33200 (12.541 iter/s, 7.97388s/100 iters), loss = -0.0589382
I0316 12:51:14.809762 55708 solver.cpp:258]     Train net output #0: loss = 0.0180373 (* 1 = 0.0180373 loss)
I0316 12:51:14.809772 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000245571 (* 1 = 0.000245571 loss)
I0316 12:51:14.809778 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0772212 (* 1 = -0.0772212 loss)
I0316 12:51:14.809784 55708 sgd_solver.cpp:112] Iteration 33200, lr = 0.0001
I0316 12:51:22.779697 55708 solver.cpp:239] Iteration 33300 (12.5471 iter/s, 7.96998s/100 iters), loss = -0.0603427
I0316 12:51:22.779747 55708 solver.cpp:258]     Train net output #0: loss = 0.0189663 (* 1 = 0.0189663 loss)
I0316 12:51:22.779753 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000351689 (* 1 = 0.000351689 loss)
I0316 12:51:22.779760 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0796608 (* 1 = -0.0796608 loss)
I0316 12:51:22.779765 55708 sgd_solver.cpp:112] Iteration 33300, lr = 0.0001
I0316 12:51:30.742009 55708 solver.cpp:239] Iteration 33400 (12.5592 iter/s, 7.9623s/100 iters), loss = -0.041135
I0316 12:51:30.742058 55708 solver.cpp:258]     Train net output #0: loss = 0.0397918 (* 1 = 0.0397918 loss)
I0316 12:51:30.742065 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000268158 (* 1 = 0.000268158 loss)
I0316 12:51:30.742089 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0811951 (* 1 = -0.0811951 loss)
I0316 12:51:30.742095 55708 sgd_solver.cpp:112] Iteration 33400, lr = 0.0001
I0316 12:51:38.705348 55708 solver.cpp:239] Iteration 33500 (12.5576 iter/s, 7.96333s/100 iters), loss = -0.0675848
I0316 12:51:38.705394 55708 solver.cpp:258]     Train net output #0: loss = 0.010956 (* 1 = 0.010956 loss)
I0316 12:51:38.705402 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000348104 (* 1 = 0.000348104 loss)
I0316 12:51:38.705410 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0788889 (* 1 = -0.0788889 loss)
I0316 12:51:38.705416 55708 sgd_solver.cpp:112] Iteration 33500, lr = 0.0001
I0316 12:51:46.665378 55708 solver.cpp:239] Iteration 33600 (12.5628 iter/s, 7.96002s/100 iters), loss = -0.030951
I0316 12:51:46.665760 55708 solver.cpp:258]     Train net output #0: loss = 0.039391 (* 1 = 0.039391 loss)
I0316 12:51:46.665771 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000258332 (* 1 = 0.000258332 loss)
I0316 12:51:46.665776 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0706004 (* 1 = -0.0706004 loss)
I0316 12:51:46.665782 55708 sgd_solver.cpp:112] Iteration 33600, lr = 0.0001
I0316 12:51:54.628394 55708 solver.cpp:239] Iteration 33700 (12.5586 iter/s, 7.96267s/100 iters), loss = -0.0547934
I0316 12:51:54.628450 55708 solver.cpp:258]     Train net output #0: loss = 0.0209884 (* 1 = 0.0209884 loss)
I0316 12:51:54.628459 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000326775 (* 1 = 0.000326775 loss)
I0316 12:51:54.628465 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0761087 (* 1 = -0.0761087 loss)
I0316 12:51:54.628473 55708 sgd_solver.cpp:112] Iteration 33700, lr = 0.0001
I0316 12:52:02.579289 55708 solver.cpp:239] Iteration 33800 (12.5772 iter/s, 7.95088s/100 iters), loss = -0.0642193
I0316 12:52:02.579335 55708 solver.cpp:258]     Train net output #0: loss = 0.0125318 (* 1 = 0.0125318 loss)
I0316 12:52:02.579342 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000214612 (* 1 = 0.000214612 loss)
I0316 12:52:02.579349 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0769658 (* 1 = -0.0769658 loss)
I0316 12:52:02.579355 55708 sgd_solver.cpp:112] Iteration 33800, lr = 0.0001
I0316 12:52:10.523336 55708 solver.cpp:239] Iteration 33900 (12.5881 iter/s, 7.94403s/100 iters), loss = -0.0627956
I0316 12:52:10.523386 55708 solver.cpp:258]     Train net output #0: loss = 0.0129002 (* 1 = 0.0129002 loss)
I0316 12:52:10.523392 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000280158 (* 1 = 0.000280158 loss)
I0316 12:52:10.523398 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0759761 (* 1 = -0.0759761 loss)
I0316 12:52:10.523403 55708 sgd_solver.cpp:112] Iteration 33900, lr = 0.0001
I0316 12:52:18.388547 55708 solver.cpp:351] Iteration 34000, Testing net (#0)
I0316 12:52:23.331522 55708 solver.cpp:418]     Test net output #0: loss = 0.450872 (* 1 = 0.450872 loss)
I0316 12:52:23.331552 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000271478 (* 1 = 0.000271478 loss)
I0316 12:52:23.331557 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0741872 (* 1 = -0.0741872 loss)
I0316 12:52:23.331562 55708 solver.cpp:418]     Test net output #3: top-1 = 0.868594
I0316 12:52:23.331565 55708 solver.cpp:418]     Test net output #4: top-5 = 0.993125
I0316 12:52:23.409281 55708 solver.cpp:239] Iteration 34000 (7.76037 iter/s, 12.886s/100 iters), loss = -0.0720108
I0316 12:52:23.409312 55708 solver.cpp:258]     Train net output #0: loss = 0.00577956 (* 1 = 0.00577956 loss)
I0316 12:52:23.409319 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000266997 (* 1 = 0.000266997 loss)
I0316 12:52:23.409324 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0780575 (* 1 = -0.0780575 loss)
I0316 12:52:23.409332 55708 sgd_solver.cpp:112] Iteration 34000, lr = 0.0001
I0316 12:52:31.351013 55708 solver.cpp:239] Iteration 34100 (12.5917 iter/s, 7.94173s/100 iters), loss = -0.0625018
I0316 12:52:31.351070 55708 solver.cpp:258]     Train net output #0: loss = 0.0148807 (* 1 = 0.0148807 loss)
I0316 12:52:31.351079 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000294915 (* 1 = 0.000294915 loss)
I0316 12:52:31.351087 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0776775 (* 1 = -0.0776775 loss)
I0316 12:52:31.351092 55708 sgd_solver.cpp:112] Iteration 34100, lr = 0.0001
I0316 12:52:39.294431 55708 solver.cpp:239] Iteration 34200 (12.5891 iter/s, 7.9434s/100 iters), loss = -0.0665892
I0316 12:52:39.294474 55708 solver.cpp:258]     Train net output #0: loss = 0.0114127 (* 1 = 0.0114127 loss)
I0316 12:52:39.294482 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000337198 (* 1 = 0.000337198 loss)
I0316 12:52:39.294487 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0783392 (* 1 = -0.0783392 loss)
I0316 12:52:39.294492 55708 sgd_solver.cpp:112] Iteration 34200, lr = 0.0001
I0316 12:52:47.238802 55708 solver.cpp:239] Iteration 34300 (12.5875 iter/s, 7.94436s/100 iters), loss = -0.0691938
I0316 12:52:47.238850 55708 solver.cpp:258]     Train net output #0: loss = 0.00892486 (* 1 = 0.00892486 loss)
I0316 12:52:47.238857 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000324518 (* 1 = 0.000324518 loss)
I0316 12:52:47.238862 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0784433 (* 1 = -0.0784433 loss)
I0316 12:52:47.238867 55708 sgd_solver.cpp:112] Iteration 34300, lr = 0.0001
I0316 12:52:52.800758 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:52:55.181352 55708 solver.cpp:239] Iteration 34400 (12.5904 iter/s, 7.94254s/100 iters), loss = -0.0584962
I0316 12:52:55.181396 55708 solver.cpp:258]     Train net output #0: loss = 0.0206785 (* 1 = 0.0206785 loss)
I0316 12:52:55.181401 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000285526 (* 1 = 0.000285526 loss)
I0316 12:52:55.181408 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0794603 (* 1 = -0.0794603 loss)
I0316 12:52:55.181413 55708 sgd_solver.cpp:112] Iteration 34400, lr = 0.0001
I0316 12:53:03.126572 55708 solver.cpp:239] Iteration 34500 (12.5862 iter/s, 7.94522s/100 iters), loss = -0.0681467
I0316 12:53:03.126621 55708 solver.cpp:258]     Train net output #0: loss = 0.0117791 (* 1 = 0.0117791 loss)
I0316 12:53:03.126628 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000299238 (* 1 = 0.000299238 loss)
I0316 12:53:03.126634 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0802251 (* 1 = -0.0802251 loss)
I0316 12:53:03.126639 55708 sgd_solver.cpp:112] Iteration 34500, lr = 0.0001
I0316 12:53:11.075142 55708 solver.cpp:239] Iteration 34600 (12.5809 iter/s, 7.94856s/100 iters), loss = -0.0449036
I0316 12:53:11.075196 55708 solver.cpp:258]     Train net output #0: loss = 0.031586 (* 1 = 0.031586 loss)
I0316 12:53:11.075202 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000257844 (* 1 = 0.000257844 loss)
I0316 12:53:11.075207 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0767476 (* 1 = -0.0767476 loss)
I0316 12:53:11.075212 55708 sgd_solver.cpp:112] Iteration 34600, lr = 0.0001
I0316 12:53:19.017976 55708 solver.cpp:239] Iteration 34700 (12.59 iter/s, 7.94282s/100 iters), loss = -0.0731644
I0316 12:53:19.018016 55708 solver.cpp:258]     Train net output #0: loss = 0.00975811 (* 1 = 0.00975811 loss)
I0316 12:53:19.018023 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000288117 (* 1 = 0.000288117 loss)
I0316 12:53:19.018028 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0832107 (* 1 = -0.0832107 loss)
I0316 12:53:19.018034 55708 sgd_solver.cpp:112] Iteration 34700, lr = 0.0001
I0316 12:53:26.963121 55708 solver.cpp:239] Iteration 34800 (12.5863 iter/s, 7.94514s/100 iters), loss = -0.0667281
I0316 12:53:26.963471 55708 solver.cpp:258]     Train net output #0: loss = 0.0101565 (* 1 = 0.0101565 loss)
I0316 12:53:26.963480 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000315169 (* 1 = 0.000315169 loss)
I0316 12:53:26.963486 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0771999 (* 1 = -0.0771999 loss)
I0316 12:53:26.963491 55708 sgd_solver.cpp:112] Iteration 34800, lr = 0.0001
I0316 12:53:34.903849 55708 solver.cpp:239] Iteration 34900 (12.5938 iter/s, 7.94042s/100 iters), loss = -0.0632837
I0316 12:53:34.903890 55708 solver.cpp:258]     Train net output #0: loss = 0.0120208 (* 1 = 0.0120208 loss)
I0316 12:53:34.903898 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000306175 (* 1 = 0.000306175 loss)
I0316 12:53:34.903903 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0756108 (* 1 = -0.0756108 loss)
I0316 12:53:34.903908 55708 sgd_solver.cpp:112] Iteration 34900, lr = 0.0001
I0316 12:53:42.769218 55708 solver.cpp:351] Iteration 35000, Testing net (#0)
I0316 12:53:44.524037 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:53:47.711452 55708 solver.cpp:418]     Test net output #0: loss = 0.465074 (* 1 = 0.465074 loss)
I0316 12:53:47.711477 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000266375 (* 1 = 0.000266375 loss)
I0316 12:53:47.711483 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0738794 (* 1 = -0.0738794 loss)
I0316 12:53:47.711488 55708 solver.cpp:418]     Test net output #3: top-1 = 0.867031
I0316 12:53:47.711493 55708 solver.cpp:418]     Test net output #4: top-5 = 0.993594
I0316 12:53:47.789508 55708 solver.cpp:239] Iteration 35000 (7.76054 iter/s, 12.8857s/100 iters), loss = -0.0529424
I0316 12:53:47.789544 55708 solver.cpp:258]     Train net output #0: loss = 0.0249435 (* 1 = 0.0249435 loss)
I0316 12:53:47.789552 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00026007 (* 1 = 0.00026007 loss)
I0316 12:53:47.789557 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.078146 (* 1 = -0.078146 loss)
I0316 12:53:47.789563 55708 sgd_solver.cpp:112] Iteration 35000, lr = 0.0001
I0316 12:53:55.732324 55708 solver.cpp:239] Iteration 35100 (12.59 iter/s, 7.94282s/100 iters), loss = -0.0560535
I0316 12:53:55.732368 55708 solver.cpp:258]     Train net output #0: loss = 0.0211714 (* 1 = 0.0211714 loss)
I0316 12:53:55.732375 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000198069 (* 1 = 0.000198069 loss)
I0316 12:53:55.732398 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.077423 (* 1 = -0.077423 loss)
I0316 12:53:55.732403 55708 sgd_solver.cpp:112] Iteration 35100, lr = 0.0001
I0316 12:54:03.675776 55708 solver.cpp:239] Iteration 35200 (12.589 iter/s, 7.94345s/100 iters), loss = -0.066353
I0316 12:54:03.676059 55708 solver.cpp:258]     Train net output #0: loss = 0.0115501 (* 1 = 0.0115501 loss)
I0316 12:54:03.676067 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000227353 (* 1 = 0.000227353 loss)
I0316 12:54:03.676074 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0781306 (* 1 = -0.0781306 loss)
I0316 12:54:03.676079 55708 sgd_solver.cpp:112] Iteration 35200, lr = 0.0001
I0316 12:54:11.619987 55708 solver.cpp:239] Iteration 35300 (12.5882 iter/s, 7.94396s/100 iters), loss = -0.0567404
I0316 12:54:11.620033 55708 solver.cpp:258]     Train net output #0: loss = 0.0195755 (* 1 = 0.0195755 loss)
I0316 12:54:11.620039 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000335199 (* 1 = 0.000335199 loss)
I0316 12:54:11.620064 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0766512 (* 1 = -0.0766512 loss)
I0316 12:54:11.620069 55708 sgd_solver.cpp:112] Iteration 35300, lr = 0.0001
I0316 12:54:19.562599 55708 solver.cpp:239] Iteration 35400 (12.5903 iter/s, 7.94261s/100 iters), loss = -0.0562811
I0316 12:54:19.562641 55708 solver.cpp:258]     Train net output #0: loss = 0.0195708 (* 1 = 0.0195708 loss)
I0316 12:54:19.562649 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000275309 (* 1 = 0.000275309 loss)
I0316 12:54:19.562670 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0761274 (* 1 = -0.0761274 loss)
I0316 12:54:19.562675 55708 sgd_solver.cpp:112] Iteration 35400, lr = 0.0001
I0316 12:54:27.505800 55708 solver.cpp:239] Iteration 35500 (12.5894 iter/s, 7.94319s/100 iters), loss = -0.0336784
I0316 12:54:27.505851 55708 solver.cpp:258]     Train net output #0: loss = 0.0410497 (* 1 = 0.0410497 loss)
I0316 12:54:27.505857 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000274655 (* 1 = 0.000274655 loss)
I0316 12:54:27.505862 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0750029 (* 1 = -0.0750029 loss)
I0316 12:54:27.505867 55708 sgd_solver.cpp:112] Iteration 35500, lr = 0.0001
I0316 12:54:35.449065 55708 solver.cpp:239] Iteration 35600 (12.5893 iter/s, 7.94326s/100 iters), loss = -0.0475203
I0316 12:54:35.449369 55708 solver.cpp:258]     Train net output #0: loss = 0.029103 (* 1 = 0.029103 loss)
I0316 12:54:35.449378 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000335409 (* 1 = 0.000335409 loss)
I0316 12:54:35.449383 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0769588 (* 1 = -0.0769588 loss)
I0316 12:54:35.449389 55708 sgd_solver.cpp:112] Iteration 35600, lr = 0.0001
I0316 12:54:43.391058 55708 solver.cpp:239] Iteration 35700 (12.5917 iter/s, 7.94173s/100 iters), loss = -0.0425874
I0316 12:54:43.391098 55708 solver.cpp:258]     Train net output #0: loss = 0.0287595 (* 1 = 0.0287595 loss)
I0316 12:54:43.391105 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000290776 (* 1 = 0.000290776 loss)
I0316 12:54:43.391111 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0716378 (* 1 = -0.0716378 loss)
I0316 12:54:43.391132 55708 sgd_solver.cpp:112] Iteration 35700, lr = 0.0001
I0316 12:54:51.331250 55708 solver.cpp:239] Iteration 35800 (12.5942 iter/s, 7.94018s/100 iters), loss = -0.0704141
I0316 12:54:51.331296 55708 solver.cpp:258]     Train net output #0: loss = 0.00843276 (* 1 = 0.00843276 loss)
I0316 12:54:51.331305 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000233464 (* 1 = 0.000233464 loss)
I0316 12:54:51.331310 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0790804 (* 1 = -0.0790804 loss)
I0316 12:54:51.331315 55708 sgd_solver.cpp:112] Iteration 35800, lr = 0.0001
I0316 12:54:59.272994 55708 solver.cpp:239] Iteration 35900 (12.5917 iter/s, 7.94174s/100 iters), loss = -0.0595027
I0316 12:54:59.273036 55708 solver.cpp:258]     Train net output #0: loss = 0.0142917 (* 1 = 0.0142917 loss)
I0316 12:54:59.273043 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000262916 (* 1 = 0.000262916 loss)
I0316 12:54:59.273048 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0740574 (* 1 = -0.0740574 loss)
I0316 12:54:59.273053 55708 sgd_solver.cpp:112] Iteration 35900, lr = 0.0001
I0316 12:55:01.895881 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:55:07.137694 55708 solver.cpp:351] Iteration 36000, Testing net (#0)
I0316 12:55:11.681605 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:55:12.076089 55708 solver.cpp:418]     Test net output #0: loss = 0.45026 (* 1 = 0.45026 loss)
I0316 12:55:12.076112 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000269735 (* 1 = 0.000269735 loss)
I0316 12:55:12.076117 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.074138 (* 1 = -0.074138 loss)
I0316 12:55:12.076122 55708 solver.cpp:418]     Test net output #3: top-1 = 0.869375
I0316 12:55:12.076126 55708 solver.cpp:418]     Test net output #4: top-5 = 0.992813
I0316 12:55:12.153967 55708 solver.cpp:239] Iteration 36000 (7.76337 iter/s, 12.881s/100 iters), loss = -0.055426
I0316 12:55:12.153995 55708 solver.cpp:258]     Train net output #0: loss = 0.0192963 (* 1 = 0.0192963 loss)
I0316 12:55:12.154001 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000306291 (* 1 = 0.000306291 loss)
I0316 12:55:12.154006 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0750287 (* 1 = -0.0750287 loss)
I0316 12:55:12.154029 55708 sgd_solver.cpp:112] Iteration 36000, lr = 0.0001
I0316 12:55:20.093358 55708 solver.cpp:239] Iteration 36100 (12.5955 iter/s, 7.93935s/100 iters), loss = -0.06721
I0316 12:55:20.093402 55708 solver.cpp:258]     Train net output #0: loss = 0.0123096 (* 1 = 0.0123096 loss)
I0316 12:55:20.093410 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000212552 (* 1 = 0.000212552 loss)
I0316 12:55:20.093416 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0797322 (* 1 = -0.0797322 loss)
I0316 12:55:20.093421 55708 sgd_solver.cpp:112] Iteration 36100, lr = 0.0001
I0316 12:55:28.037894 55708 solver.cpp:239] Iteration 36200 (12.5874 iter/s, 7.94447s/100 iters), loss = -0.067666
I0316 12:55:28.037947 55708 solver.cpp:258]     Train net output #0: loss = 0.0103134 (* 1 = 0.0103134 loss)
I0316 12:55:28.037955 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00031401 (* 1 = 0.00031401 loss)
I0316 12:55:28.037976 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0782935 (* 1 = -0.0782935 loss)
I0316 12:55:28.037982 55708 sgd_solver.cpp:112] Iteration 36200, lr = 0.0001
I0316 12:55:35.980769 55708 solver.cpp:239] Iteration 36300 (12.59 iter/s, 7.94281s/100 iters), loss = -0.0422852
I0316 12:55:35.980814 55708 solver.cpp:258]     Train net output #0: loss = 0.0326371 (* 1 = 0.0326371 loss)
I0316 12:55:35.980820 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000321433 (* 1 = 0.000321433 loss)
I0316 12:55:35.980826 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0752438 (* 1 = -0.0752438 loss)
I0316 12:55:35.980831 55708 sgd_solver.cpp:112] Iteration 36300, lr = 0.0001
I0316 12:55:43.925079 55708 solver.cpp:239] Iteration 36400 (12.5877 iter/s, 7.94425s/100 iters), loss = -0.0439322
I0316 12:55:43.925408 55708 solver.cpp:258]     Train net output #0: loss = 0.0349762 (* 1 = 0.0349762 loss)
I0316 12:55:43.925417 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000272501 (* 1 = 0.000272501 loss)
I0316 12:55:43.925422 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0791809 (* 1 = -0.0791809 loss)
I0316 12:55:43.925428 55708 sgd_solver.cpp:112] Iteration 36400, lr = 0.0001
I0316 12:55:51.868681 55708 solver.cpp:239] Iteration 36500 (12.5893 iter/s, 7.94326s/100 iters), loss = -0.0509136
I0316 12:55:51.868733 55708 solver.cpp:258]     Train net output #0: loss = 0.0274299 (* 1 = 0.0274299 loss)
I0316 12:55:51.868741 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000299116 (* 1 = 0.000299116 loss)
I0316 12:55:51.868746 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0786427 (* 1 = -0.0786427 loss)
I0316 12:55:51.868752 55708 sgd_solver.cpp:112] Iteration 36500, lr = 0.0001
I0316 12:55:59.811568 55708 solver.cpp:239] Iteration 36600 (12.59 iter/s, 7.94282s/100 iters), loss = -0.0575669
I0316 12:55:59.811606 55708 solver.cpp:258]     Train net output #0: loss = 0.0188094 (* 1 = 0.0188094 loss)
I0316 12:55:59.811614 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000281435 (* 1 = 0.000281435 loss)
I0316 12:55:59.811635 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0766579 (* 1 = -0.0766579 loss)
I0316 12:55:59.811640 55708 sgd_solver.cpp:112] Iteration 36600, lr = 0.0001
I0316 12:56:07.755846 55708 solver.cpp:239] Iteration 36700 (12.5878 iter/s, 7.94422s/100 iters), loss = -0.0645531
I0316 12:56:07.755894 55708 solver.cpp:258]     Train net output #0: loss = 0.0163657 (* 1 = 0.0163657 loss)
I0316 12:56:07.755900 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000360939 (* 1 = 0.000360939 loss)
I0316 12:56:07.755923 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0812799 (* 1 = -0.0812799 loss)
I0316 12:56:07.755928 55708 sgd_solver.cpp:112] Iteration 36700, lr = 0.0001
I0316 12:56:15.701367 55708 solver.cpp:239] Iteration 36800 (12.5858 iter/s, 7.94546s/100 iters), loss = -0.0195342
I0316 12:56:15.708914 55708 solver.cpp:258]     Train net output #0: loss = 0.058186 (* 1 = 0.058186 loss)
I0316 12:56:15.708923 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000328132 (* 1 = 0.000328132 loss)
I0316 12:56:15.708930 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0780484 (* 1 = -0.0780484 loss)
I0316 12:56:15.708948 55708 sgd_solver.cpp:112] Iteration 36800, lr = 0.0001
I0316 12:56:23.652269 55708 solver.cpp:239] Iteration 36900 (12.5891 iter/s, 7.94335s/100 iters), loss = -0.0391102
I0316 12:56:23.652314 55708 solver.cpp:258]     Train net output #0: loss = 0.0400061 (* 1 = 0.0400061 loss)
I0316 12:56:23.652321 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000284973 (* 1 = 0.000284973 loss)
I0316 12:56:23.652343 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0794013 (* 1 = -0.0794013 loss)
I0316 12:56:23.652348 55708 sgd_solver.cpp:112] Iteration 36900, lr = 0.0001
I0316 12:56:31.518952 55708 solver.cpp:351] Iteration 37000, Testing net (#0)
I0316 12:56:36.460727 55708 solver.cpp:418]     Test net output #0: loss = 0.446188 (* 1 = 0.446188 loss)
I0316 12:56:36.460755 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.00027226 (* 1 = 0.00027226 loss)
I0316 12:56:36.460762 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.074489 (* 1 = -0.074489 loss)
I0316 12:56:36.460765 55708 solver.cpp:418]     Test net output #3: top-1 = 0.870156
I0316 12:56:36.460769 55708 solver.cpp:418]     Test net output #4: top-5 = 0.992656
I0316 12:56:36.538761 55708 solver.cpp:239] Iteration 37000 (7.7601 iter/s, 12.8864s/100 iters), loss = -0.0707183
I0316 12:56:36.538792 55708 solver.cpp:258]     Train net output #0: loss = 0.0116509 (* 1 = 0.0116509 loss)
I0316 12:56:36.538798 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000301398 (* 1 = 0.000301398 loss)
I0316 12:56:36.538803 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0826707 (* 1 = -0.0826707 loss)
I0316 12:56:36.538826 55708 sgd_solver.cpp:112] Iteration 37000, lr = 0.0001
I0316 12:56:44.480931 55708 solver.cpp:239] Iteration 37100 (12.5911 iter/s, 7.94213s/100 iters), loss = -0.0464209
I0316 12:56:44.480971 55708 solver.cpp:258]     Train net output #0: loss = 0.029732 (* 1 = 0.029732 loss)
I0316 12:56:44.480980 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000253595 (* 1 = 0.000253595 loss)
I0316 12:56:44.480986 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0764066 (* 1 = -0.0764066 loss)
I0316 12:56:44.480991 55708 sgd_solver.cpp:112] Iteration 37100, lr = 0.0001
I0316 12:56:52.424456 55708 solver.cpp:239] Iteration 37200 (12.589 iter/s, 7.94347s/100 iters), loss = -0.0695377
I0316 12:56:52.424687 55708 solver.cpp:258]     Train net output #0: loss = 0.0111198 (* 1 = 0.0111198 loss)
I0316 12:56:52.424696 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000310299 (* 1 = 0.000310299 loss)
I0316 12:56:52.424702 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0809679 (* 1 = -0.0809679 loss)
I0316 12:56:52.424706 55708 sgd_solver.cpp:112] Iteration 37200, lr = 0.0001
I0316 12:57:00.367170 55708 solver.cpp:239] Iteration 37300 (12.5905 iter/s, 7.94247s/100 iters), loss = -0.0651362
I0316 12:57:00.367215 55708 solver.cpp:258]     Train net output #0: loss = 0.0121865 (* 1 = 0.0121865 loss)
I0316 12:57:00.367223 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000396574 (* 1 = 0.000396574 loss)
I0316 12:57:00.367228 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0777193 (* 1 = -0.0777193 loss)
I0316 12:57:00.367233 55708 sgd_solver.cpp:112] Iteration 37300, lr = 0.0001
I0316 12:57:08.315222 55708 solver.cpp:239] Iteration 37400 (12.5818 iter/s, 7.94799s/100 iters), loss = -0.0527439
I0316 12:57:08.315271 55708 solver.cpp:258]     Train net output #0: loss = 0.0202152 (* 1 = 0.0202152 loss)
I0316 12:57:08.315279 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000235315 (* 1 = 0.000235315 loss)
I0316 12:57:08.315284 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0731945 (* 1 = -0.0731945 loss)
I0316 12:57:08.315289 55708 sgd_solver.cpp:112] Iteration 37400, lr = 0.0001
I0316 12:57:15.865147 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:57:16.259605 55708 solver.cpp:239] Iteration 37500 (12.5876 iter/s, 7.94432s/100 iters), loss = -0.051447
I0316 12:57:16.259652 55708 solver.cpp:258]     Train net output #0: loss = 0.0229103 (* 1 = 0.0229103 loss)
I0316 12:57:16.259660 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000307085 (* 1 = 0.000307085 loss)
I0316 12:57:16.259666 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0746645 (* 1 = -0.0746645 loss)
I0316 12:57:16.259672 55708 sgd_solver.cpp:112] Iteration 37500, lr = 0.0001
I0316 12:57:24.202642 55708 solver.cpp:239] Iteration 37600 (12.5897 iter/s, 7.94298s/100 iters), loss = -0.0567257
I0316 12:57:24.202972 55708 solver.cpp:258]     Train net output #0: loss = 0.023559 (* 1 = 0.023559 loss)
I0316 12:57:24.202980 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000362412 (* 1 = 0.000362412 loss)
I0316 12:57:24.202986 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0806473 (* 1 = -0.0806473 loss)
I0316 12:57:24.202991 55708 sgd_solver.cpp:112] Iteration 37600, lr = 0.0001
I0316 12:57:32.147039 55708 solver.cpp:239] Iteration 37700 (12.588 iter/s, 7.94405s/100 iters), loss = -0.0678128
I0316 12:57:32.147091 55708 solver.cpp:258]     Train net output #0: loss = 0.0116736 (* 1 = 0.0116736 loss)
I0316 12:57:32.147099 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000348582 (* 1 = 0.000348582 loss)
I0316 12:57:32.147104 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0798351 (* 1 = -0.0798351 loss)
I0316 12:57:32.147111 55708 sgd_solver.cpp:112] Iteration 37700, lr = 0.0001
I0316 12:57:40.091276 55708 solver.cpp:239] Iteration 37800 (12.5878 iter/s, 7.94418s/100 iters), loss = -0.0435699
I0316 12:57:40.091325 55708 solver.cpp:258]     Train net output #0: loss = 0.032821 (* 1 = 0.032821 loss)
I0316 12:57:40.091331 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000264887 (* 1 = 0.000264887 loss)
I0316 12:57:40.091353 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0766559 (* 1 = -0.0766559 loss)
I0316 12:57:40.091358 55708 sgd_solver.cpp:112] Iteration 37800, lr = 0.0001
I0316 12:57:48.034659 55708 solver.cpp:239] Iteration 37900 (12.5892 iter/s, 7.94332s/100 iters), loss = -0.0273483
I0316 12:57:48.034709 55708 solver.cpp:258]     Train net output #0: loss = 0.0470092 (* 1 = 0.0470092 loss)
I0316 12:57:48.034718 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000224625 (* 1 = 0.000224625 loss)
I0316 12:57:48.034723 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0745822 (* 1 = -0.0745822 loss)
I0316 12:57:48.034729 55708 sgd_solver.cpp:112] Iteration 37900, lr = 0.0001
I0316 12:57:55.902292 55708 solver.cpp:351] Iteration 38000, Testing net (#0)
I0316 12:57:58.275941 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:58:00.842640 55708 solver.cpp:418]     Test net output #0: loss = 0.468207 (* 1 = 0.468207 loss)
I0316 12:58:00.842669 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000268768 (* 1 = 0.000268768 loss)
I0316 12:58:00.842676 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0741345 (* 1 = -0.0741345 loss)
I0316 12:58:00.842681 55708 solver.cpp:418]     Test net output #3: top-1 = 0.863594
I0316 12:58:00.842685 55708 solver.cpp:418]     Test net output #4: top-5 = 0.9925
I0316 12:58:00.920533 55708 solver.cpp:239] Iteration 38000 (7.76047 iter/s, 12.8858s/100 iters), loss = -0.0630791
I0316 12:58:00.920578 55708 solver.cpp:258]     Train net output #0: loss = 0.0118795 (* 1 = 0.0118795 loss)
I0316 12:58:00.920585 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00029536 (* 1 = 0.00029536 loss)
I0316 12:58:00.920590 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0752541 (* 1 = -0.0752541 loss)
I0316 12:58:00.920598 55708 sgd_solver.cpp:112] Iteration 38000, lr = 0.0001
I0316 12:58:08.860641 55708 solver.cpp:239] Iteration 38100 (12.5944 iter/s, 7.94005s/100 iters), loss = -0.0647481
I0316 12:58:08.860692 55708 solver.cpp:258]     Train net output #0: loss = 0.0131937 (* 1 = 0.0131937 loss)
I0316 12:58:08.860698 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000247747 (* 1 = 0.000247747 loss)
I0316 12:58:08.860703 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0781896 (* 1 = -0.0781896 loss)
I0316 12:58:08.860708 55708 sgd_solver.cpp:112] Iteration 38100, lr = 0.0001
I0316 12:58:16.804833 55708 solver.cpp:239] Iteration 38200 (12.5879 iter/s, 7.94413s/100 iters), loss = -0.0683616
I0316 12:58:16.804879 55708 solver.cpp:258]     Train net output #0: loss = 0.0102872 (* 1 = 0.0102872 loss)
I0316 12:58:16.804885 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000317792 (* 1 = 0.000317792 loss)
I0316 12:58:16.804891 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0789667 (* 1 = -0.0789667 loss)
I0316 12:58:16.804898 55708 sgd_solver.cpp:112] Iteration 38200, lr = 0.0001
I0316 12:58:24.748049 55708 solver.cpp:239] Iteration 38300 (12.5894 iter/s, 7.94316s/100 iters), loss = -0.0677289
I0316 12:58:24.748088 55708 solver.cpp:258]     Train net output #0: loss = 0.0114925 (* 1 = 0.0114925 loss)
I0316 12:58:24.748095 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000294009 (* 1 = 0.000294009 loss)
I0316 12:58:24.748118 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0795155 (* 1 = -0.0795155 loss)
I0316 12:58:24.748123 55708 sgd_solver.cpp:112] Iteration 38300, lr = 0.0001
I0316 12:58:32.693528 55708 solver.cpp:239] Iteration 38400 (12.5859 iter/s, 7.94543s/100 iters), loss = -0.0313231
I0316 12:58:32.693846 55708 solver.cpp:258]     Train net output #0: loss = 0.0457769 (* 1 = 0.0457769 loss)
I0316 12:58:32.693856 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000347326 (* 1 = 0.000347326 loss)
I0316 12:58:32.693862 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0774474 (* 1 = -0.0774474 loss)
I0316 12:58:32.693867 55708 sgd_solver.cpp:112] Iteration 38400, lr = 0.0001
I0316 12:58:40.639535 55708 solver.cpp:239] Iteration 38500 (12.5854 iter/s, 7.94569s/100 iters), loss = -0.0281417
I0316 12:58:40.639576 55708 solver.cpp:258]     Train net output #0: loss = 0.0502973 (* 1 = 0.0502973 loss)
I0316 12:58:40.639583 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00032894 (* 1 = 0.00032894 loss)
I0316 12:58:40.639604 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.078768 (* 1 = -0.078768 loss)
I0316 12:58:40.639609 55708 sgd_solver.cpp:112] Iteration 38500, lr = 0.0001
I0316 12:58:48.585317 55708 solver.cpp:239] Iteration 38600 (12.5854 iter/s, 7.94572s/100 iters), loss = -0.0706681
I0316 12:58:48.585367 55708 solver.cpp:258]     Train net output #0: loss = 0.00839277 (* 1 = 0.00839277 loss)
I0316 12:58:48.585374 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000327273 (* 1 = 0.000327273 loss)
I0316 12:58:48.585381 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0793883 (* 1 = -0.0793883 loss)
I0316 12:58:48.585386 55708 sgd_solver.cpp:112] Iteration 38600, lr = 0.0001
I0316 12:58:56.528273 55708 solver.cpp:239] Iteration 38700 (12.5899 iter/s, 7.9429s/100 iters), loss = -0.070248
I0316 12:58:56.528314 55708 solver.cpp:258]     Train net output #0: loss = 0.0100035 (* 1 = 0.0100035 loss)
I0316 12:58:56.528321 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000318657 (* 1 = 0.000318657 loss)
I0316 12:58:56.528344 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0805702 (* 1 = -0.0805702 loss)
I0316 12:58:56.528348 55708 sgd_solver.cpp:112] Iteration 38700, lr = 0.0001
I0316 12:59:04.474879 55708 solver.cpp:239] Iteration 38800 (12.5841 iter/s, 7.94656s/100 iters), loss = -0.00404082
I0316 12:59:04.475965 55708 solver.cpp:258]     Train net output #0: loss = 0.070879 (* 1 = 0.070879 loss)
I0316 12:59:04.475975 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000175163 (* 1 = 0.000175163 loss)
I0316 12:59:04.475991 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0750951 (* 1 = -0.0750951 loss)
I0316 12:59:04.475996 55708 sgd_solver.cpp:112] Iteration 38800, lr = 0.0001
I0316 12:59:12.417695 55708 solver.cpp:239] Iteration 38900 (12.5917 iter/s, 7.94172s/100 iters), loss = -0.07015
I0316 12:59:12.417764 55708 solver.cpp:258]     Train net output #0: loss = 0.00958595 (* 1 = 0.00958595 loss)
I0316 12:59:12.417775 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000249367 (* 1 = 0.000249367 loss)
I0316 12:59:12.417784 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0799854 (* 1 = -0.0799854 loss)
I0316 12:59:12.417793 55708 sgd_solver.cpp:112] Iteration 38900, lr = 0.0001
I0316 12:59:20.281932 55708 solver.cpp:351] Iteration 39000, Testing net (#0)
I0316 12:59:25.225220 55708 solver.cpp:418]     Test net output #0: loss = 0.447195 (* 1 = 0.447195 loss)
I0316 12:59:25.225246 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000273563 (* 1 = 0.000273563 loss)
I0316 12:59:25.225252 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0746956 (* 1 = -0.0746956 loss)
I0316 12:59:25.225258 55708 solver.cpp:418]     Test net output #3: top-1 = 0.871094
I0316 12:59:25.225262 55708 solver.cpp:418]     Test net output #4: top-5 = 0.992656
I0316 12:59:25.303082 55708 solver.cpp:239] Iteration 39000 (7.76076 iter/s, 12.8853s/100 iters), loss = -0.0649583
I0316 12:59:25.303112 55708 solver.cpp:258]     Train net output #0: loss = 0.0123763 (* 1 = 0.0123763 loss)
I0316 12:59:25.303118 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000278974 (* 1 = 0.000278974 loss)
I0316 12:59:25.303123 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0776137 (* 1 = -0.0776137 loss)
I0316 12:59:25.303129 55708 sgd_solver.cpp:112] Iteration 39000, lr = 0.0001
I0316 12:59:29.913324 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 12:59:33.245312 55708 solver.cpp:239] Iteration 39100 (12.591 iter/s, 7.9422s/100 iters), loss = -0.070663
I0316 12:59:33.245359 55708 solver.cpp:258]     Train net output #0: loss = 0.00944819 (* 1 = 0.00944819 loss)
I0316 12:59:33.245366 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000317835 (* 1 = 0.000317835 loss)
I0316 12:59:33.245371 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0804291 (* 1 = -0.0804291 loss)
I0316 12:59:33.245378 55708 sgd_solver.cpp:112] Iteration 39100, lr = 0.0001
I0316 12:59:41.189173 55708 solver.cpp:239] Iteration 39200 (12.5884 iter/s, 7.94381s/100 iters), loss = 0.00425065
I0316 12:59:41.189625 55708 solver.cpp:258]     Train net output #0: loss = 0.0743842 (* 1 = 0.0743842 loss)
I0316 12:59:41.189633 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.0002869 (* 1 = 0.0002869 loss)
I0316 12:59:41.189640 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0704206 (* 1 = -0.0704206 loss)
I0316 12:59:41.189646 55708 sgd_solver.cpp:112] Iteration 39200, lr = 0.0001
I0316 12:59:49.134855 55708 solver.cpp:239] Iteration 39300 (12.5862 iter/s, 7.94524s/100 iters), loss = -0.0548411
I0316 12:59:49.134904 55708 solver.cpp:258]     Train net output #0: loss = 0.0244135 (* 1 = 0.0244135 loss)
I0316 12:59:49.134912 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000267081 (* 1 = 0.000267081 loss)
I0316 12:59:49.134917 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0795218 (* 1 = -0.0795218 loss)
I0316 12:59:49.134922 55708 sgd_solver.cpp:112] Iteration 39300, lr = 0.0001
I0316 12:59:57.077301 55708 solver.cpp:239] Iteration 39400 (12.5907 iter/s, 7.9424s/100 iters), loss = -0.00608477
I0316 12:59:57.077344 55708 solver.cpp:258]     Train net output #0: loss = 0.0641555 (* 1 = 0.0641555 loss)
I0316 12:59:57.077351 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000285541 (* 1 = 0.000285541 loss)
I0316 12:59:57.077356 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0705259 (* 1 = -0.0705259 loss)
I0316 12:59:57.077361 55708 sgd_solver.cpp:112] Iteration 39400, lr = 0.0001
I0316 13:00:05.019579 55708 solver.cpp:239] Iteration 39500 (12.5909 iter/s, 7.94224s/100 iters), loss = -0.0705279
I0316 13:00:05.019620 55708 solver.cpp:258]     Train net output #0: loss = 0.00860237 (* 1 = 0.00860237 loss)
I0316 13:00:05.019627 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000232452 (* 1 = 0.000232452 loss)
I0316 13:00:05.019632 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0793629 (* 1 = -0.0793629 loss)
I0316 13:00:05.019654 55708 sgd_solver.cpp:112] Iteration 39500, lr = 0.0001
I0316 13:00:12.963482 55708 solver.cpp:239] Iteration 39600 (12.5884 iter/s, 7.94385s/100 iters), loss = -0.0755561
I0316 13:00:12.963819 55708 solver.cpp:258]     Train net output #0: loss = 0.00670262 (* 1 = 0.00670262 loss)
I0316 13:00:12.963829 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000308837 (* 1 = 0.000308837 loss)
I0316 13:00:12.963835 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0825677 (* 1 = -0.0825677 loss)
I0316 13:00:12.963841 55708 sgd_solver.cpp:112] Iteration 39600, lr = 0.0001
I0316 13:00:20.911409 55708 solver.cpp:239] Iteration 39700 (12.5824 iter/s, 7.94759s/100 iters), loss = 0.00269701
I0316 13:00:20.911458 55708 solver.cpp:258]     Train net output #0: loss = 0.0767521 (* 1 = 0.0767521 loss)
I0316 13:00:20.911466 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000250206 (* 1 = 0.000250206 loss)
I0316 13:00:20.911471 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0743054 (* 1 = -0.0743054 loss)
I0316 13:00:20.911478 55708 sgd_solver.cpp:112] Iteration 39700, lr = 0.0001
I0316 13:00:28.856945 55708 solver.cpp:239] Iteration 39800 (12.5858 iter/s, 7.94549s/100 iters), loss = -0.0614171
I0316 13:00:28.856997 55708 solver.cpp:258]     Train net output #0: loss = 0.0186894 (* 1 = 0.0186894 loss)
I0316 13:00:28.857004 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000310794 (* 1 = 0.000310794 loss)
I0316 13:00:28.857012 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0804174 (* 1 = -0.0804174 loss)
I0316 13:00:28.857017 55708 sgd_solver.cpp:112] Iteration 39800, lr = 0.0001
I0316 13:00:36.799636 55708 solver.cpp:239] Iteration 39900 (12.5903 iter/s, 7.94265s/100 iters), loss = -0.0528044
I0316 13:00:36.799677 55708 solver.cpp:258]     Train net output #0: loss = 0.0246664 (* 1 = 0.0246664 loss)
I0316 13:00:36.799683 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000256202 (* 1 = 0.000256202 loss)
I0316 13:00:36.799688 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0777271 (* 1 = -0.0777271 loss)
I0316 13:00:36.799695 55708 sgd_solver.cpp:112] Iteration 39900, lr = 0.0001
I0316 13:00:44.663762 55708 solver.cpp:351] Iteration 40000, Testing net (#0)
I0316 13:00:44.886620 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 13:00:49.605114 55708 solver.cpp:418]     Test net output #0: loss = 0.443828 (* 1 = 0.443828 loss)
I0316 13:00:49.605142 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000276304 (* 1 = 0.000276304 loss)
I0316 13:00:49.605149 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0748212 (* 1 = -0.0748212 loss)
I0316 13:00:49.605154 55708 solver.cpp:418]     Test net output #3: top-1 = 0.870625
I0316 13:00:49.605157 55708 solver.cpp:418]     Test net output #4: top-5 = 0.993438
I0316 13:00:49.683065 55708 solver.cpp:239] Iteration 40000 (7.76192 iter/s, 12.8834s/100 iters), loss = -0.062519
I0316 13:00:49.683094 55708 solver.cpp:258]     Train net output #0: loss = 0.0192282 (* 1 = 0.0192282 loss)
I0316 13:00:49.683099 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000311778 (* 1 = 0.000311778 loss)
I0316 13:00:49.683105 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0820592 (* 1 = -0.0820592 loss)
I0316 13:00:49.683115 55708 sgd_solver.cpp:112] Iteration 40000, lr = 0.0001
I0316 13:00:57.626464 55708 solver.cpp:239] Iteration 40100 (12.5891 iter/s, 7.94338s/100 iters), loss = -0.0502389
I0316 13:00:57.626507 55708 solver.cpp:258]     Train net output #0: loss = 0.0254329 (* 1 = 0.0254329 loss)
I0316 13:00:57.626514 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000303647 (* 1 = 0.000303647 loss)
I0316 13:00:57.626521 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0759755 (* 1 = -0.0759755 loss)
I0316 13:00:57.626525 55708 sgd_solver.cpp:112] Iteration 40100, lr = 0.0001
I0316 13:01:05.574187 55708 solver.cpp:239] Iteration 40200 (12.5823 iter/s, 7.94768s/100 iters), loss = -0.0728672
I0316 13:01:05.574236 55708 solver.cpp:258]     Train net output #0: loss = 0.00857583 (* 1 = 0.00857583 loss)
I0316 13:01:05.574245 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000308575 (* 1 = 0.000308575 loss)
I0316 13:01:05.574251 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0817517 (* 1 = -0.0817517 loss)
I0316 13:01:05.574259 55708 sgd_solver.cpp:112] Iteration 40200, lr = 0.0001
I0316 13:01:13.524081 55708 solver.cpp:239] Iteration 40300 (12.5789 iter/s, 7.94985s/100 iters), loss = -0.0553727
I0316 13:01:13.524132 55708 solver.cpp:258]     Train net output #0: loss = 0.023824 (* 1 = 0.023824 loss)
I0316 13:01:13.524138 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000269592 (* 1 = 0.000269592 loss)
I0316 13:01:13.524144 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0794664 (* 1 = -0.0794664 loss)
I0316 13:01:13.524148 55708 sgd_solver.cpp:112] Iteration 40300, lr = 0.0001
I0316 13:01:21.467981 55708 solver.cpp:239] Iteration 40400 (12.5883 iter/s, 7.94386s/100 iters), loss = -0.0551604
I0316 13:01:21.468291 55708 solver.cpp:258]     Train net output #0: loss = 0.0168579 (* 1 = 0.0168579 loss)
I0316 13:01:21.468298 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000278792 (* 1 = 0.000278792 loss)
I0316 13:01:21.468304 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0722972 (* 1 = -0.0722972 loss)
I0316 13:01:21.468310 55708 sgd_solver.cpp:112] Iteration 40400, lr = 0.0001
I0316 13:01:29.417924 55708 solver.cpp:239] Iteration 40500 (12.5792 iter/s, 7.94964s/100 iters), loss = -0.0496642
I0316 13:01:29.417975 55708 solver.cpp:258]     Train net output #0: loss = 0.0275645 (* 1 = 0.0275645 loss)
I0316 13:01:29.417982 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000305482 (* 1 = 0.000305482 loss)
I0316 13:01:29.417989 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0775343 (* 1 = -0.0775343 loss)
I0316 13:01:29.417994 55708 sgd_solver.cpp:112] Iteration 40500, lr = 0.0001
I0316 13:01:37.364434 55708 solver.cpp:239] Iteration 40600 (12.5842 iter/s, 7.94647s/100 iters), loss = -0.049524
I0316 13:01:37.364477 55708 solver.cpp:258]     Train net output #0: loss = 0.0286033 (* 1 = 0.0286033 loss)
I0316 13:01:37.364485 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000217082 (* 1 = 0.000217082 loss)
I0316 13:01:37.364490 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0783445 (* 1 = -0.0783445 loss)
I0316 13:01:37.364495 55708 sgd_solver.cpp:112] Iteration 40600, lr = 0.0001
I0316 13:01:38.955875 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 13:01:45.309552 55708 solver.cpp:239] Iteration 40700 (12.5864 iter/s, 7.94509s/100 iters), loss = -0.0587115
I0316 13:01:45.309593 55708 solver.cpp:258]     Train net output #0: loss = 0.0204934 (* 1 = 0.0204934 loss)
I0316 13:01:45.309600 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000316388 (* 1 = 0.000316388 loss)
I0316 13:01:45.309607 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0795214 (* 1 = -0.0795214 loss)
I0316 13:01:45.309612 55708 sgd_solver.cpp:112] Iteration 40700, lr = 0.0001
I0316 13:01:53.252661 55708 solver.cpp:239] Iteration 40800 (12.5896 iter/s, 7.94307s/100 iters), loss = -0.0603571
I0316 13:01:53.253026 55708 solver.cpp:258]     Train net output #0: loss = 0.0159774 (* 1 = 0.0159774 loss)
I0316 13:01:53.253036 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000310007 (* 1 = 0.000310007 loss)
I0316 13:01:53.253043 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0766447 (* 1 = -0.0766447 loss)
I0316 13:01:53.253049 55708 sgd_solver.cpp:112] Iteration 40800, lr = 0.0001
I0316 13:02:01.197739 55708 solver.cpp:239] Iteration 40900 (12.587 iter/s, 7.94473s/100 iters), loss = -0.0649064
I0316 13:02:01.197785 55708 solver.cpp:258]     Train net output #0: loss = 0.0138558 (* 1 = 0.0138558 loss)
I0316 13:02:01.197793 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000339448 (* 1 = 0.000339448 loss)
I0316 13:02:01.197798 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0791017 (* 1 = -0.0791017 loss)
I0316 13:02:01.197804 55708 sgd_solver.cpp:112] Iteration 40900, lr = 0.0001
I0316 13:02:09.067055 55708 solver.cpp:351] Iteration 41000, Testing net (#0)
I0316 13:02:12.055168 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 13:02:14.008766 55708 solver.cpp:418]     Test net output #0: loss = 0.453437 (* 1 = 0.453437 loss)
I0316 13:02:14.008797 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000272087 (* 1 = 0.000272087 loss)
I0316 13:02:14.008806 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0744813 (* 1 = -0.0744813 loss)
I0316 13:02:14.008813 55708 solver.cpp:418]     Test net output #3: top-1 = 0.868594
I0316 13:02:14.008819 55708 solver.cpp:418]     Test net output #4: top-5 = 0.993125
I0316 13:02:14.086688 55708 solver.cpp:239] Iteration 41000 (7.7586 iter/s, 12.8889s/100 iters), loss = -0.0703973
I0316 13:02:14.086726 55708 solver.cpp:258]     Train net output #0: loss = 0.00688554 (* 1 = 0.00688554 loss)
I0316 13:02:14.086736 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000278531 (* 1 = 0.000278531 loss)
I0316 13:02:14.086745 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0775615 (* 1 = -0.0775615 loss)
I0316 13:02:14.086756 55708 sgd_solver.cpp:112] Iteration 41000, lr = 0.0001
I0316 13:02:22.030279 55708 solver.cpp:239] Iteration 41100 (12.5888 iter/s, 7.94356s/100 iters), loss = -0.0784949
I0316 13:02:22.030323 55708 solver.cpp:258]     Train net output #0: loss = 0.00483903 (* 1 = 0.00483903 loss)
I0316 13:02:22.030333 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00026531 (* 1 = 0.00026531 loss)
I0316 13:02:22.030340 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0835994 (* 1 = -0.0835994 loss)
I0316 13:02:22.030346 55708 sgd_solver.cpp:112] Iteration 41100, lr = 0.0001
I0316 13:02:29.978029 55708 solver.cpp:239] Iteration 41200 (12.5822 iter/s, 7.94771s/100 iters), loss = -0.0636795
I0316 13:02:29.978382 55708 solver.cpp:258]     Train net output #0: loss = 0.0114684 (* 1 = 0.0114684 loss)
I0316 13:02:29.978394 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000245609 (* 1 = 0.000245609 loss)
I0316 13:02:29.978401 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0753937 (* 1 = -0.0753937 loss)
I0316 13:02:29.978410 55708 sgd_solver.cpp:112] Iteration 41200, lr = 0.0001
I0316 13:02:37.924167 55708 solver.cpp:239] Iteration 41300 (12.5853 iter/s, 7.9458s/100 iters), loss = -0.0649365
I0316 13:02:37.924212 55708 solver.cpp:258]     Train net output #0: loss = 0.0117493 (* 1 = 0.0117493 loss)
I0316 13:02:37.924221 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000264731 (* 1 = 0.000264731 loss)
I0316 13:02:37.924230 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0769507 (* 1 = -0.0769507 loss)
I0316 13:02:37.924237 55708 sgd_solver.cpp:112] Iteration 41300, lr = 0.0001
I0316 13:02:45.868955 55708 solver.cpp:239] Iteration 41400 (12.5869 iter/s, 7.94476s/100 iters), loss = -0.0678058
I0316 13:02:45.869000 55708 solver.cpp:258]     Train net output #0: loss = 0.0114854 (* 1 = 0.0114854 loss)
I0316 13:02:45.869011 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000291271 (* 1 = 0.000291271 loss)
I0316 13:02:45.869019 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0795826 (* 1 = -0.0795826 loss)
I0316 13:02:45.869025 55708 sgd_solver.cpp:112] Iteration 41400, lr = 0.0001
I0316 13:02:53.814515 55708 solver.cpp:239] Iteration 41500 (12.5857 iter/s, 7.94552s/100 iters), loss = -0.0140908
I0316 13:02:53.814571 55708 solver.cpp:258]     Train net output #0: loss = 0.0658785 (* 1 = 0.0658785 loss)
I0316 13:02:53.814584 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000295348 (* 1 = 0.000295348 loss)
I0316 13:02:53.814594 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0802648 (* 1 = -0.0802648 loss)
I0316 13:02:53.814604 55708 sgd_solver.cpp:112] Iteration 41500, lr = 0.0001
I0316 13:03:01.757495 55708 solver.cpp:239] Iteration 41600 (12.5898 iter/s, 7.94294s/100 iters), loss = -0.0666533
I0316 13:03:01.757774 55708 solver.cpp:258]     Train net output #0: loss = 0.010686 (* 1 = 0.010686 loss)
I0316 13:03:01.757784 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000292451 (* 1 = 0.000292451 loss)
I0316 13:03:01.757792 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0776319 (* 1 = -0.0776319 loss)
I0316 13:03:01.757800 55708 sgd_solver.cpp:112] Iteration 41600, lr = 0.0001
I0316 13:03:09.703181 55708 solver.cpp:239] Iteration 41700 (12.5859 iter/s, 7.94541s/100 iters), loss = -0.0651328
I0316 13:03:09.703238 55708 solver.cpp:258]     Train net output #0: loss = 0.0175111 (* 1 = 0.0175111 loss)
I0316 13:03:09.703248 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00032757 (* 1 = 0.00032757 loss)
I0316 13:03:09.703258 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0829717 (* 1 = -0.0829717 loss)
I0316 13:03:09.703266 55708 sgd_solver.cpp:112] Iteration 41700, lr = 0.0001
I0316 13:03:17.650527 55708 solver.cpp:239] Iteration 41800 (12.5829 iter/s, 7.94731s/100 iters), loss = -0.0626256
I0316 13:03:17.650570 55708 solver.cpp:258]     Train net output #0: loss = 0.0149199 (* 1 = 0.0149199 loss)
I0316 13:03:17.650580 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000258613 (* 1 = 0.000258613 loss)
I0316 13:03:17.650588 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0778042 (* 1 = -0.0778042 loss)
I0316 13:03:17.650594 55708 sgd_solver.cpp:112] Iteration 41800, lr = 0.0001
I0316 13:03:25.595654 55708 solver.cpp:239] Iteration 41900 (12.5864 iter/s, 7.9451s/100 iters), loss = -0.0724972
I0316 13:03:25.595702 55708 solver.cpp:258]     Train net output #0: loss = 0.00827151 (* 1 = 0.00827151 loss)
I0316 13:03:25.595711 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000338702 (* 1 = 0.000338702 loss)
I0316 13:03:25.595719 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0811075 (* 1 = -0.0811075 loss)
I0316 13:03:25.595726 55708 sgd_solver.cpp:112] Iteration 41900, lr = 0.0001
I0316 13:03:33.463112 55708 solver.cpp:351] Iteration 42000, Testing net (#0)
I0316 13:03:38.406199 55708 solver.cpp:418]     Test net output #0: loss = 0.47013 (* 1 = 0.47013 loss)
I0316 13:03:38.406229 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000273141 (* 1 = 0.000273141 loss)
I0316 13:03:38.406236 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.07513 (* 1 = -0.07513 loss)
I0316 13:03:38.406244 55708 solver.cpp:418]     Test net output #3: top-1 = 0.866406
I0316 13:03:38.406248 55708 solver.cpp:418]     Test net output #4: top-5 = 0.991562
I0316 13:03:38.484045 55708 solver.cpp:239] Iteration 42000 (7.75893 iter/s, 12.8884s/100 iters), loss = -0.0693648
I0316 13:03:38.484081 55708 solver.cpp:258]     Train net output #0: loss = 0.00865497 (* 1 = 0.00865497 loss)
I0316 13:03:38.484091 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000316173 (* 1 = 0.000316173 loss)
I0316 13:03:38.484100 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0783361 (* 1 = -0.0783361 loss)
I0316 13:03:38.484112 55708 sgd_solver.cpp:112] Iteration 42000, lr = 0.0001
I0316 13:03:46.428730 55708 solver.cpp:239] Iteration 42100 (12.5871 iter/s, 7.94466s/100 iters), loss = -0.0609278
I0316 13:03:46.428774 55708 solver.cpp:258]     Train net output #0: loss = 0.0160268 (* 1 = 0.0160268 loss)
I0316 13:03:46.428783 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000261789 (* 1 = 0.000261789 loss)
I0316 13:03:46.428791 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0772165 (* 1 = -0.0772165 loss)
I0316 13:03:46.428797 55708 sgd_solver.cpp:112] Iteration 42100, lr = 0.0001
I0316 13:03:53.024996 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 13:03:54.373770 55708 solver.cpp:239] Iteration 42200 (12.5865 iter/s, 7.94501s/100 iters), loss = -0.0539197
I0316 13:03:54.373821 55708 solver.cpp:258]     Train net output #0: loss = 0.0230595 (* 1 = 0.0230595 loss)
I0316 13:03:54.373829 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000278323 (* 1 = 0.000278323 loss)
I0316 13:03:54.373838 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0772577 (* 1 = -0.0772577 loss)
I0316 13:03:54.373844 55708 sgd_solver.cpp:112] Iteration 42200, lr = 0.0001
I0316 13:04:02.315917 55708 solver.cpp:239] Iteration 42300 (12.5911 iter/s, 7.94211s/100 iters), loss = -0.0677142
I0316 13:04:02.315961 55708 solver.cpp:258]     Train net output #0: loss = 0.0114473 (* 1 = 0.0114473 loss)
I0316 13:04:02.315971 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000283511 (* 1 = 0.000283511 loss)
I0316 13:04:02.315979 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0794451 (* 1 = -0.0794451 loss)
I0316 13:04:02.315985 55708 sgd_solver.cpp:112] Iteration 42300, lr = 0.0001
I0316 13:04:10.261668 55708 solver.cpp:239] Iteration 42400 (12.5854 iter/s, 7.9457s/100 iters), loss = -0.0611262
I0316 13:04:10.262022 55708 solver.cpp:258]     Train net output #0: loss = 0.0159601 (* 1 = 0.0159601 loss)
I0316 13:04:10.262030 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000278311 (* 1 = 0.000278311 loss)
I0316 13:04:10.262037 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0773647 (* 1 = -0.0773647 loss)
I0316 13:04:10.262041 55708 sgd_solver.cpp:112] Iteration 42400, lr = 0.0001
I0316 13:04:18.208921 55708 solver.cpp:239] Iteration 42500 (12.5835 iter/s, 7.94692s/100 iters), loss = -0.0538593
I0316 13:04:18.208964 55708 solver.cpp:258]     Train net output #0: loss = 0.0268074 (* 1 = 0.0268074 loss)
I0316 13:04:18.208971 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000262287 (* 1 = 0.000262287 loss)
I0316 13:04:18.208977 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0809292 (* 1 = -0.0809292 loss)
I0316 13:04:18.208983 55708 sgd_solver.cpp:112] Iteration 42500, lr = 0.0001
I0316 13:04:26.153415 55708 solver.cpp:239] Iteration 42600 (12.5874 iter/s, 7.94446s/100 iters), loss = -0.0742304
I0316 13:04:26.153457 55708 solver.cpp:258]     Train net output #0: loss = 0.00531732 (* 1 = 0.00531732 loss)
I0316 13:04:26.153465 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000289915 (* 1 = 0.000289915 loss)
I0316 13:04:26.153471 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0798378 (* 1 = -0.0798378 loss)
I0316 13:04:26.153477 55708 sgd_solver.cpp:112] Iteration 42600, lr = 0.0001
I0316 13:04:34.104890 55708 solver.cpp:239] Iteration 42700 (12.5763 iter/s, 7.95143s/100 iters), loss = -0.0674184
I0316 13:04:34.104949 55708 solver.cpp:258]     Train net output #0: loss = 0.0132657 (* 1 = 0.0132657 loss)
I0316 13:04:34.104959 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000337871 (* 1 = 0.000337871 loss)
I0316 13:04:34.104964 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0810221 (* 1 = -0.0810221 loss)
I0316 13:04:34.104971 55708 sgd_solver.cpp:112] Iteration 42700, lr = 0.0001
I0316 13:04:42.099403 55708 solver.cpp:239] Iteration 42800 (12.5087 iter/s, 7.99447s/100 iters), loss = -0.0532516
I0316 13:04:42.099767 55708 solver.cpp:258]     Train net output #0: loss = 0.0249857 (* 1 = 0.0249857 loss)
I0316 13:04:42.099776 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000236142 (* 1 = 0.000236142 loss)
I0316 13:04:42.099783 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0784736 (* 1 = -0.0784736 loss)
I0316 13:04:42.099789 55708 sgd_solver.cpp:112] Iteration 42800, lr = 0.0001
I0316 13:04:50.063797 55708 solver.cpp:239] Iteration 42900 (12.5564 iter/s, 7.96404s/100 iters), loss = -0.0774294
I0316 13:04:50.063859 55708 solver.cpp:258]     Train net output #0: loss = 0.00454144 (* 1 = 0.00454144 loss)
I0316 13:04:50.063867 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000335874 (* 1 = 0.000335874 loss)
I0316 13:04:50.063890 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0823068 (* 1 = -0.0823068 loss)
I0316 13:04:50.063896 55708 sgd_solver.cpp:112] Iteration 42900, lr = 0.0001
I0316 13:04:57.951521 55708 solver.cpp:351] Iteration 43000, Testing net (#0)
I0316 13:04:58.796955 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 13:05:02.900483 55708 solver.cpp:418]     Test net output #0: loss = 0.44766 (* 1 = 0.44766 loss)
I0316 13:05:02.900511 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000276627 (* 1 = 0.000276627 loss)
I0316 13:05:02.900517 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0750584 (* 1 = -0.0750584 loss)
I0316 13:05:02.900522 55708 solver.cpp:418]     Test net output #3: top-1 = 0.871094
I0316 13:05:02.900527 55708 solver.cpp:418]     Test net output #4: top-5 = 0.99375
I0316 13:05:02.978377 55708 solver.cpp:239] Iteration 43000 (7.7432 iter/s, 12.9146s/100 iters), loss = -0.0641261
I0316 13:05:02.978411 55708 solver.cpp:258]     Train net output #0: loss = 0.0108418 (* 1 = 0.0108418 loss)
I0316 13:05:02.978421 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000299145 (* 1 = 0.000299145 loss)
I0316 13:05:02.978430 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0752672 (* 1 = -0.0752672 loss)
I0316 13:05:02.978440 55708 sgd_solver.cpp:112] Iteration 43000, lr = 0.0001
I0316 13:05:10.921854 55708 solver.cpp:239] Iteration 43100 (12.589 iter/s, 7.94345s/100 iters), loss = -0.0666705
I0316 13:05:10.921901 55708 solver.cpp:258]     Train net output #0: loss = 0.0096995 (* 1 = 0.0096995 loss)
I0316 13:05:10.921908 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000305812 (* 1 = 0.000305812 loss)
I0316 13:05:10.921916 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.076676 (* 1 = -0.076676 loss)
I0316 13:05:10.921921 55708 sgd_solver.cpp:112] Iteration 43100, lr = 0.0001
I0316 13:05:18.865113 55708 solver.cpp:239] Iteration 43200 (12.5893 iter/s, 7.94322s/100 iters), loss = -0.0428876
I0316 13:05:18.865442 55708 solver.cpp:258]     Train net output #0: loss = 0.0337869 (* 1 = 0.0337869 loss)
I0316 13:05:18.865451 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00032264 (* 1 = 0.00032264 loss)
I0316 13:05:18.865458 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0769973 (* 1 = -0.0769973 loss)
I0316 13:05:18.865463 55708 sgd_solver.cpp:112] Iteration 43200, lr = 0.0001
I0316 13:05:26.808619 55708 solver.cpp:239] Iteration 43300 (12.5894 iter/s, 7.94319s/100 iters), loss = -0.07351
I0316 13:05:26.808661 55708 solver.cpp:258]     Train net output #0: loss = 0.00584921 (* 1 = 0.00584921 loss)
I0316 13:05:26.808668 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00026748 (* 1 = 0.00026748 loss)
I0316 13:05:26.808673 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0796268 (* 1 = -0.0796268 loss)
I0316 13:05:26.808678 55708 sgd_solver.cpp:112] Iteration 43300, lr = 0.0001
I0316 13:05:34.752722 55708 solver.cpp:239] Iteration 43400 (12.588 iter/s, 7.94406s/100 iters), loss = -0.0645768
I0316 13:05:34.752766 55708 solver.cpp:258]     Train net output #0: loss = 0.011722 (* 1 = 0.011722 loss)
I0316 13:05:34.752774 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000217533 (* 1 = 0.000217533 loss)
I0316 13:05:34.752779 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0765165 (* 1 = -0.0765165 loss)
I0316 13:05:34.752784 55708 sgd_solver.cpp:112] Iteration 43400, lr = 0.0001
I0316 13:05:42.697219 55708 solver.cpp:239] Iteration 43500 (12.5874 iter/s, 7.94447s/100 iters), loss = -0.0683007
I0316 13:05:42.697260 55708 solver.cpp:258]     Train net output #0: loss = 0.0125084 (* 1 = 0.0125084 loss)
I0316 13:05:42.697268 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000327074 (* 1 = 0.000327074 loss)
I0316 13:05:42.697274 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0811363 (* 1 = -0.0811363 loss)
I0316 13:05:42.697278 55708 sgd_solver.cpp:112] Iteration 43500, lr = 0.0001
I0316 13:05:50.641218 55708 solver.cpp:239] Iteration 43600 (12.5882 iter/s, 7.94396s/100 iters), loss = -0.0608771
I0316 13:05:50.641499 55708 solver.cpp:258]     Train net output #0: loss = 0.0154045 (* 1 = 0.0154045 loss)
I0316 13:05:50.641507 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000228085 (* 1 = 0.000228085 loss)
I0316 13:05:50.641513 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0765098 (* 1 = -0.0765098 loss)
I0316 13:05:50.641518 55708 sgd_solver.cpp:112] Iteration 43600, lr = 0.0001
I0316 13:05:58.584641 55708 solver.cpp:239] Iteration 43700 (12.5894 iter/s, 7.94316s/100 iters), loss = -0.0637596
I0316 13:05:58.584683 55708 solver.cpp:258]     Train net output #0: loss = 0.0153935 (* 1 = 0.0153935 loss)
I0316 13:05:58.584690 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000295676 (* 1 = 0.000295676 loss)
I0316 13:05:58.584697 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0794489 (* 1 = -0.0794489 loss)
I0316 13:05:58.584702 55708 sgd_solver.cpp:112] Iteration 43700, lr = 0.0001
I0316 13:06:02.163228 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 13:06:06.529260 55708 solver.cpp:239] Iteration 43800 (12.5872 iter/s, 7.94459s/100 iters), loss = -0.065993
I0316 13:06:06.529302 55708 solver.cpp:258]     Train net output #0: loss = 0.0106312 (* 1 = 0.0106312 loss)
I0316 13:06:06.529309 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000269278 (* 1 = 0.000269278 loss)
I0316 13:06:06.529315 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0768936 (* 1 = -0.0768936 loss)
I0316 13:06:06.529320 55708 sgd_solver.cpp:112] Iteration 43800, lr = 0.0001
I0316 13:06:14.473716 55708 solver.cpp:239] Iteration 43900 (12.5875 iter/s, 7.94442s/100 iters), loss = -0.0657327
I0316 13:06:14.473762 55708 solver.cpp:258]     Train net output #0: loss = 0.0135456 (* 1 = 0.0135456 loss)
I0316 13:06:14.473769 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000216281 (* 1 = 0.000216281 loss)
I0316 13:06:14.473790 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0794947 (* 1 = -0.0794947 loss)
I0316 13:06:14.473795 55708 sgd_solver.cpp:112] Iteration 43900, lr = 0.0001
I0316 13:06:22.338512 55708 solver.cpp:351] Iteration 44000, Testing net (#0)
I0316 13:06:25.945081 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 13:06:27.279434 55708 solver.cpp:418]     Test net output #0: loss = 0.457782 (* 1 = 0.457782 loss)
I0316 13:06:27.279459 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000272728 (* 1 = 0.000272728 loss)
I0316 13:06:27.279465 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0748685 (* 1 = -0.0748685 loss)
I0316 13:06:27.279470 55708 solver.cpp:418]     Test net output #3: top-1 = 0.867188
I0316 13:06:27.279474 55708 solver.cpp:418]     Test net output #4: top-5 = 0.992969
I0316 13:06:27.357352 55708 solver.cpp:239] Iteration 44000 (7.76179 iter/s, 12.8836s/100 iters), loss = -0.0686548
I0316 13:06:27.357383 55708 solver.cpp:258]     Train net output #0: loss = 0.0101816 (* 1 = 0.0101816 loss)
I0316 13:06:27.357389 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000238654 (* 1 = 0.000238654 loss)
I0316 13:06:27.357394 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0790752 (* 1 = -0.0790752 loss)
I0316 13:06:27.357400 55708 sgd_solver.cpp:112] Iteration 44000, lr = 0.0001
I0316 13:06:35.303539 55708 solver.cpp:239] Iteration 44100 (12.5847 iter/s, 7.94616s/100 iters), loss = -0.0382027
I0316 13:06:35.303588 55708 solver.cpp:258]     Train net output #0: loss = 0.0367582 (* 1 = 0.0367582 loss)
I0316 13:06:35.303596 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00025245 (* 1 = 0.00025245 loss)
I0316 13:06:35.303601 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0752134 (* 1 = -0.0752134 loss)
I0316 13:06:35.303606 55708 sgd_solver.cpp:112] Iteration 44100, lr = 0.0001
I0316 13:06:43.248306 55708 solver.cpp:239] Iteration 44200 (12.587 iter/s, 7.94473s/100 iters), loss = -0.0765182
I0316 13:06:43.248347 55708 solver.cpp:258]     Train net output #0: loss = 0.00596837 (* 1 = 0.00596837 loss)
I0316 13:06:43.248353 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000271688 (* 1 = 0.000271688 loss)
I0316 13:06:43.248359 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0827584 (* 1 = -0.0827584 loss)
I0316 13:06:43.248368 55708 sgd_solver.cpp:112] Iteration 44200, lr = 0.0001
I0316 13:06:51.192708 55708 solver.cpp:239] Iteration 44300 (12.5875 iter/s, 7.94436s/100 iters), loss = -0.0668085
I0316 13:06:51.192757 55708 solver.cpp:258]     Train net output #0: loss = 0.00865462 (* 1 = 0.00865462 loss)
I0316 13:06:51.192764 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000359416 (* 1 = 0.000359416 loss)
I0316 13:06:51.192770 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0758226 (* 1 = -0.0758226 loss)
I0316 13:06:51.192775 55708 sgd_solver.cpp:112] Iteration 44300, lr = 0.0001
I0316 13:06:59.134176 55708 solver.cpp:239] Iteration 44400 (12.5922 iter/s, 7.94143s/100 iters), loss = -0.0684389
I0316 13:06:59.134486 55708 solver.cpp:258]     Train net output #0: loss = 0.0123736 (* 1 = 0.0123736 loss)
I0316 13:06:59.134495 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000398197 (* 1 = 0.000398197 loss)
I0316 13:06:59.134501 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0812108 (* 1 = -0.0812108 loss)
I0316 13:06:59.134506 55708 sgd_solver.cpp:112] Iteration 44400, lr = 0.0001
I0316 13:07:07.077448 55708 solver.cpp:239] Iteration 44500 (12.5897 iter/s, 7.94297s/100 iters), loss = -0.0644183
I0316 13:07:07.077497 55708 solver.cpp:258]     Train net output #0: loss = 0.01889 (* 1 = 0.01889 loss)
I0316 13:07:07.077504 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000301234 (* 1 = 0.000301234 loss)
I0316 13:07:07.077510 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0836096 (* 1 = -0.0836096 loss)
I0316 13:07:07.077517 55708 sgd_solver.cpp:112] Iteration 44500, lr = 0.0001
I0316 13:07:15.021975 55708 solver.cpp:239] Iteration 44600 (12.5873 iter/s, 7.94449s/100 iters), loss = -0.0527829
I0316 13:07:15.022034 55708 solver.cpp:258]     Train net output #0: loss = 0.0247364 (* 1 = 0.0247364 loss)
I0316 13:07:15.022042 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000290334 (* 1 = 0.000290334 loss)
I0316 13:07:15.022063 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0778097 (* 1 = -0.0778097 loss)
I0316 13:07:15.022068 55708 sgd_solver.cpp:112] Iteration 44600, lr = 0.0001
I0316 13:07:22.965456 55708 solver.cpp:239] Iteration 44700 (12.589 iter/s, 7.94344s/100 iters), loss = -0.0673705
I0316 13:07:22.965497 55708 solver.cpp:258]     Train net output #0: loss = 0.0112422 (* 1 = 0.0112422 loss)
I0316 13:07:22.965504 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000256972 (* 1 = 0.000256972 loss)
I0316 13:07:22.965512 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0788698 (* 1 = -0.0788698 loss)
I0316 13:07:22.965517 55708 sgd_solver.cpp:112] Iteration 44700, lr = 0.0001
I0316 13:07:30.910820 55708 solver.cpp:239] Iteration 44800 (12.586 iter/s, 7.94532s/100 iters), loss = -0.0502974
I0316 13:07:30.911159 55708 solver.cpp:258]     Train net output #0: loss = 0.0243878 (* 1 = 0.0243878 loss)
I0316 13:07:30.911168 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000305107 (* 1 = 0.000305107 loss)
I0316 13:07:30.911173 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0749905 (* 1 = -0.0749905 loss)
I0316 13:07:30.911178 55708 sgd_solver.cpp:112] Iteration 44800, lr = 0.0001
I0316 13:07:38.854171 55708 solver.cpp:239] Iteration 44900 (12.5897 iter/s, 7.94303s/100 iters), loss = -0.0657597
I0316 13:07:38.854214 55708 solver.cpp:258]     Train net output #0: loss = 0.012667 (* 1 = 0.012667 loss)
I0316 13:07:38.854221 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00024784 (* 1 = 0.00024784 loss)
I0316 13:07:38.854226 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0786746 (* 1 = -0.0786746 loss)
I0316 13:07:38.854231 55708 sgd_solver.cpp:112] Iteration 44900, lr = 0.0001
I0316 13:07:46.720939 55708 solver.cpp:351] Iteration 45000, Testing net (#0)
I0316 13:07:51.663763 55708 solver.cpp:418]     Test net output #0: loss = 0.459539 (* 1 = 0.459539 loss)
I0316 13:07:51.663791 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000276776 (* 1 = 0.000276776 loss)
I0316 13:07:51.663797 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0754877 (* 1 = -0.0754877 loss)
I0316 13:07:51.663802 55708 solver.cpp:418]     Test net output #3: top-1 = 0.870625
I0316 13:07:51.663806 55708 solver.cpp:418]     Test net output #4: top-5 = 0.992656
I0316 13:07:51.741776 55708 solver.cpp:239] Iteration 45000 (7.7594 iter/s, 12.8876s/100 iters), loss = -0.058942
I0316 13:07:51.741808 55708 solver.cpp:258]     Train net output #0: loss = 0.0165868 (* 1 = 0.0165868 loss)
I0316 13:07:51.741816 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000233687 (* 1 = 0.000233687 loss)
I0316 13:07:51.741820 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0757625 (* 1 = -0.0757625 loss)
I0316 13:07:51.741827 55708 sgd_solver.cpp:112] Iteration 45000, lr = 0.0001
I0316 13:07:59.684460 55708 solver.cpp:239] Iteration 45100 (12.5902 iter/s, 7.94267s/100 iters), loss = -0.0568716
I0316 13:07:59.684502 55708 solver.cpp:258]     Train net output #0: loss = 0.0189149 (* 1 = 0.0189149 loss)
I0316 13:07:59.684509 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000327495 (* 1 = 0.000327495 loss)
I0316 13:07:59.684514 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0761142 (* 1 = -0.0761142 loss)
I0316 13:07:59.684520 55708 sgd_solver.cpp:112] Iteration 45100, lr = 0.0001
I0316 13:08:07.627146 55708 solver.cpp:239] Iteration 45200 (12.5902 iter/s, 7.94266s/100 iters), loss = -0.0588073
I0316 13:08:07.627413 55708 solver.cpp:258]     Train net output #0: loss = 0.0205076 (* 1 = 0.0205076 loss)
I0316 13:08:07.627421 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000262949 (* 1 = 0.000262949 loss)
I0316 13:08:07.627426 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.079578 (* 1 = -0.079578 loss)
I0316 13:08:07.627432 55708 sgd_solver.cpp:112] Iteration 45200, lr = 0.0001
I0316 13:08:15.572588 55708 solver.cpp:239] Iteration 45300 (12.5862 iter/s, 7.94518s/100 iters), loss = -0.0615866
I0316 13:08:15.572636 55708 solver.cpp:258]     Train net output #0: loss = 0.0158657 (* 1 = 0.0158657 loss)
I0316 13:08:15.572643 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000292364 (* 1 = 0.000292364 loss)
I0316 13:08:15.572650 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0777447 (* 1 = -0.0777447 loss)
I0316 13:08:15.572655 55708 sgd_solver.cpp:112] Iteration 45300, lr = 0.0001
I0316 13:08:16.210896 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 13:08:23.516791 55708 solver.cpp:239] Iteration 45400 (12.5879 iter/s, 7.94417s/100 iters), loss = -0.0717222
I0316 13:08:23.516840 55708 solver.cpp:258]     Train net output #0: loss = 0.0104331 (* 1 = 0.0104331 loss)
I0316 13:08:23.516847 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00033353 (* 1 = 0.00033353 loss)
I0316 13:08:23.516852 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.082489 (* 1 = -0.082489 loss)
I0316 13:08:23.516858 55708 sgd_solver.cpp:112] Iteration 45400, lr = 0.0001
I0316 13:08:31.461735 55708 solver.cpp:239] Iteration 45500 (12.5867 iter/s, 7.9449s/100 iters), loss = -0.0705347
I0316 13:08:31.461802 55708 solver.cpp:258]     Train net output #0: loss = 0.00870154 (* 1 = 0.00870154 loss)
I0316 13:08:31.461808 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000275992 (* 1 = 0.000275992 loss)
I0316 13:08:31.461817 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0795124 (* 1 = -0.0795124 loss)
I0316 13:08:31.461829 55708 sgd_solver.cpp:112] Iteration 45500, lr = 0.0001
I0316 13:08:39.407524 55708 solver.cpp:239] Iteration 45600 (12.5854 iter/s, 7.94574s/100 iters), loss = -0.0324405
I0316 13:08:39.407824 55708 solver.cpp:258]     Train net output #0: loss = 0.0408873 (* 1 = 0.0408873 loss)
I0316 13:08:39.407836 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000227767 (* 1 = 0.000227767 loss)
I0316 13:08:39.407843 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0735557 (* 1 = -0.0735557 loss)
I0316 13:08:39.407847 55708 sgd_solver.cpp:112] Iteration 45600, lr = 0.0001
I0316 13:08:47.348754 55708 solver.cpp:239] Iteration 45700 (12.5929 iter/s, 7.94095s/100 iters), loss = -0.0764473
I0316 13:08:47.348794 55708 solver.cpp:258]     Train net output #0: loss = 0.00652665 (* 1 = 0.00652665 loss)
I0316 13:08:47.348803 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000253342 (* 1 = 0.000253342 loss)
I0316 13:08:47.348807 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0832274 (* 1 = -0.0832274 loss)
I0316 13:08:47.348812 55708 sgd_solver.cpp:112] Iteration 45700, lr = 0.0001
I0316 13:08:55.293802 55708 solver.cpp:239] Iteration 45800 (12.5865 iter/s, 7.94501s/100 iters), loss = -0.0647425
I0316 13:08:55.293848 55708 solver.cpp:258]     Train net output #0: loss = 0.0143595 (* 1 = 0.0143595 loss)
I0316 13:08:55.293855 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000288178 (* 1 = 0.000288178 loss)
I0316 13:08:55.293861 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0793903 (* 1 = -0.0793903 loss)
I0316 13:08:55.293865 55708 sgd_solver.cpp:112] Iteration 45800, lr = 0.0001
I0316 13:09:03.235349 55708 solver.cpp:239] Iteration 45900 (12.5921 iter/s, 7.94151s/100 iters), loss = -0.0713859
I0316 13:09:03.235389 55708 solver.cpp:258]     Train net output #0: loss = 0.0099022 (* 1 = 0.0099022 loss)
I0316 13:09:03.235395 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000207827 (* 1 = 0.000207827 loss)
I0316 13:09:03.235401 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0814961 (* 1 = -0.0814961 loss)
I0316 13:09:03.235422 55708 sgd_solver.cpp:112] Iteration 45900, lr = 0.0001
I0316 13:09:11.100816 55708 solver.cpp:351] Iteration 46000, Testing net (#0)
I0316 13:09:12.558687 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 13:09:16.044520 55708 solver.cpp:418]     Test net output #0: loss = 0.450886 (* 1 = 0.450886 loss)
I0316 13:09:16.044548 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000274764 (* 1 = 0.000274764 loss)
I0316 13:09:16.044554 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0753078 (* 1 = -0.0753078 loss)
I0316 13:09:16.044559 55708 solver.cpp:418]     Test net output #3: top-1 = 0.870781
I0316 13:09:16.044562 55708 solver.cpp:418]     Test net output #4: top-5 = 0.994062
I0316 13:09:16.122409 55708 solver.cpp:239] Iteration 46000 (7.75973 iter/s, 12.8871s/100 iters), loss = -0.0692287
I0316 13:09:16.122444 55708 solver.cpp:258]     Train net output #0: loss = 0.00995622 (* 1 = 0.00995622 loss)
I0316 13:09:16.122452 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000322294 (* 1 = 0.000322294 loss)
I0316 13:09:16.122457 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0795073 (* 1 = -0.0795073 loss)
I0316 13:09:16.122464 55708 sgd_solver.cpp:112] Iteration 46000, lr = 0.0001
I0316 13:09:24.069767 55708 solver.cpp:239] Iteration 46100 (12.5828 iter/s, 7.94734s/100 iters), loss = -0.0450174
I0316 13:09:24.069809 55708 solver.cpp:258]     Train net output #0: loss = 0.0283913 (* 1 = 0.0283913 loss)
I0316 13:09:24.069816 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000258864 (* 1 = 0.000258864 loss)
I0316 13:09:24.069823 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0736677 (* 1 = -0.0736677 loss)
I0316 13:09:24.069828 55708 sgd_solver.cpp:112] Iteration 46100, lr = 0.0001
I0316 13:09:32.019888 55708 solver.cpp:239] Iteration 46200 (12.5785 iter/s, 7.95008s/100 iters), loss = -0.0667345
I0316 13:09:32.019937 55708 solver.cpp:258]     Train net output #0: loss = 0.0115457 (* 1 = 0.0115457 loss)
I0316 13:09:32.019944 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000290529 (* 1 = 0.000290529 loss)
I0316 13:09:32.019950 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0785709 (* 1 = -0.0785709 loss)
I0316 13:09:32.019955 55708 sgd_solver.cpp:112] Iteration 46200, lr = 0.0001
I0316 13:09:39.961458 55708 solver.cpp:239] Iteration 46300 (12.592 iter/s, 7.94154s/100 iters), loss = -0.0429804
I0316 13:09:39.961503 55708 solver.cpp:258]     Train net output #0: loss = 0.0323443 (* 1 = 0.0323443 loss)
I0316 13:09:39.961510 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000291447 (* 1 = 0.000291447 loss)
I0316 13:09:39.961515 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0756163 (* 1 = -0.0756163 loss)
I0316 13:09:39.961520 55708 sgd_solver.cpp:112] Iteration 46300, lr = 0.0001
I0316 13:09:47.904182 55708 solver.cpp:239] Iteration 46400 (12.5902 iter/s, 7.94268s/100 iters), loss = -0.062724
I0316 13:09:47.904543 55708 solver.cpp:258]     Train net output #0: loss = 0.0139001 (* 1 = 0.0139001 loss)
I0316 13:09:47.904552 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000316572 (* 1 = 0.000316572 loss)
I0316 13:09:47.904558 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0769408 (* 1 = -0.0769408 loss)
I0316 13:09:47.904567 55708 sgd_solver.cpp:112] Iteration 46400, lr = 0.0001
I0316 13:09:55.845788 55708 solver.cpp:239] Iteration 46500 (12.5925 iter/s, 7.94126s/100 iters), loss = -0.0709126
I0316 13:09:55.845837 55708 solver.cpp:258]     Train net output #0: loss = 0.00663777 (* 1 = 0.00663777 loss)
I0316 13:09:55.845844 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000252207 (* 1 = 0.000252207 loss)
I0316 13:09:55.845867 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0778027 (* 1 = -0.0778027 loss)
I0316 13:09:55.845871 55708 sgd_solver.cpp:112] Iteration 46500, lr = 0.0001
I0316 13:10:03.788645 55708 solver.cpp:239] Iteration 46600 (12.59 iter/s, 7.94282s/100 iters), loss = -0.0686204
I0316 13:10:03.788684 55708 solver.cpp:258]     Train net output #0: loss = 0.0096582 (* 1 = 0.0096582 loss)
I0316 13:10:03.788692 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000357749 (* 1 = 0.000357749 loss)
I0316 13:10:03.788698 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0786364 (* 1 = -0.0786364 loss)
I0316 13:10:03.788703 55708 sgd_solver.cpp:112] Iteration 46600, lr = 0.0001
I0316 13:10:11.732173 55708 solver.cpp:239] Iteration 46700 (12.5889 iter/s, 7.9435s/100 iters), loss = -0.0687109
I0316 13:10:11.732223 55708 solver.cpp:258]     Train net output #0: loss = 0.00784987 (* 1 = 0.00784987 loss)
I0316 13:10:11.732229 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000340142 (* 1 = 0.000340142 loss)
I0316 13:10:11.732251 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0769011 (* 1 = -0.0769011 loss)
I0316 13:10:11.732256 55708 sgd_solver.cpp:112] Iteration 46700, lr = 0.0001
I0316 13:10:19.674190 55708 solver.cpp:239] Iteration 46800 (12.5913 iter/s, 7.94198s/100 iters), loss = -0.0689886
I0316 13:10:19.674499 55708 solver.cpp:258]     Train net output #0: loss = 0.00995959 (* 1 = 0.00995959 loss)
I0316 13:10:19.674507 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000302574 (* 1 = 0.000302574 loss)
I0316 13:10:19.674512 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0792509 (* 1 = -0.0792509 loss)
I0316 13:10:19.674518 55708 sgd_solver.cpp:112] Iteration 46800, lr = 0.0001
I0316 13:10:25.238479 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 13:10:27.620117 55708 solver.cpp:239] Iteration 46900 (12.5855 iter/s, 7.94564s/100 iters), loss = -0.0689693
I0316 13:10:27.620157 55708 solver.cpp:258]     Train net output #0: loss = 0.0129346 (* 1 = 0.0129346 loss)
I0316 13:10:27.620164 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000312742 (* 1 = 0.000312742 loss)
I0316 13:10:27.620169 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0822167 (* 1 = -0.0822167 loss)
I0316 13:10:27.620174 55708 sgd_solver.cpp:112] Iteration 46900, lr = 0.0001
I0316 13:10:35.486357 55708 solver.cpp:351] Iteration 47000, Testing net (#0)
I0316 13:10:39.715853 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 13:10:40.429541 55708 solver.cpp:418]     Test net output #0: loss = 0.464469 (* 1 = 0.464469 loss)
I0316 13:10:40.429565 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000277461 (* 1 = 0.000277461 loss)
I0316 13:10:40.429571 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0753402 (* 1 = -0.0753402 loss)
I0316 13:10:40.429576 55708 solver.cpp:418]     Test net output #3: top-1 = 0.866406
I0316 13:10:40.429580 55708 solver.cpp:418]     Test net output #4: top-5 = 0.9925
I0316 13:10:40.507282 55708 solver.cpp:239] Iteration 47000 (7.75966 iter/s, 12.8872s/100 iters), loss = -0.0697246
I0316 13:10:40.507309 55708 solver.cpp:258]     Train net output #0: loss = 0.011487 (* 1 = 0.011487 loss)
I0316 13:10:40.507316 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000226387 (* 1 = 0.000226387 loss)
I0316 13:10:40.507323 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0814381 (* 1 = -0.0814381 loss)
I0316 13:10:40.507328 55708 sgd_solver.cpp:112] Iteration 47000, lr = 0.0001
I0316 13:10:48.450886 55708 solver.cpp:239] Iteration 47100 (12.5888 iter/s, 7.94358s/100 iters), loss = -0.0556407
I0316 13:10:48.450935 55708 solver.cpp:258]     Train net output #0: loss = 0.018795 (* 1 = 0.018795 loss)
I0316 13:10:48.450942 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000211948 (* 1 = 0.000211948 loss)
I0316 13:10:48.450947 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0746479 (* 1 = -0.0746479 loss)
I0316 13:10:48.450951 55708 sgd_solver.cpp:112] Iteration 47100, lr = 0.0001
I0316 13:10:56.393559 55708 solver.cpp:239] Iteration 47200 (12.5903 iter/s, 7.94264s/100 iters), loss = -0.0613727
I0316 13:10:56.393954 55708 solver.cpp:258]     Train net output #0: loss = 0.0186384 (* 1 = 0.0186384 loss)
I0316 13:10:56.393962 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000280788 (* 1 = 0.000280788 loss)
I0316 13:10:56.393968 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.080292 (* 1 = -0.080292 loss)
I0316 13:10:56.393975 55708 sgd_solver.cpp:112] Iteration 47200, lr = 0.0001
I0316 13:11:04.337332 55708 solver.cpp:239] Iteration 47300 (12.5891 iter/s, 7.9434s/100 iters), loss = -0.0735841
I0316 13:11:04.337376 55708 solver.cpp:258]     Train net output #0: loss = 0.00709178 (* 1 = 0.00709178 loss)
I0316 13:11:04.337383 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000317983 (* 1 = 0.000317983 loss)
I0316 13:11:04.337389 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.080994 (* 1 = -0.080994 loss)
I0316 13:11:04.337394 55708 sgd_solver.cpp:112] Iteration 47300, lr = 0.0001
I0316 13:11:12.281033 55708 solver.cpp:239] Iteration 47400 (12.5886 iter/s, 7.94367s/100 iters), loss = -0.0568674
I0316 13:11:12.281082 55708 solver.cpp:258]     Train net output #0: loss = 0.0153934 (* 1 = 0.0153934 loss)
I0316 13:11:12.281090 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000289973 (* 1 = 0.000289973 loss)
I0316 13:11:12.281095 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0725508 (* 1 = -0.0725508 loss)
I0316 13:11:12.281100 55708 sgd_solver.cpp:112] Iteration 47400, lr = 0.0001
I0316 13:11:20.225041 55708 solver.cpp:239] Iteration 47500 (12.5882 iter/s, 7.94398s/100 iters), loss = -0.0679074
I0316 13:11:20.225082 55708 solver.cpp:258]     Train net output #0: loss = 0.0107593 (* 1 = 0.0107593 loss)
I0316 13:11:20.225090 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000265013 (* 1 = 0.000265013 loss)
I0316 13:11:20.225095 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0789319 (* 1 = -0.0789319 loss)
I0316 13:11:20.225100 55708 sgd_solver.cpp:112] Iteration 47500, lr = 0.0001
I0316 13:11:28.167837 55708 solver.cpp:239] Iteration 47600 (12.5901 iter/s, 7.94277s/100 iters), loss = -0.0590968
I0316 13:11:28.168155 55708 solver.cpp:258]     Train net output #0: loss = 0.0191895 (* 1 = 0.0191895 loss)
I0316 13:11:28.168164 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000235292 (* 1 = 0.000235292 loss)
I0316 13:11:28.168169 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0785216 (* 1 = -0.0785216 loss)
I0316 13:11:28.168175 55708 sgd_solver.cpp:112] Iteration 47600, lr = 0.0001
I0316 13:11:36.111655 55708 solver.cpp:239] Iteration 47700 (12.5889 iter/s, 7.94351s/100 iters), loss = -0.0489363
I0316 13:11:36.111701 55708 solver.cpp:258]     Train net output #0: loss = 0.0277865 (* 1 = 0.0277865 loss)
I0316 13:11:36.111707 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000233269 (* 1 = 0.000233269 loss)
I0316 13:11:36.111714 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0769562 (* 1 = -0.0769562 loss)
I0316 13:11:36.111734 55708 sgd_solver.cpp:112] Iteration 47700, lr = 0.0001
I0316 13:11:44.059406 55708 solver.cpp:239] Iteration 47800 (12.5822 iter/s, 7.94772s/100 iters), loss = -0.0578676
I0316 13:11:44.059450 55708 solver.cpp:258]     Train net output #0: loss = 0.0197245 (* 1 = 0.0197245 loss)
I0316 13:11:44.059458 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000306954 (* 1 = 0.000306954 loss)
I0316 13:11:44.059463 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0778991 (* 1 = -0.0778991 loss)
I0316 13:11:44.059468 55708 sgd_solver.cpp:112] Iteration 47800, lr = 0.0001
I0316 13:11:52.004696 55708 solver.cpp:239] Iteration 47900 (12.5861 iter/s, 7.94525s/100 iters), loss = -0.0686938
I0316 13:11:52.004751 55708 solver.cpp:258]     Train net output #0: loss = 0.00874287 (* 1 = 0.00874287 loss)
I0316 13:11:52.004760 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000241667 (* 1 = 0.000241667 loss)
I0316 13:11:52.004765 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0776785 (* 1 = -0.0776785 loss)
I0316 13:11:52.004771 55708 sgd_solver.cpp:112] Iteration 47900, lr = 0.0001
I0316 13:11:59.871024 55708 solver.cpp:351] Iteration 48000, Testing net (#0)
I0316 13:12:04.812322 55708 solver.cpp:418]     Test net output #0: loss = 0.462754 (* 1 = 0.462754 loss)
I0316 13:12:04.812355 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000278005 (* 1 = 0.000278005 loss)
I0316 13:12:04.812359 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0756253 (* 1 = -0.0756253 loss)
I0316 13:12:04.812387 55708 solver.cpp:418]     Test net output #3: top-1 = 0.868594
I0316 13:12:04.812391 55708 solver.cpp:418]     Test net output #4: top-5 = 0.992656
I0316 13:12:04.891821 55708 solver.cpp:239] Iteration 48000 (7.7597 iter/s, 12.8871s/100 iters), loss = -0.0625834
I0316 13:12:04.891863 55708 solver.cpp:258]     Train net output #0: loss = 0.0118633 (* 1 = 0.0118633 loss)
I0316 13:12:04.891871 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000291157 (* 1 = 0.000291157 loss)
I0316 13:12:04.891877 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.074738 (* 1 = -0.074738 loss)
I0316 13:12:04.891883 55708 sgd_solver.cpp:112] Iteration 48000, lr = 0.0001
I0316 13:12:12.836369 55708 solver.cpp:239] Iteration 48100 (12.5873 iter/s, 7.9445s/100 iters), loss = -0.0700075
I0316 13:12:12.836443 55708 solver.cpp:258]     Train net output #0: loss = 0.00931927 (* 1 = 0.00931927 loss)
I0316 13:12:12.836452 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000326843 (* 1 = 0.000326843 loss)
I0316 13:12:12.836458 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0796537 (* 1 = -0.0796537 loss)
I0316 13:12:12.836463 55708 sgd_solver.cpp:112] Iteration 48100, lr = 0.0001
I0316 13:12:20.779448 55708 solver.cpp:239] Iteration 48200 (12.5897 iter/s, 7.94302s/100 iters), loss = -0.0539247
I0316 13:12:20.779489 55708 solver.cpp:258]     Train net output #0: loss = 0.0198339 (* 1 = 0.0198339 loss)
I0316 13:12:20.779495 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000270532 (* 1 = 0.000270532 loss)
I0316 13:12:20.779500 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0740292 (* 1 = -0.0740292 loss)
I0316 13:12:20.779521 55708 sgd_solver.cpp:112] Iteration 48200, lr = 0.0001
I0316 13:12:28.723598 55708 solver.cpp:239] Iteration 48300 (12.5879 iter/s, 7.94412s/100 iters), loss = -0.0734677
I0316 13:12:28.723644 55708 solver.cpp:258]     Train net output #0: loss = 0.00744006 (* 1 = 0.00744006 loss)
I0316 13:12:28.723650 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00028829 (* 1 = 0.00028829 loss)
I0316 13:12:28.723656 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0811962 (* 1 = -0.0811962 loss)
I0316 13:12:28.723661 55708 sgd_solver.cpp:112] Iteration 48300, lr = 0.0001
I0316 13:12:36.666050 55708 solver.cpp:239] Iteration 48400 (12.5906 iter/s, 7.94242s/100 iters), loss = -0.0434602
I0316 13:12:36.666363 55708 solver.cpp:258]     Train net output #0: loss = 0.0302366 (* 1 = 0.0302366 loss)
I0316 13:12:36.666371 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000224725 (* 1 = 0.000224725 loss)
I0316 13:12:36.666378 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0739217 (* 1 = -0.0739217 loss)
I0316 13:12:36.666383 55708 sgd_solver.cpp:112] Iteration 48400, lr = 0.0001
I0316 13:12:39.290794 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 13:12:44.608309 55708 solver.cpp:239] Iteration 48500 (12.5913 iter/s, 7.94196s/100 iters), loss = -0.0716221
I0316 13:12:44.608351 55708 solver.cpp:258]     Train net output #0: loss = 0.00755219 (* 1 = 0.00755219 loss)
I0316 13:12:44.608357 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000317473 (* 1 = 0.000317473 loss)
I0316 13:12:44.608367 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0794919 (* 1 = -0.0794919 loss)
I0316 13:12:44.608372 55708 sgd_solver.cpp:112] Iteration 48500, lr = 0.0001
I0316 13:12:52.550313 55708 solver.cpp:239] Iteration 48600 (12.5913 iter/s, 7.94197s/100 iters), loss = -0.0511629
I0316 13:12:52.550359 55708 solver.cpp:258]     Train net output #0: loss = 0.0261139 (* 1 = 0.0261139 loss)
I0316 13:12:52.550366 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000273101 (* 1 = 0.000273101 loss)
I0316 13:12:52.550374 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.07755 (* 1 = -0.07755 loss)
I0316 13:12:52.550379 55708 sgd_solver.cpp:112] Iteration 48600, lr = 0.0001
I0316 13:13:00.493387 55708 solver.cpp:239] Iteration 48700 (12.5896 iter/s, 7.94304s/100 iters), loss = -0.0742549
I0316 13:13:00.493430 55708 solver.cpp:258]     Train net output #0: loss = 0.00653365 (* 1 = 0.00653365 loss)
I0316 13:13:00.493438 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000268449 (* 1 = 0.000268449 loss)
I0316 13:13:00.493443 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0810571 (* 1 = -0.0810571 loss)
I0316 13:13:00.493448 55708 sgd_solver.cpp:112] Iteration 48700, lr = 0.0001
I0316 13:13:08.438092 55708 solver.cpp:239] Iteration 48800 (12.5897 iter/s, 7.943s/100 iters), loss = -0.0694374
I0316 13:13:08.438393 55708 solver.cpp:258]     Train net output #0: loss = 0.00864758 (* 1 = 0.00864758 loss)
I0316 13:13:08.438405 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000305295 (* 1 = 0.000305295 loss)
I0316 13:13:08.438412 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0783904 (* 1 = -0.0783904 loss)
I0316 13:13:08.438417 55708 sgd_solver.cpp:112] Iteration 48800, lr = 0.0001
I0316 13:13:16.386468 55708 solver.cpp:239] Iteration 48900 (12.5816 iter/s, 7.9481s/100 iters), loss = -0.0538542
I0316 13:13:16.386512 55708 solver.cpp:258]     Train net output #0: loss = 0.0223827 (* 1 = 0.0223827 loss)
I0316 13:13:16.386518 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.00028904 (* 1 = 0.00028904 loss)
I0316 13:13:16.386523 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0765261 (* 1 = -0.0765261 loss)
I0316 13:13:16.386529 55708 sgd_solver.cpp:112] Iteration 48900, lr = 0.0001
I0316 13:13:24.251454 55708 solver.cpp:351] Iteration 49000, Testing net (#0)
I0316 13:13:26.325433 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 13:13:29.191762 55708 solver.cpp:418]     Test net output #0: loss = 0.454676 (* 1 = 0.454676 loss)
I0316 13:13:29.191792 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000275624 (* 1 = 0.000275624 loss)
I0316 13:13:29.191797 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0755077 (* 1 = -0.0755077 loss)
I0316 13:13:29.191802 55708 solver.cpp:418]     Test net output #3: top-1 = 0.871406
I0316 13:13:29.191805 55708 solver.cpp:418]     Test net output #4: top-5 = 0.993125
I0316 13:13:29.269541 55708 solver.cpp:239] Iteration 49000 (7.76213 iter/s, 12.8831s/100 iters), loss = -0.0424572
I0316 13:13:29.269572 55708 solver.cpp:258]     Train net output #0: loss = 0.0378719 (* 1 = 0.0378719 loss)
I0316 13:13:29.269579 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000252222 (* 1 = 0.000252222 loss)
I0316 13:13:29.269584 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0805814 (* 1 = -0.0805814 loss)
I0316 13:13:29.269593 55708 sgd_solver.cpp:112] Iteration 49000, lr = 0.0001
I0316 13:13:37.212775 55708 solver.cpp:239] Iteration 49100 (12.5894 iter/s, 7.94322s/100 iters), loss = -0.0450682
I0316 13:13:37.212816 55708 solver.cpp:258]     Train net output #0: loss = 0.0336952 (* 1 = 0.0336952 loss)
I0316 13:13:37.212822 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000300982 (* 1 = 0.000300982 loss)
I0316 13:13:37.212829 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0790645 (* 1 = -0.0790645 loss)
I0316 13:13:37.212834 55708 sgd_solver.cpp:112] Iteration 49100, lr = 0.0001
I0316 13:13:45.156401 55708 solver.cpp:239] Iteration 49200 (12.5887 iter/s, 7.9436s/100 iters), loss = -0.0755772
I0316 13:13:45.156685 55708 solver.cpp:258]     Train net output #0: loss = 0.00677397 (* 1 = 0.00677397 loss)
I0316 13:13:45.156693 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000285481 (* 1 = 0.000285481 loss)
I0316 13:13:45.156699 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0826368 (* 1 = -0.0826368 loss)
I0316 13:13:45.156704 55708 sgd_solver.cpp:112] Iteration 49200, lr = 0.0001
I0316 13:13:53.100883 55708 solver.cpp:239] Iteration 49300 (12.5878 iter/s, 7.94421s/100 iters), loss = -0.0673719
I0316 13:13:53.100930 55708 solver.cpp:258]     Train net output #0: loss = 0.0127162 (* 1 = 0.0127162 loss)
I0316 13:13:53.100937 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000323559 (* 1 = 0.000323559 loss)
I0316 13:13:53.100944 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0804118 (* 1 = -0.0804118 loss)
I0316 13:13:53.100947 55708 sgd_solver.cpp:112] Iteration 49300, lr = 0.0001
I0316 13:14:01.043151 55708 solver.cpp:239] Iteration 49400 (12.5909 iter/s, 7.94224s/100 iters), loss = -0.0570699
I0316 13:14:01.043193 55708 solver.cpp:258]     Train net output #0: loss = 0.0213409 (* 1 = 0.0213409 loss)
I0316 13:14:01.043200 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000300574 (* 1 = 0.000300574 loss)
I0316 13:14:01.043205 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0787114 (* 1 = -0.0787114 loss)
I0316 13:14:01.043211 55708 sgd_solver.cpp:112] Iteration 49400, lr = 0.0001
I0316 13:14:08.985890 55708 solver.cpp:239] Iteration 49500 (12.5902 iter/s, 7.94271s/100 iters), loss = -0.0744773
I0316 13:14:08.985941 55708 solver.cpp:258]     Train net output #0: loss = 0.00725145 (* 1 = 0.00725145 loss)
I0316 13:14:08.985949 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000283757 (* 1 = 0.000283757 loss)
I0316 13:14:08.985970 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0820126 (* 1 = -0.0820126 loss)
I0316 13:14:08.985977 55708 sgd_solver.cpp:112] Iteration 49500, lr = 0.0001
I0316 13:14:16.930647 55708 solver.cpp:239] Iteration 49600 (12.587 iter/s, 7.94472s/100 iters), loss = -0.0611299
I0316 13:14:16.930979 55708 solver.cpp:258]     Train net output #0: loss = 0.019632 (* 1 = 0.019632 loss)
I0316 13:14:16.930989 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000249848 (* 1 = 0.000249848 loss)
I0316 13:14:16.930994 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0810119 (* 1 = -0.0810119 loss)
I0316 13:14:16.930999 55708 sgd_solver.cpp:112] Iteration 49600, lr = 0.0001
I0316 13:14:24.873934 55708 solver.cpp:239] Iteration 49700 (12.5897 iter/s, 7.94298s/100 iters), loss = -0.0709798
I0316 13:14:24.873977 55708 solver.cpp:258]     Train net output #0: loss = 0.00970457 (* 1 = 0.00970457 loss)
I0316 13:14:24.873983 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000319532 (* 1 = 0.000319532 loss)
I0316 13:14:24.873989 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.081004 (* 1 = -0.081004 loss)
I0316 13:14:24.873994 55708 sgd_solver.cpp:112] Iteration 49700, lr = 0.0001
I0316 13:14:32.819691 55708 solver.cpp:239] Iteration 49800 (12.5854 iter/s, 7.94573s/100 iters), loss = -0.0688087
I0316 13:14:32.819742 55708 solver.cpp:258]     Train net output #0: loss = 0.0108454 (* 1 = 0.0108454 loss)
I0316 13:14:32.819749 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000385478 (* 1 = 0.000385478 loss)
I0316 13:14:32.819756 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0800397 (* 1 = -0.0800397 loss)
I0316 13:14:32.819761 55708 sgd_solver.cpp:112] Iteration 49800, lr = 0.0001
I0316 13:14:40.763229 55708 solver.cpp:239] Iteration 49900 (12.5889 iter/s, 7.94351s/100 iters), loss = -0.0679021
I0316 13:14:40.763269 55708 solver.cpp:258]     Train net output #0: loss = 0.00893696 (* 1 = 0.00893696 loss)
I0316 13:14:40.763276 55708 solver.cpp:258]     Train net output #1: loss: 50%-fire-rate = 0.000262457 (* 1 = 0.000262457 loss)
I0316 13:14:40.763298 55708 solver.cpp:258]     Train net output #2: loss: forcing-binary = -0.0771016 (* 1 = -0.0771016 loss)
I0316 13:14:40.763303 55708 sgd_solver.cpp:112] Iteration 49900, lr = 0.0001
I0316 13:14:48.312644 55713 data_layer.cpp:73] Restarting data prefetching from start.
I0316 13:14:48.628799 55708 solver.cpp:468] Snapshotting to binary proto file DPU_CIFAR10_48_iter_50000.caffemodel
I0316 13:14:48.717146 55708 sgd_solver.cpp:280] Snapshotting solver state to binary proto file DPU_CIFAR10_48_iter_50000.solverstate
I0316 13:14:48.747154 55708 solver.cpp:331] Iteration 50000, loss = -0.0528421
I0316 13:14:48.747186 55708 solver.cpp:351] Iteration 50000, Testing net (#0)
I0316 13:14:53.590417 55714 data_layer.cpp:73] Restarting data prefetching from start.
I0316 13:14:53.688282 55708 solver.cpp:418]     Test net output #0: loss = 0.46246 (* 1 = 0.46246 loss)
I0316 13:14:53.688304 55708 solver.cpp:418]     Test net output #1: loss: 50%-fire-rate = 0.000277805 (* 1 = 0.000277805 loss)
I0316 13:14:53.688311 55708 solver.cpp:418]     Test net output #2: loss: forcing-binary = -0.0756786 (* 1 = -0.0756786 loss)
I0316 13:14:53.688315 55708 solver.cpp:418]     Test net output #3: top-1 = 0.86875
I0316 13:14:53.688320 55708 solver.cpp:418]     Test net output #4: top-5 = 0.992344
I0316 13:14:53.688324 55708 solver.cpp:336] Optimization Done.
I0316 13:14:53.688328 55708 caffe.cpp:250] Optimization Done.
